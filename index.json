[{"content":"cURL 是我们常用的 http 命令行请求工具，它支持显示请求开始到响应结束各阶段的耗时，以便于开发中排查问题是网络原因还是服务器处理慢原因，主要是利用 -w 参数\ncurl -L -w \u0026#34;time_namelookup: %{time_namelookup} time_connect: %{time_connect} time_appconnect: %{time_appconnect} time_pretransfer: %{time_pretransfer} time_redirect: %{time_redirect} time_starttransfer: %{time_starttransfer} time_total: %{time_total} http_code: %{http_code} content_type: %{content_type} speed_download: %{speed_download} (byte/s) \u0026#34; https://example.com/ 如果使用单行方便拷贝\ncurl -L -w \u0026#34;time_namelookup: %{time_namelookup}\\ntime_connect: %{time_connect}\\ntime_appconnect: %{time_appconnect}\\ntime_pretransfer: %{time_pretransfer}\\ntime_redirect: %{time_redirect}\\ntime_starttransfer: %{time_starttransfer}\\ntime_total: %{time_total}\\nhttp_code: %{http_code}\\ncontent_type: %{content_type}\\nspeed_download: %{speed_download} (byte/s)\\n\u0026#34; https://example.com/ 返回如下\n\u0026lt;!doctype html\u0026gt; \u0026lt;html\u0026gt; ..... \u0026lt;/html\u0026gt; time_namelookup: 0.007911 time_connect: 0.008221 time_appconnect: 0.415794 time_pretransfer: 0.415880 time_redirect: 0.000000 time_starttransfer: 0.618522 time_total: 0.618948 http_code: 200 content_type: text/html; charset=UTF-8 speed_download: 2034 (byte/s) 返回的各参数如下，这是官方文档上的截图\ntime_namelookup 从开始到名称解析完成所花费的时间（以秒为单位） time_connect 从开始到完成与远程主机（或代理）建立 TCP 连接所花费的时间（以秒为单位） time_appconnect 从开始到完成与远程主机的 SSL/SSH 连接/握手所花费的时间（以秒为单位） time_pretransfer 从开始到文件传输即将开始所花费的时间（以秒为单位） time_redirect 在最终事务开始之前，中间所有重定向步骤所花费的时间（以秒为单位） time_starttransfer 从开始到接收到第一个字节所花费的时间（以秒为单位）。这包括 time_pretransfer 以及服务器计算结果所需的时间 time_total 完整操作持续的总时间（以秒为单位） http_code HTTP 响应代码 content_type 请求的 Content-Type speed_download 完整下载测得的平均下载速度 每秒字节数 (bytes/s) 根据上面的文档，我们就可以计算出客户端发出请求之后，服务器处理请求到开始发回数据所需要的时间是 0.610301 秒\ntime_starttransfer:0.618522 - time_connect:0.008221\n客户端从服务器下载数据所用的时间是 0.000426 秒\ntime_total:0.618948 - time_starttransfer:0.618522\nSSL/TLS 握手花费了 0.407573 秒\ntime_appconnect:0.415794 - time_connect:0.008221\n对于没有 SSL/TLS 的明文连接(http://) time_appconnect 为零\nReference https://susam.net/blog/timing-with-curl.html https://curl.se/docs/manpage.html ","permalink":"https://blog.fangjiahui.me/posts/2023-11-26-curl-http-timing/","summary":"cURL 是我们常用的 http 命令行请求工具，它支持显示请求开始到响应结束各阶段的耗时，以便于开发中排查问题是网络原因还是服务器处理慢原因，主要是利用 -w 参数\ncurl -L -w \u0026#34;time_namelookup: %{time_namelookup} time_connect: %{time_connect} time_appconnect: %{time_appconnect} time_pretransfer: %{time_pretransfer} time_redirect: %{time_redirect} time_starttransfer: %{time_starttransfer} time_total: %{time_total} http_code: %{http_code} content_type: %{content_type} speed_download: %{speed_download} (byte/s) \u0026#34; https://example.com/ 如果使用单行方便拷贝\ncurl -L -w \u0026#34;time_namelookup: %{time_namelookup}\\ntime_connect: %{time_connect}\\ntime_appconnect: %{time_appconnect}\\ntime_pretransfer: %{time_pretransfer}\\ntime_redirect: %{time_redirect}\\ntime_starttransfer: %{time_starttransfer}\\ntime_total: %{time_total}\\nhttp_code: %{http_code}\\ncontent_type: %{content_type}\\nspeed_download: %{speed_download} (byte/s)\\n\u0026#34; https://example.com/ 返回如下\n\u0026lt;!doctype html\u0026gt; \u0026lt;html\u0026gt; ..... \u0026lt;/html\u0026gt; time_namelookup: 0.007911 time_connect: 0.008221 time_appconnect: 0.415794 time_pretransfer: 0.415880 time_redirect: 0.000000 time_starttransfer: 0.618522 time_total: 0.618948 http_code: 200 content_type: text/html; charset=UTF-8 speed_download: 2034 (byte/s) 返回的各参数如下，这是官方文档上的截图","title":"cURL 命令 查看请求响应时间"},{"content":"PostgreSQL 全文搜索 在数据量较小的项目中可以使用 PostgreSQL 自带的全文搜索（Full Text Search）支持，代替非常重的 ElasticSearch，减少开发和维护成本，简单又好用，记录下最近的学习\n实现全文搜索主要分为几步，分词、向量化、创建索引（倒排索引）、匹配查询\n分词 默认自带的分词配置是不支持中文的，但可以安装第三方扩展来支持，检查支持的配置库在 psql 中使用 \\dF 命令，\\dFp 列出解析器 。\npostgres=\u0026gt; \\dF List of text search configurations Schema | Name | Description ------------+------------+--------------------------------------- pg_catalog | danish | configuration for danish language pg_catalog | dutch | configuration for dutch language pg_catalog | english | configuration for english language pg_catalog | portuguese | configuration for portuguese language pg_catalog | russian | configuration for russian language pg_catalog | simple | simple configuration pg_catalog | spanish | configuration for spanish language postgres-# \\dFp List of text search parsers Schema | Name | Description ------------+---------+--------------------- pg_catalog | default | default word parser 安装支持中文的扩展 支持中文的扩展有以下这两个\npg_jieba zhparser 根据上面文档安装完后查看，zhparser 和结巴都能用了\npostgres=# \\dF List of text search configurations Schema | Name | Description ------------+------------+-------------------------------------------- ... public | jiebacfg | Mix segmentation configuration for jieba public | jiebahmm | Hmm segmentation configuration for jieba public | jiebamp | MP segmentation configuration for jieba public | jiebaqry | Query segmentation configuration for jieba public | testzhcfg | postgres=# \\dFp List of text search parsers Schema | Name | Description ------------+----------+--------------------- ... public | jieba | public | jiebahmm | public | jiebamp | public | jiebaqry | public | zhparser | 向量化 文本向量化 我们要全文搜索的一般是我们表中的某个字符串字段，必须先向量化此字段，可以直接计算向量也可以存储在新的一列中，该向量的数据类型是 tsvector 它是词和位置组成的列表，用来保存的是分词后的结果 (文本向量)，这两种方式都可以建索引加快查询时间。\npostgres=\u0026gt; select \u0026#39;hello world hello world\u0026#39;::tsvector; tsvector ----------------- \u0026#39;hello\u0026#39; \u0026#39;world\u0026#39; 字符串转化成 tsvector 会以空格分隔去掉重复的词条，按照一定的顺序装入，也可以设置位置\npostgres=\u0026gt; select \u0026#39;hello:2 world:1\u0026#39;::tsvector; tsvector --------------------- \u0026#39;hello\u0026#39;:2 \u0026#39;world\u0026#39;:1 一般我们使用 to_tsvector(regconfig, text) 函数分词并构建 tsvecotr ， regconfig 参数必须在上文 \\dF 返回的配置语言\npostgres=\u0026gt; select to_tsvector(\u0026#39;english\u0026#39;, \u0026#39;hello a world, hello worlds !\u0026#39;); to_tsvector ------------------------- \u0026#39;hello\u0026#39;:1,4 \u0026#39;world\u0026#39;:3,5 如果分词在程序中实现那 regconfig 使用 simple 就可以，text 中传分好的词然后构建向量。上面返回的向量 hello 出现在 1，4 的位置，world 出现在 3，5 的位置，分词忽略了量词、标点、复数\n如果需要搜索两个字段可以使用 || 符号连接字符串后传给 to_tsvector\nto_tsvector(\u0026#39;english\u0026#39;, coalesce(col1, \u0026#39;\u0026#39;) || \u0026#39; \u0026#39; || coalesce(col2, \u0026#39;\u0026#39;)) 还有一种方法是使用 setweight 函数，可以单独指定每列的权重，从 A - D 权重依次递减\nsetweight(to_tsvector(\u0026#39;english\u0026#39;, coalesce(col1,\u0026#39;\u0026#39;)), \u0026#39;A\u0026#39;) || setweight(to_tsvector(\u0026#39;english\u0026#39;, coalesce(col2,\u0026#39;\u0026#39;)), \u0026#39;B\u0026#39;) 在工程上我们可以创建单独的一列存储 tsvector 然后创建索引，详见下文。\n搜索关键字向量化 查询的关键词也需要向量化类型是 tsquery ，tsquery 相当于是查询 tsvector 的查询条件然后通这条件去搜索向量。tsquery 可以组合多种操作符 \u0026amp; (AND), | (OR), ! (NOT), and \u0026lt;-\u0026gt; (FOLLOWED BY)， @@ 是全文搜索匹配操作符参考下文搜索\npostgres=\u0026gt; select \u0026#39;hello world\u0026#39;::tsvector @@ \u0026#39;hello | happy \u0026#39;::tsquery; ?column? ---------- t 我们一般不直接转成 tsquery 来查询，而使用 PostgreSQL 提供的 to_tsquery(regconfig, querytext) 函数来将词组织成 tsquery 向量，querytext 为搜索语句必须为单个关键词或者多个 词和 \u0026amp; 、| 、! 等组合，如上是匹配 hello 或 happy 词。\npostgres=\u0026gt; select to_tsquery(\u0026#39;simple\u0026#39;, \u0026#39;hello | happy\u0026#39;); to_tsquery ------------------- \u0026#39;hello\u0026#39; | \u0026#39;happy\u0026#39; postgres=\u0026gt; select \u0026#39;hello world\u0026#39;::tsvector @@ to_tsquery(\u0026#39;simple\u0026#39;, \u0026#39;hello | happy\u0026#39;); ?column? ---------- t postgres=\u0026gt; select \u0026#39;hello world\u0026#39;::tsvector @@ to_tsquery(\u0026#39;simple\u0026#39;, \u0026#39;hello \u0026amp; happy\u0026#39;); ?column? ---------- f to_tsquery , to_tsvecotr 等函数参数中的第一个参数配置文件（regconfig）可以忽略，这样就使用 PostgreSQL 默认的 default_text_search_config 配置参数\npostgres=# show default_text_search_config; default_text_search_config ---------------------------- pg_catalog.english 搜索 PostgreSQL 中的全文搜索基于匹配操作符 @@ ，如果tsvector(文档)与tsquery(查询)匹配，则返回true。两个位置无所谓可以调换。\npostgres=\u0026gt; select to_tsvector(\u0026#39;Cats are very cute\u0026#39;) @@ to_tsquery(\u0026#39;cats\u0026#39;); ?column? ---------- t postgres=\u0026gt; select \u0026#39;Cats are very cute\u0026#39;::tsvector @@ to_tsquery(\u0026#39;cats\u0026#39;); ?column? ---------- f 注意上文的两个查询，第一个能匹配上是使用了 to_tsvector 进行了分词转 tsvector，结果中会有 cat 词素，第二没有使用则只有 Cats\n@@ 操作符还有以下几种写法\ntsvector @@ tsquery tsquery @@ tsvector text @@ tsquery text @@ text 第一种和第二种相等 第三种等于 to_tsvector(text) @@ tsquery 第四种等于 to_tsvector(text) @@ plainto_tsquery(text). 索引 tsvector 支持的索引分为 gin 和 gist 索引，GIST 索引是有损的，构建速度快。GIN 索引构建速度慢点但查询更快，推荐使用 GIN\n创建 GIN 索引。列必须为 tsvector 类型。 CREATE INDEX name ON table USING GIN (column);\n创建基于 GiST 的索引。该列可以是 tsvector 或 tsquery 类型。 CREATE INDEX name ON table USING GIST (column);\n排序 对于搜索结果的排序 PostgreSQL 提供了下面两个函数\nts_rank(tsvector, tsquery) returns float4 ts_rank_cd(tsvector, tsquery) returns float4 ts_rank 函数依据 tsquery 和 tsvector 考虑查询在搜索字段中出现的频率、位置、相关性等信息计算出一个值，ts_rank_cd 和 ts_rank 基本一致只是考虑了匹配词之间的覆盖密度（cover density）。\n示例 下面看个例子，先创建一张表\ncreate table post ( id serial primary key, title varchar(128) not null, subtitle varchar(256), body text ); 创建 search_vector 列存储 tsvector 然后创建索引\nalter table post add column search_vector tsvector generated always as (to_tsvector(\u0026#39;english\u0026#39;, coalesce(title, \u0026#39;\u0026#39;) || \u0026#39; \u0026#39; || coalesce(subtitle, \u0026#39;\u0026#39;))) stored; create index search_vector_idx on post using gin (search_vector); 上面使用了 generated always 在插入和更新的时候都会更新 search_vector 列，拼接了 title 和 subtitle 同时搜索这两列，也可以使用 setweight 替换成\n... as (setweight(to_tsvector(\u0026#39;english\u0026#39;, coalesce(title,\u0026#39;\u0026#39;)), \u0026#39;A\u0026#39;) || setweight(to_tsvector(\u0026#39;english\u0026#39;, coalesce(subtitle,\u0026#39;\u0026#39;)), \u0026#39;B\u0026#39;))) stored; 上面使用 generated always 自动更新 tsvector ，适用 PostgreSQL 版本大于 11 的，如果版在 11 及以下的可以配合 trigger 使用官方也提供了两个 tsvector_update_trigger 和 tsvector_update_trigger_column 也可以使用自定义的参考官方文档\n我们为 search_vector 列创建了 gin 索引，最后使用下面的 sql 就能搜索了\nselect * from post where search_vector @@ to_tsquery(\u0026#39;english\u0026#39;, \u0026#39;querytext\u0026#39;); 如果我们不使用单独的列存储 tsvector 列，也可以使用索引用下面的 sql 完成\ncreate index search_vector_bare_idx on post using gin (to_tsvector(\u0026#39;english\u0026#39;, coalesce(title, \u0026#39;\u0026#39;) || \u0026#39; \u0026#39; || coalesce(subtitle, \u0026#39;\u0026#39;))); select * from post where to_tsvector(\u0026#39;english\u0026#39;, coalesce(title, \u0026#39;\u0026#39;) || \u0026#39; \u0026#39; || coalesce(subtitle, \u0026#39;\u0026#39;)) @@ to_tsquery(\u0026#39;english\u0026#39;, \u0026#39;querytext\u0026#39;); 查询的时候必须也指定 to_tsvector(regconfig, text) 不能忽略 regconfig 。上面虽然没有占用一列存 tsvector ，但不建议使用这种方式，因为新加一列可以不需要显示指定 regconfig 也就是使用 to_tsquery(text) 的方式，已经预先计算完了 tsvector 所以查询效率更高。\n常用的会加上排序，就是下面这样的 SQL\nselect * from post, to_tsquery(\u0026#39;english\u0026#39;, \u0026#39;querytext1 | querytext2\u0026#39;) query where query @@ search_vector order by ts_rank_cd(search_vector, query) desc; Reference https://www.postgresql.org/docs/current/textsearch.html https://www.jianshu.com/p/0dc2a8bf9631 ","permalink":"https://blog.fangjiahui.me/posts/2023-02-11-postgresql-full-text-search/","summary":"PostgreSQL 全文搜索 在数据量较小的项目中可以使用 PostgreSQL 自带的全文搜索（Full Text Search）支持，代替非常重的 ElasticSearch，减少开发和维护成本，简单又好用，记录下最近的学习\n实现全文搜索主要分为几步，分词、向量化、创建索引（倒排索引）、匹配查询\n分词 默认自带的分词配置是不支持中文的，但可以安装第三方扩展来支持，检查支持的配置库在 psql 中使用 \\dF 命令，\\dFp 列出解析器 。\npostgres=\u0026gt; \\dF List of text search configurations Schema | Name | Description ------------+------------+--------------------------------------- pg_catalog | danish | configuration for danish language pg_catalog | dutch | configuration for dutch language pg_catalog | english | configuration for english language pg_catalog | portuguese | configuration for portuguese language pg_catalog | russian | configuration for russian language pg_catalog | simple | simple configuration pg_catalog | spanish | configuration for spanish language postgres-# \\dFp List of text search parsers Schema | Name | Description ------------+---------+--------------------- pg_catalog | default | default word parser 安装支持中文的扩展 支持中文的扩展有以下这两个","title":"PostgreSQL 全文搜索"},{"content":"Go 服务性能分析 pprof 的使用 go 是主打性能的语言 所以官方集成了方便性能检测的工具 go tool pprof 方便好用，主要可以收集如下指标\nprofile : 程序 cpu 使用情况，按照一定频率去采集应用程序在 CPU 和寄存器上面的数据 heap : 程序 heap 内存使用情况，和调用关系 goroutine : 程序内 goroutine 启动数，各自的调用情况。 block : 报告导致阻塞的同步原语的情况 goroutines 不在运行状态的情况，可以用来分析和查找死锁等性能瓶颈。默认情况下未启用，需要手动调用runtime.SetBlockProfileRate启用。 mutex: 报告锁竞争。默认情况下未启用，需要手动调用runtime.SetMutexProfileFraction启用。 集成到服务 服务应用 常驻的服务型应用要使用 pprof 首先得在服务启动入口导入包\nimport _ \u0026#34;net/http/pprof\u0026#34; ··· go func() { log.Println(http.ListenAndServe(\u0026#34;localhost:6060\u0026#34;, nil)) }() 然后浏览器访问http://localhost:6060/debug/pprof/，显示如下页面\n如上如果服务是 http 服务且使用的是 http.DefaultServeMux 不需要做任何路由注册默认会注册相关路由，初始化调用了init 函数会自动注册，路径为 /debug/pprof/，显示上图，能大概看个当前 goroutine 数目、堆分配情况、锁的情况，具体分析还是要使用下文的 go tool pprof 工具。\n如果使用的是自定义的 ServeMux 或 Handler 需要我们自己手动注册需要的路由，比如使用 echo 框架的时候\nfunc RegisterRoutes(engine *echo.Echo) { router := engine.Group(\u0026#34;\u0026#34;) ...... // 按需注册 router.GET(\u0026#34;/debug/pprof\u0026#34;, echo.WrapHandler(http.HandlerFunc(pprof.Index))) router.GET(\u0026#34;/debug/pprof/allocs\u0026#34;, echo.WrapHandler(http.HandlerFunc(pprof.Index))) router.GET(\u0026#34;/debug/pprof/block\u0026#34;, echo.WrapHandler(http.HandlerFunc(pprof.Index))) router.GET(\u0026#34;/debug/pprof/goroutine\u0026#34;, echo.WrapHandler(http.HandlerFunc(pprof.Index))) router.GET(\u0026#34;/debug/pprof/heap\u0026#34;, echo.WrapHandler(http.HandlerFunc(pprof.Index))) router.GET(\u0026#34;/debug/pprof/mutex\u0026#34;, echo.WrapHandler(http.HandlerFunc(pprof.Index))) router.GET(\u0026#34;/debug/pprof/cmdline\u0026#34;, echo.WrapHandler(http.HandlerFunc(pprof.Cmdline))) router.GET(\u0026#34;/debug/pprof/profile\u0026#34;, echo.WrapHandler(http.HandlerFunc(pprof.Profile))) router.GET(\u0026#34;/debug/pprof/symbol\u0026#34;, echo.WrapHandler(http.HandlerFunc(pprof.Symbol))) router.POST(\u0026#34;/debug/pprof/symbol\u0026#34;, echo.WrapHandler(http.HandlerFunc(pprof.Symbol))) router.GET(\u0026#34;/debug/pprof/trace\u0026#34;, echo.WrapHandler(http.HandlerFunc(pprof.Trace))) router.GET(\u0026#34;/debug/pprof/threadcreate\u0026#34;, echo.WrapHandler(http.HandlerFunc(pprof.Index))) } 如果使用的是 gin 框架，可以使用官方提供的 middleware\n独立应用 独立应用（执行完就退出）使用 pprof ，如工具类应用需要用到 runtime/pprof 包，手动设置 cpu profile 直接放在 main 函数就行，为了更小的影响性能 pprof 会大概以 100 次/秒的频率采样，程序退出最后保存到设置的文件\nvar cpuprofile = flag.String(\u0026#34;cpuprofile\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;write cpu profile to file\u0026#34;) func main() { flag.Parse() if *cpuprofile != \u0026#34;\u0026#34; { f, err := os.Create(*cpuprofile) if err != nil { log.Fatal(err) } pprof.StartCPUProfile(f) defer pprof.StopCPUProfile() // cpu 需要调用 StopCPUProfile } ... 内存分析需要在调用的函数后调用 WriteHeapProfile 方法就可以，不需要 stop，如官方教程在 FindHavlakLoops 后设置了 WriteHeapProfile\nvar memprofile = flag.String(\u0026#34;memprofile\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;write memory profile to this file\u0026#34;) ... FindHavlakLoops(cfgraph, lsgraph) if *memprofile != \u0026#34;\u0026#34; { f, err := os.Create(*memprofile) if err != nil { log.Fatal(err) } pprof.WriteHeapProfile(f) f.Close() return } 分析 不管是开启了 http 服务分析，还是手动设置的，都需要使用如下命令分析\ngo tool pprof [options] [binary] \u0026lt;source\u0026gt; ... binary 为 build 后的二进制文件，source 为上面生成的报告，也可以是 http 地址， 如果带 -http= 参数会以 web UI 方式展示\n# cpu profile go tool pprof ./main profile.out # cpu profile use http go tool pprof ./main http://loacalhost:6060/debug/pprof/profile # memory go tool pprof ./main http://loacalhost:6060/debug/pprof/heap # goroutine go tool pprof ./main http://loacalhost:6060/debug/pprof/goroutine # cpu 采样 60s 默认 30s go tool pprof ./main \u0026#39;http://loacalhost:6060/debug/pprof/profile?seconds=60\u0026#39; # web UI 方式查看 go tool pprof -http=:8080 ./main profile.out 单体应用 以cpu_profile.go代码为例，启动参数开启 cpu profile\ngo build ./cpu_profile.go ./cpu_profile -cpuprofile cpu_profile.out go tool pprof ./cpu_profile cpu_profile.out 然后启动文本模式的命令行\nFile: cpu_profile Type: cpu Time: Dec 13, 2022 at 2:29pm (CST) Duration: 5.16s, Total samples = 4.02s (77.93%) Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) (pprof) 显示 Type: cpu 表示是 cpu profile，采样时间是 5.16s，输入 help 可以查看所有的命令，命令有很多一般常用的有 top, list, peek, tree,web\n(pprof) top Showing nodes accounting for 4.02s, 100% of 4.02s total Showing top 10 nodes out of 11 flat flat% sum% cum cum% 3.63s 90.30% 90.30% 3.99s 99.25% main.Task 0.36s 8.96% 99.25% 0.36s 8.96% runtime.asyncPreempt 0.03s 0.75% 100% 0.03s 0.75% runtime.pthread_cond_signal 0 0% 100% 0.03s 0.75% runtime.mcall 0 0% 100% 0.03s 0.75% runtime.notewakeup 0 0% 100% 0.03s 0.75% runtime.park_m 0 0% 100% 0.03s 0.75% runtime.resetspinning 0 0% 100% 0.03s 0.75% runtime.schedule 0 0% 100% 0.03s 0.75% runtime.semawakeup 0 0% 100% 0.03s 0.75% runtime.startm (pprof) 使用 top 命令查看占用前 10 占用 cpu 的采样，可以使用 top 30 增加输出数目，前三列显示了函数正在运行的占用 cpu 的时间，所占用的百分比，第三列是当前所有函数总的使用 cpu 的比例。第四列和第五列代表这个函数以及子函数运行所占用的时间和比例（也被称为累加值 cumulative），应该大于等于前两列的值，可以用 top -cum 按 cumulative 排序，可以明显的看到 main.Task 占用了 90.30% 占用 cpu 异常高\n(pprof) list Task Total: 4.02s ROUTINE ======================== main.Task in ... cpu_profile.go 3.63s 3.99s (flat, cum) 99.25% of Total . . 9:) . . 10: . . 11:var cpuprofile = flag.String(\u0026#34;cpuprofile\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;write cpu profile to file\u0026#34;) . . 12: . . 13:func Task() { 3.63s 3.99s 14: for { . . 15: } . . 16:} . . 17: . . 18:func main() { . . 19: flag.Parse() (pprof) peek Task Showing nodes accounting for 4.02s, 100% of 4.02s total ----------------------------------------------------------+------------- flat flat% sum% cum cum% calls calls% + context ----------------------------------------------------------+------------- 3.63s 90.30% 90.30% 3.99s 99.25% | main.Task 0.36s 9.02% | runtime.asyncPreempt ----------------------------------------------------------+------------- (pprof) list 后跟正则表达式显示源码，peek 显示调用链\n(pprof) web web 命令显示 svg 图，能更直观的展示，前提是需要安装 graphviz，权重越大方框越大，颜色越明显，箭头是调用图\n服务型应用 我们来看下如果使用的是 http 服务，以 server.go 为例，服务启动后监听在:6060端口\n❯ go build ./server.go ❯ ./server # 启动 访问 http://127.0.0.1:6060/debug/pprof/ 显示 profile 信息，如上图。多次调用/enlarge 路由后进入内存分析\n❯ curl http://127.0.0.1:6060/enlarge slice len: 10485760 ❯ curl http://127.0.0.1:6060/enlarge slice len: 20971520 ❯ curl http://127.0.0.1:6060/enlarge slice len: 31457280 ❯ curl http://127.0.0.1:6060/enlarge slice len: 41943040 ❯ go tool pprof \u0026#39;http://127.0.0.1:6060/debug/pprof/heap\u0026#39; Fetching profile over HTTP from http://127.0.0.1:6060/debug/pprof/heap Saved profile in ~/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.001.pb.gz Type: inuse_space Time: Dec 13, 2022 at 3:32pm (CST) Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) (pprof) top Showing nodes accounting for 57.95MB, 100% of 57.95MB total Showing top 10 nodes out of 28 flat flat% sum% cum cum% 54.95MB 94.82% 94.82% 54.95MB 94.82% main.main.func1 1.50MB 2.59% 97.41% 1.50MB 2.59% runtime.allocm 0.50MB 0.86% 98.27% 0.50MB 0.86% runtime.acquireSudog 0.50MB 0.86% 99.14% 0.50MB 0.86% runtime.bgscavenge 0.50MB 0.86% 100% 1MB 1.73% runtime.gcBgMarkWorker 0 0% 100% 54.95MB 94.82% net/http.(*ServeMux).ServeHTTP 0 0% 100% 54.95MB 94.82% net/http.(*conn).serve 0 0% 100% 54.95MB 94.82% net/http.HandlerFunc.ServeHTTP 0 0% 100% 54.95MB 94.82% net/http.serverHandler.ServeHTTP 0 0% 100% 0.50MB 0.86% runtime.gcMarkDone (pprof) list func1 Total: 57.95MB ROUTINE ======================== main.main.func1 in ~/pprof/demo/server.go 54.95MB 54.95MB (flat, cum) 94.82% of Total . . 11: . . 12:func main() { . . 13: . . 14: http.HandleFunc(\u0026#34;/enlarge\u0026#34;, func(w http.ResponseWriter, r *http.Request) { . . 15: d := make([]byte, 10*1024*1024) // 10M 54.95MB 54.95MB 16: data = append(data, d...) . . 17: fmt.Fprintf(w, \u0026#34;slice len: %d\u0026#34;, len(data)) . . 18: }) . . 19: . . 20: log.Println(http.ListenAndServe(\u0026#34;localhost:6060\u0026#34;, nil)) . . 21:} (pprof) tree func1 Active filters: focus=func1 Showing nodes accounting for 54.95MB, 93.21% of 58.96MB total ----------------------------------------------------------+------------- flat flat% sum% cum cum% calls calls% + context ----------------------------------------------------------+------------- 54.95MB 100% | net/http.HandlerFunc.ServeHTTP 54.95MB 93.21% 93.21% 54.95MB 93.21% | main.main.func1 ----------------------------------------------------------+------------- 54.95MB 100% | net/http.serverHandler.ServeHTTP 0 0% 93.21% 54.95MB 93.21% | net/http.(*ServeMux).ServeHTTP 54.95MB 100% | net/http.HandlerFunc.ServeHTTP ----------------------------------------------------------+------------- 0 0% 93.21% 54.95MB 93.21% | net/http.(*conn).serve 54.95MB 100% | net/http.serverHandler.ServeHTTP ----------------------------------------------------------+------------- 54.95MB 100% | net/http.(*ServeMux).ServeHTTP 0 0% 93.21% 54.95MB 93.21% | net/http.HandlerFunc.ServeHTTP 54.95MB 100% | main.main.func1 ----------------------------------------------------------+------------- 54.95MB 100% | net/http.(*conn).serve 0 0% 93.21% 54.95MB 93.21% | net/http.serverHandler.ServeHTTP 54.95MB 100% | net/http.(*ServeMux).ServeHTTP ----------------------------------------------------------+------------- (pprof) 命令和之前 cpu profile 分析一样只是这次对象是内存，Type: inuse_space 是默认的统计的是内存使用大小，在 go tool pprof执行时加上 -inuse_objects 可以切换，还有几个参数如下\n-inuse_space: 正在使用的内存大小，默认模式 -inuse_objects: 正在使用，尚未被释放的对象数量 -alloc_space: 已经被分配的内存空间，没有考虑对象释放的情况 -alloc_objects: 已经被分配的对象数量，没有考虑对象释放的情况 如果是内存泄露, 可以根据 inuse_space 的占比和变化判断, 但是也不是万能的, 有些时候, 一些 inuse_space 是因为高流量导致的. 对于频繁创建的一些对象 可以在 alloc_space 和 alloc_object 判断, 这种场景可以通过复用对象池来减少没意义的分配。\n上面 main.main.func1 明显就是内存很高，很容易排查到，tree命令显示了函数调用栈\n在调用 cpu profile 时默认采样 30s，可以使用 ?seconds=5s参数指定，如果在调用时返回一个 \u0026quot;profile duration exceeds server's *WriteTimeout*\u0026quot;的错误。那是 http.Server 的 WriteTimeout 小了调大相应的值即可\nhttp.Server{ Addr: addr, ReadTimeout: time.Second * 5, ReadHeaderTimeout: time.Second * 2, WriteTimeout: time.Second * 90, } 加上 -http=:8080 可以使用 web ui 的方式查看，不启动命令行\ngo tool pprof -http=:8080 \u0026#39;http://127.0.0.1:6060/debug/pprof/heap\u0026#39; Fetching profile over HTTP from http://127.0.0.1:6060/debug/pprof/heap Saved profile in ~/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.002.pb.gz Serving web UI on http://localhost:8080 访问网页，在左上角 view 中切换 Flame Graph 可以以火焰图的方式展示\n如果应用比较复杂，生成的调用图特别大，看起来很乱，有两个办法可以优化：\n使用 web funcName 的方式，只打印和某个函数相关的内容 运行 go tool pprof 命令时加上 --nodefration=0.05 参数，表示如果调用的子函数使用的 CPU、memory 不超过 5%，就忽略 测试集成 go test 命令有两个参数和 pprof 相关，它们分别指定生成的 CPU 和 Memory profiling 保存的文件：\n-cpuprofile：cpu profiling 数据要保存的文件地址 -memprofile：memory profiling 数据要报文的文件地址 比如下面执行 go test 的同时，也会执行 CPU profiling，并把结果保存在 cpu.prof 文件中：\n$ go test -bench . -cpuprofile=cpu.prof 执行结束之后，就会生成 main.test 和 cpu.prof 文件。要想使用 go tool pprof，需要指定的二进制文件就是 main.test。\n在 https 中使用 go tool pprof https+insecure://localhost:6060/debug/pprof/heap将原来的http替换成https+insecure即可。\n自动捕获 profile 是查看当时的系统状态 我们线上代码运行出问题的时候有时候要么已经重启要么程序已经退出，怎么保留案发现场及时的记录有用的数据呢，手动调用runtime/pprof是可以控制，但自己打哪里不知道啊，所以介绍下下面一个包\nholmes\n它能在两种状态下记录 profile\ncpu/mem/goroutine 数突然比正常情况下的平均值高出了一定的比例，比如说资源占用率突增 25%就是出现了资源尖刺。 cpu/mem/goroutine 数超过了程序正常运行情况下的阈值，比如说 80%就定义为服务资源紧张。 具体可参考文档自行配置\nReference https://go.dev/blog/pprof https://mp.weixin.qq.com/s/m68JmVxEW2NebjM7PMnE1A https://mp.weixin.qq.com/s/MNj7SqooyCYLo0ooUt5APA https://mp.weixin.qq.com/s/SsCPvePTvjxzLqudZaN4Sw ","permalink":"https://blog.fangjiahui.me/posts/2022-12-16-go-tool-pprof-tutorial/","summary":"Go 服务性能分析 pprof 的使用 go 是主打性能的语言 所以官方集成了方便性能检测的工具 go tool pprof 方便好用，主要可以收集如下指标\nprofile : 程序 cpu 使用情况，按照一定频率去采集应用程序在 CPU 和寄存器上面的数据 heap : 程序 heap 内存使用情况，和调用关系 goroutine : 程序内 goroutine 启动数，各自的调用情况。 block : 报告导致阻塞的同步原语的情况 goroutines 不在运行状态的情况，可以用来分析和查找死锁等性能瓶颈。默认情况下未启用，需要手动调用runtime.SetBlockProfileRate启用。 mutex: 报告锁竞争。默认情况下未启用，需要手动调用runtime.SetMutexProfileFraction启用。 集成到服务 服务应用 常驻的服务型应用要使用 pprof 首先得在服务启动入口导入包\nimport _ \u0026#34;net/http/pprof\u0026#34; ··· go func() { log.Println(http.ListenAndServe(\u0026#34;localhost:6060\u0026#34;, nil)) }() 然后浏览器访问http://localhost:6060/debug/pprof/，显示如下页面\n如上如果服务是 http 服务且使用的是 http.DefaultServeMux 不需要做任何路由注册默认会注册相关路由，初始化调用了init 函数会自动注册，路径为 /debug/pprof/，显示上图，能大概看个当前 goroutine 数目、堆分配情况、锁的情况，具体分析还是要使用下文的 go tool pprof 工具。\n如果使用的是自定义的 ServeMux 或 Handler 需要我们自己手动注册需要的路由，比如使用 echo 框架的时候","title":"Go 服务性能分析 pprof 的使用"},{"content":"有的 openwrt 固件不会断网自动重播，检查 /etc/ppp/options 文件是否存在如下参数，没有的话自己加上一般就好了\nmaxfail 0 persist 或者使用 crotab 重启接口，每天 3 点重新拨号\n0 3 * * * ifdown wan \u0026amp;\u0026amp; sleep 3 \u0026amp;\u0026amp; ifup wan Reference: https://www.right.com.cn/FORUM/thread-4107089-1-1.html ","permalink":"https://blog.fangjiahui.me/posts/2022-08-06-openwrt-auto-pppoe/","summary":"有的 openwrt 固件不会断网自动重播，检查 /etc/ppp/options 文件是否存在如下参数，没有的话自己加上一般就好了\nmaxfail 0 persist 或者使用 crotab 重启接口，每天 3 点重新拨号\n0 3 * * * ifdown wan \u0026amp;\u0026amp; sleep 3 \u0026amp;\u0026amp; ifup wan Reference: https://www.right.com.cn/FORUM/thread-4107089-1-1.html ","title":"openwrt 自动重拨"},{"content":"Go 中的类型和比较 go 是一个强类型的语言，map 中要求键(key)必须是可比较的(comparable)，什么是可比较呢？就是能用操作符 == 的类型， 我们知道必须两个类型一致才能比较，否则编译器会报 invalid operation: a == c (mismatched types...) 的错误，准确的说基本类型（int8,float32,string）符合上面的原则，但 golang 中又有复合类型就不一样，先来看 go 中的类型\n1. 基本类型 (Basic Types)\n数字类型：\nint8, uint8 (byte), int16, uint16, int32 (rune), uint32, int64, uint64, int, uint, uintptr.\nfloat32, float64.\ncomplex64, complex128.\n布尔类型：\nbool\n字符串类型：\nstring\n2. 复合类型 (Basic Types)\n结构体(struct)类型\n函数：go 中函数是一等公民，也是一种类型\n数组(array)：包括长度和类型，不同长度的相同类型不属于同一类型\n切片(slice)：切片有动态的长度和容量是一种引用类型\n字典(map)：底层是哈希表也是一种引用类型\n指针类型(pointer)\n管道(channel)\n接口类型(interface)\n类型重定义(Type Definitions)和类型别名(Type Alias Declarations) 讲完了类型再来看看用户可以创建自己的类型（类型重定义）和创建别名，先看类型定义\n// Define a solo new type. // type NewTypeName SourceType type MyInt int type Num int 上面定义了 MyInt , Num 两个类型，虽然他们的源类型都是 int 但他们是不同的类型，所以他们是不可以比较的，但可以通过转换成相同类型的再比较如\nvar a MyInt = 1 var b Num = 1 // a == b can not compare println(a == MyInt(b)) // true 有了 type 关键字使用者可以定义任何与业务相关的类型\n新手在类型别名和类型重定义很容易搞混，类型别名只多了一个 =\ntype Age = int 我们定义了 Age 只是 int 类型的一个别名，Age 类型是可以和 int 做比较的，也就是创建了类型别名之后和原来的源类型是可以比较的\nvar age1 Age = 1 var age2 int = 1 println(age1 == age2) // true 官方 rune 和 int32 ，byte 和 uint8 就是类型别名\n基本类型的比较 遵守如下规则\n两个变量必须属于同一种基本类型 类型别名可以比较 类型重定义不能比较，可以通过转换成同一类型再比较 复合类型的比较 复合类型有多种情况，我们需要分开讨论\n切片 (slice) 切片不可比较，只能与 nil 做比较 a := []int{} b := []int{} println(a == b) // invalid operation: a == b (slice can only be compared to nil) 字典 (map) map 类型无法比较，只能与 nil 比较 a := map[string]int{} b := map[string]int{} println(a == b) // invalid operation: a == b (map can only be compared to nil) 函数 (function) 函数无法比较，只能与 nil 比较 a := func() {} b := func() {} println(a == b) // invalid operation: a == b (func can only be compared to nil) 结构体 (struct) 同一个类型的 struct 逐个字段比较 当 struct 中有字段是不可比较的成员类型时(slice, map, function)无法比较 type Person struct { Name string Age int } type Company struct { Count int Persons []Person } func main() { a := Person{\u0026#34;foo\u0026#34;, 1} b := Person{\u0026#34;bar\u0026#34;, 1} println(a == b) // false c := Company{2, []Person{a, b}} d := Company{2, []Person{a, b}} // print(c == d) // invalid operation: c == d (struct containing []Person cannot be compared) } Company 中包含 []Person 切片类型所以是不可比较的，尽管 Person 是可以比较的\n数组 (array) 需要数组的长度和类型一致才能比较 数组的长度是类型的一部分，如果数组长度不同无法比较 值逐个比较 如果数组元素的类型是不可比较的类型(slice, map, function)，则数组也不能比较 a := [2]int{1, 2} b := [3]int{1, 2, 3} c := [3]int{1, 2, 3} d := [2]int{1, 1} // a == b // invalid operation: a == b (mismatched types [2]int and [3]int) println(c == b) // true println(a == d) // false type myFunc func() e := [1]myFunc{} f := [1]myFunc{} // print(e == f) // invalid operation: e == f ([1]myFunc cannot be compared) 指针 (Pointer) 和 管道 (channel) pointer 和 channel 归一起说是因为他们其实都是引用类型，指向一个内存地址，所以必须地址一致才会相等\n指向的地址一致为相等 可以和 nil 比较判断是否为空 package main type A struct { x string } func main() { a1 := \u0026amp;A{\u0026#34;foo\u0026#34;} a2 := \u0026amp;A{\u0026#34;foo\u0026#34;} a3 := a1 println(a1 == a2) // false 地址不同 println(a1 == a3) // true var a4 *A println(a4 == nil) // true c1 := make(chan int) c2 := make(chan int) println(c1 == c2) // false var c3 chan int println(c3 == nil) // true } 接口 (interface) 接口的比较需要接口的**动态类型 (_type)和值 (data)**都相等时才相同 实现接口的动态类型其指向一定是可比较，不能是不可比较的类型(slice, map, function) package main type MyInterface interface { Echo() string } type A struct { AField string } func (a A) Echo() string { return a.AField } type B struct { BField string } func (b B) Echo() string { return b.BField } func compare(a, b MyInterface) bool { return a == b } func main() { A1 := A{ AField: \u0026#34;foo\u0026#34;, } A2 := A{ AField: \u0026#34;foo\u0026#34;, } B1 := B{ BField: \u0026#34;foo\u0026#34;, } println(compare(A1, A2)) // true println(compare(A1, B1)) // false 动态类型不同 A3 := \u0026amp;A{ AField: \u0026#34;foo\u0026#34;, } A4 := \u0026amp;A{ AField: \u0026#34;foo\u0026#34;, } println(compare(A3, A4)) // false 使用了指针值不同 } 如果动态类型是不可比较的编译能通过，但运行时会 panic\ntype MySlice []int func (m MySlice) Echo() string { return \u0026#34;echo\u0026#34; } e1 := MySlice([]int{1}) e2 := MySlice([]int{1}) compare(e1, e2) // panic: runtime error: comparing uncomparable type main.MySlice 使用 reflect 比较 slice 和 map 类型 使用 == 操作符是无法比较 slice 和 map 的，可使用提供的 reflect 包中的 reflect.DeepEqual 是可以比较 slice 和 map 类型的\nm1 := map[string]int{\u0026#34;foo\u0026#34;: 1, \u0026#34;bar\u0026#34;: 2} m2 := map[string]int{\u0026#34;bar\u0026#34;: 2, \u0026#34;foo\u0026#34;: 1} m3 := map[string]string{\u0026#34;foo\u0026#34;: \u0026#34;bar\u0026#34;} println(reflect.DeepEqual(m1, m2)) // true println(reflect.DeepEqual(m1, m3)) // false var m4 map[string]int println(reflect.DeepEqual(m4, nil)) // false println(m4 == nil) // true s1 := []int{1, 2} s2 := []int{2, 1} s3 := []int{1, 2} println(reflect.DeepEqual(s1, s2)) // false println(reflect.DeepEqual(s1, s3)) // true var s4 []int println(reflect.DeepEqual(s4, nil)) // false println(s4 == nil) // true map 比较只要相同的键值对都相同两个 map 相等，与顺序无关 slice 顺序不同值相同就不相等 声名空的 map 和 slice 和 nil 比较会返回 flase ， 如果用 == 操作符就返回 true 总结 slice 、map、function 不可比较 任何 struct 和 array 含有上述不可比较的类型就不能比较 接口的比较要实现接口的动态类型和动态值都相同时才相等，动态类型也不能为不可比较的类型 slice、map 的比较可以用 reflect.DeepEqual Reference https://go101.org/article/type-system-overview.html https://www.jianshu.com/p/a982807819fa ","permalink":"https://blog.fangjiahui.me/posts/2022-05-29-go-types-and-comparisons/","summary":"Go 中的类型和比较 go 是一个强类型的语言，map 中要求键(key)必须是可比较的(comparable)，什么是可比较呢？就是能用操作符 == 的类型， 我们知道必须两个类型一致才能比较，否则编译器会报 invalid operation: a == c (mismatched types...) 的错误，准确的说基本类型（int8,float32,string）符合上面的原则，但 golang 中又有复合类型就不一样，先来看 go 中的类型\n1. 基本类型 (Basic Types)\n数字类型：\nint8, uint8 (byte), int16, uint16, int32 (rune), uint32, int64, uint64, int, uint, uintptr.\nfloat32, float64.\ncomplex64, complex128.\n布尔类型：\nbool\n字符串类型：\nstring\n2. 复合类型 (Basic Types)\n结构体(struct)类型\n函数：go 中函数是一等公民，也是一种类型\n数组(array)：包括长度和类型，不同长度的相同类型不属于同一类型\n切片(slice)：切片有动态的长度和容量是一种引用类型\n字典(map)：底层是哈希表也是一种引用类型\n指针类型(pointer)\n管道(channel)\n接口类型(interface)\n类型重定义(Type Definitions)和类型别名(Type Alias Declarations) 讲完了类型再来看看用户可以创建自己的类型（类型重定义）和创建别名，先看类型定义\n// Define a solo new type. // type NewTypeName SourceType type MyInt int type Num int 上面定义了 MyInt , Num 两个类型，虽然他们的源类型都是 int 但他们是不同的类型，所以他们是不可以比较的，但可以通过转换成相同类型的再比较如","title":"Go 中的类型和比较"},{"content":"Chrome 继续访问证书错误的网页 chrome 有时访问 https 网页会出现警告 NET::ERR_CERT_DATE_INVALID\nYour connection is not private Attackers might be trying to steal your information from xxx.example.com (for example, passwords, messages, or credit cards). Learn more NET::ERR_CERT_DATE_INVALID 有个彩蛋 如果要继续访问只需要点击页面然后键盘输入 thisisunsafe 就可以继续访问了\n或者打开控制台粘贴以下命令\nsendCommand(SecurityInterstitialCommandId.CMD_PROCEED); Reference https://stackoverflow.com/questions/58802767/no-proceed-anyway-option-on-neterr-cert-invalid-in-chrome-on-macos\n","permalink":"https://blog.fangjiahui.me/posts/2021-12-21-chrome-proceed-anyway/","summary":"Chrome 继续访问证书错误的网页 chrome 有时访问 https 网页会出现警告 NET::ERR_CERT_DATE_INVALID\nYour connection is not private Attackers might be trying to steal your information from xxx.example.com (for example, passwords, messages, or credit cards). Learn more NET::ERR_CERT_DATE_INVALID 有个彩蛋 如果要继续访问只需要点击页面然后键盘输入 thisisunsafe 就可以继续访问了\n或者打开控制台粘贴以下命令\nsendCommand(SecurityInterstitialCommandId.CMD_PROCEED); Reference https://stackoverflow.com/questions/58802767/no-proceed-anyway-option-on-neterr-cert-invalid-in-chrome-on-macos","title":"Chrome  继续访问证书错误的网页"},{"content":"Manjaro 原生的字体没法覆盖全部的 Emojis 可能导致一些字体显示框框 可以通过安装 noto-fonts-emoji 将Noto Color Emoji 字体设置为默认表情符号字体来解决这个问题。Arch 应该也可以通过此方法解决\n1. 安装字体 sudo pacman -S noto-fonts-emoji 2. 在 /usr/share/fontconfig/conf.avail/ 中创建 75-noto-color-emoji.conf 文件 文件内容如下\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE fontconfig SYSTEM \u0026#34;fonts.dtd\u0026#34;\u0026gt; \u0026lt;fontconfig\u0026gt; \u0026lt;!-- Add generic family. --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;emoji\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;assign\u0026#34; binding=\u0026#34;same\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- This adds Noto Color Emoji as a final fallback font for the default font families. --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;sans\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;append\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;serif\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;append\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;sans-serif\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;append\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;monospace\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;append\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- Block Symbola from the list of fallback fonts. --\u0026gt; \u0026lt;selectfont\u0026gt; \u0026lt;rejectfont\u0026gt; \u0026lt;pattern\u0026gt; \u0026lt;patelt name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Symbola\u0026lt;/string\u0026gt; \u0026lt;/patelt\u0026gt; \u0026lt;/pattern\u0026gt; \u0026lt;/rejectfont\u0026gt; \u0026lt;/selectfont\u0026gt; \u0026lt;!-- Use Noto Color Emoji when other popular fonts are being specifically requested. --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Apple Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;assign\u0026#34; binding=\u0026#34;same\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Segoe UI Emoji\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;assign\u0026#34; binding=\u0026#34;same\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Segoe UI Symbol\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;assign\u0026#34; binding=\u0026#34;same\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Android Emoji\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;assign\u0026#34; binding=\u0026#34;same\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Twitter Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;assign\u0026#34; binding=\u0026#34;same\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Twemoji\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;assign\u0026#34; binding=\u0026#34;same\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Twemoji Mozilla\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;assign\u0026#34; binding=\u0026#34;same\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;TwemojiMozilla\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;assign\u0026#34; binding=\u0026#34;same\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;EmojiTwo\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;assign\u0026#34; binding=\u0026#34;same\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Emoji Two\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;assign\u0026#34; binding=\u0026#34;same\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;EmojiSymbols\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;assign\u0026#34; binding=\u0026#34;same\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Symbola\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;assign\u0026#34; binding=\u0026#34;same\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;/fontconfig\u0026gt; 3. 配置文件 sudo ln -sf /usr/share/fontconfig/conf.avail/75-noto-color-emoji.conf /etc/fonts/conf.d sudo fc-cache -f -v 然后重启电脑应该就可以了\n","permalink":"https://blog.fangjiahui.me/posts/2021-10-08-marjaro-arch-linxu-install-full-emoji/","summary":"Manjaro 原生的字体没法覆盖全部的 Emojis 可能导致一些字体显示框框 可以通过安装 noto-fonts-emoji 将Noto Color Emoji 字体设置为默认表情符号字体来解决这个问题。Arch 应该也可以通过此方法解决\n1. 安装字体 sudo pacman -S noto-fonts-emoji 2. 在 /usr/share/fontconfig/conf.avail/ 中创建 75-noto-color-emoji.conf 文件 文件内容如下\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE fontconfig SYSTEM \u0026#34;fonts.dtd\u0026#34;\u0026gt; \u0026lt;fontconfig\u0026gt; \u0026lt;!-- Add generic family. --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;emoji\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;assign\u0026#34; binding=\u0026#34;same\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!-- This adds Noto Color Emoji as a final fallback font for the default font families. --\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;sans\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;append\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;serif\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;append\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;sans-serif\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;append\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test name=\u0026#34;family\u0026#34;\u0026gt;\u0026lt;string\u0026gt;monospace\u0026lt;/string\u0026gt;\u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;append\u0026#34;\u0026gt;\u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt;\u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;!","title":"Manjaro Linux 安装 Emoji"},{"content":"破解滑块验证码（geetest极验） 最近写爬虫遇到极验（geetest）的滑块验证码，首先想到的是用Selenium模拟人拖动滑块，那么问题来了其实主要解决下面两个问题\n拖动的距离是多少 怎么模拟出像人一样再滑动 滑动距离 先来解决第一个问题，我们怎么计算拖动距离，打开chrome的审查元素查看需要拖动的图片\n\u0026lt;div class=\u0026#34;geetest_canvas_img geetest_absolute\u0026#34; style=\u0026#34;display: block;\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;geetest_slicebg geetest_absolute\u0026#34;\u0026gt; \u0026lt;canvas class=\u0026#34;geetest_canvas_bg geetest_absolute\u0026#34; height=\u0026#34;160\u0026#34; width=\u0026#34;260\u0026#34;\u0026gt;\u0026lt;/canvas\u0026gt; \u0026lt;canvas class=\u0026#34;geetest_canvas_slice geetest_absolute\u0026#34; width=\u0026#34;260\u0026#34; height=\u0026#34;160\u0026#34;\u0026gt;\u0026lt;/canvas\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;canvas class=\u0026#34;geetest_canvas_fullbg geetest_fade geetest_absolute\u0026#34; height=\u0026#34;160\u0026#34; width=\u0026#34;260\u0026#34; style=\u0026#34;display: none;\u0026#34;\u0026gt;\u0026lt;/canvas\u0026gt; \u0026lt;/div\u0026gt; 发现有三个canvas 对应三张图片大小都是 260* 160 ，我们使用selenium执行 js 转成 base64 后再转成图片都保存下来看一下，第一张 geetest_canvas_bg 是有缺口的图片\nim_bg_b64 = driver.execute_script( \u0026#39;return document.getElementsByClassName(\u0026#34;geetest_canvas_bg geetest_absolute\u0026#34;)[0].toDataURL(\u0026#34;image/png\u0026#34;);\u0026#39;) # base64 encoded image im_bg_b64 = im_bg_b64.split(\u0026#39;,\u0026#39;)[-1] im_bg_bytes = base64.b64decode(im_bg_b64) with open(\u0026#39;./temp_bg.png\u0026#39;, \u0026#39;wb\u0026#39;) as f: f.write(im_bg_bytes) 然后第二张 geetest_canvas_slice 根据上面相同的方法保存到本地是这样的，就是一个滑块\n第三张 geetest_canvas_fullbg 猜名称也能猜到是图片的全景\n有上面三张图片，怎么计算滑动的距离呢，发现只要找到第一张缺口的位置坐标 x1 和第二张滑块的坐标 x2 那么 x1 - x2 就是我们要的距离，主要是找到 x1 的位置可以通过对比第一张和第三张得到，具体的方法是对比两张图像素点不同时即为 x1 的位置。因为 x2 的位置一直在左边差不多固定的位置假设离最左边为 10 个像素所以我们不需要计算 x2，以下是实现两张图片确定 x1 的代码，图片处理使用的是pillow库\ndef get_dis_use_same_pixel(self, im_fullbg, im_bg): \u0026#34;\u0026#34;\u0026#34; 对比是否是相同像素确定移动距离 \u0026#34;\u0026#34;\u0026#34; pix_1 = im_fullbg.load() pix_2 = im_bg.load() threshold = 60 for x in range(im_fullbg.size[0]): # 垂直方向不同像素的计数 vert_count = 0 for y in range(im_fullbg.size[1]): p_1 = pix_1[x, y] p_2 = pix_2[x, y] # 找到像素不同的点 if abs(p_1[0] - p_2[0]) \u0026gt; threshold and abs(p_1[1] - p_2[1]) \u0026gt; threshold and abs(p_1[2] - p_2[2]) \u0026gt; threshold: vert_count += 1 # 如果是一条直线返回横坐标距离，测试下来10个像素结果较好 # print(vert_count, x) if vert_count \u0026gt; 10: return x 上面可以得出 x1，然后 x1 - 10 就是所需要的滑动的距离了\n模拟滑动 第一个问题解决了得到了滑动距离 x， 那怎么模拟人为的滑动呢。经过简单测试发现机器只要像人一样一下划过去多一点然后再收一点回来就可以骗过机器，代码如下，主要用到selenium的ActionChains。也有人尝试加上加速度，因为我测试下来这也可以我又非常懒就没加了。。。\ndef simulate_human_drag_x(self, element, offset_x): \u0026#34;\u0026#34;\u0026#34; 简单拖拽模仿人的拖拽：快速沿着X轴拖动，多拖一点然后再回来，再暂停，释放 \u0026#34;\u0026#34;\u0026#34; action_chains = webdriver.ActionChains(driver) # 点击，准备拖拽 action_chains.click_and_hold(element) action_chains.pause(0.3) action_chains.move_by_offset(offset_x + 7, 0) action_chains.pause(0.8) action_chains.move_by_offset(-7, 0) action_chains.pause(0.6) action_chains.release() action_chains.perform() 验证 按照上面的思路串起来，再加上失败重试（点击刷新按钮）就差不多，下面以注册极验账户https://www.geetest.com/Register测试下。代码可以直接运行，GitHub链接\nfrom selenium import webdriver from selenium.webdriver.support.ui import WebDriverWait from selenium.webdriver.support import expected_conditions as EC from selenium.webdriver.common.by import By import time import base64 from PIL import Image from io import BytesIO class GeetestCaptcha: def __init__(self, driver): self.driver = driver def crack_geetest_captcha(self, try_time=5): \u0026#34;\u0026#34;\u0026#34; 模拟滑动GeeTest滑动验证码 \u0026#34;\u0026#34;\u0026#34; print(f\u0026#34;try crack captcha, remain {try_time} times\u0026#34;) # 等待图片刷新 time.sleep(3) WebDriverWait(self.driver, 20).until(EC.visibility_of_element_located( (By.CSS_SELECTOR, \u0026#34;canvas.geetest_canvas_slice.geetest_absolute\u0026#34;))) im_bg_b64 = self.driver.execute_script( \u0026#39;return document.getElementsByClassName(\u0026#34;geetest_canvas_bg geetest_absolute\u0026#34;)[0].toDataURL(\u0026#34;image/png\u0026#34;);\u0026#39;) # base64 encoded image im_bg_b64 = im_bg_b64.split(\u0026#39;,\u0026#39;)[-1] im_bg_bytes = base64.b64decode(im_bg_b64) # with open(\u0026#39;./temp_bg.png\u0026#39;, \u0026#39;wb\u0026#39;) as f: # f.write(im_bg_bytes) # im_slice_b64 = self.driver.execute_script( # \u0026#39;return document.getElementsByClassName(\u0026#34;geetest_canvas_slice geetest_absolute\u0026#34;)[0].toDataURL(\u0026#34;image/png\u0026#34;);\u0026#39;) # im_slice_b64 = im_slice_b64.split(\u0026#39;,\u0026#39;)[-1] # im_slice_bytes = base64.b64decode(im_slice_b64) # with open(\u0026#39;./temp_slice.png\u0026#39;, \u0026#39;wb\u0026#39;) as f: # f.write(im_slice_bytes) im_fullbg = self.driver.execute_script( \u0026#39;return document.getElementsByClassName(\u0026#34;geetest_canvas_fullbg geetest_fade geetest_absolute\u0026#34;)[0].toDataURL(\u0026#34;image/png\u0026#34;);\u0026#39;) im_fullbg = im_fullbg.split(\u0026#39;,\u0026#39;)[-1] im_fullbg_bytes = base64.b64decode(im_fullbg) # with open(\u0026#39;./temp_fullbg.png\u0026#39;, \u0026#39;wb\u0026#39;) as f: # f.write(im_fullbg_bytes) # calculate sliding distance im_bg = Image.open(BytesIO(im_bg_bytes)) im_fullbg = Image.open(BytesIO(im_fullbg_bytes)) # 计算距离 x_offset = self.get_dis_use_same_pixel(im_fullbg, im_bg) # 根据距离滑动滑块 if x_offset is not None: WebDriverWait(self.driver, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \u0026#34;.geetest_slider_button\u0026#34;))) button = self.driver.find_element_by_css_selector(\u0026#34;.geetest_slider_button\u0026#34;) # 滑块距离左边有 10 像素左右，需要减掉 x_offset -= 10 print(f\u0026#34;slide {x_offset} pixel\u0026#34;) self.simulate_human_drag_x(button, x_offset) time.sleep(3) if \u0026#39;geetest_panel_box geetest_panelshowslide\u0026#39; not in self.driver.page_source: print(\u0026#39;crack success\u0026#39;) return True if len(self.driver.find_elements_by_xpath(\u0026#34;//div[@class=\u0026#39;geetest_panel_box geetest_panelshowslide\u0026#39;]\u0026#34;)) \u0026gt; 0 and \\ try_time \u0026gt; 0: WebDriverWait(self.driver, 20).until(EC.element_to_be_clickable((By.XPATH, \u0026#34;//a[@class=\u0026#39;geetest_refresh_1\u0026#39;]\u0026#34;))).click() return self.crack_geetest_captcha(try_time - 1) print(\u0026#34;sorry! failed to crack\u0026#34;) return False else: print(\u0026#34;failed to calculate pixel distance\u0026#34;) # 没计算出滑动距离。继续刷新下尝试 if try_time \u0026gt; 0: time.sleep(2) WebDriverWait(self.driver, 20).until(EC.element_to_be_clickable((By.XPATH, \u0026#34;//a[@class=\u0026#39;geetest_refresh_1\u0026#39;]\u0026#34;))).click() return self.crack_geetest_captcha(try_time - 1) else: print(\u0026#34;sorry! no chance. failed\u0026#34;) return False def simulate_human_drag_x(self, element, offset_x): \u0026#34;\u0026#34;\u0026#34; 简单拖拽模仿人的拖拽：快速沿着X轴拖动，多拖一点然后再回来，再暂停，释放 \u0026#34;\u0026#34;\u0026#34; action_chains = webdriver.ActionChains(self.driver) # 点击，准备拖拽 action_chains.click_and_hold(element) action_chains.pause(0.3) action_chains.move_by_offset(offset_x + 7, 0) action_chains.pause(0.8) action_chains.move_by_offset(-7, 0) action_chains.pause(0.6) action_chains.release() action_chains.perform() def get_dis_use_same_pixel(self, im_fullbg, im_bg): \u0026#34;\u0026#34;\u0026#34; 对比是否是相同像素确定移动距离 \u0026#34;\u0026#34;\u0026#34; pix_1 = im_fullbg.load() pix_2 = im_bg.load() threshold = 60 for x in range(im_fullbg.size[0]): # 垂直方向不同像素的计数 vert_count = 0 for y in range(im_fullbg.size[1]): p_1 = pix_1[x, y] p_2 = pix_2[x, y] # 找到像素不同的点 if abs(p_1[0] - p_2[0]) \u0026gt; threshold and abs(p_1[1] - p_2[1]) \u0026gt; threshold and abs(p_1[2] - p_2[2]) \u0026gt; threshold: vert_count += 1 # 如果是一条直线返回横坐标距离，测试下来10个像素结果较好 # print(vert_count, x) if vert_count \u0026gt; 10: return x options = webdriver.ChromeOptions() # options.add_argument(\u0026#34;--headless\u0026#34;) # Runs Chrome in headless mode. options.add_argument(\u0026#39;--no-sandbox\u0026#39;) # Bypass OS security model # options.add_argument(\u0026#39;--disable-gpu\u0026#39;) # applicable to windows os only options.add_argument(\u0026#39;--ignore-certificate-errors\u0026#39;) options.add_argument(\u0026#34;--disable-extensions\u0026#34;) options.add_argument(\u0026#39;start-maximized\u0026#39;) options.add_argument(\u0026#39;disable-infobars\u0026#39;) # Configure capabilities capabilities = webdriver.DesiredCapabilities.CHROME driver = webdriver.Chrome(executable_path=\u0026#34;/usr/bin/chromedriver\u0026#34;, options=options, desired_capabilities=capabilities) driver.set_script_timeout(120) driver.set_page_load_timeout(120) driver.get(\u0026#34;https://www.geetest.com/Register\u0026#34;) WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \u0026#39;//div[@id=\u0026#34;gt-register-mobile\u0026#34;]//input[@placeholder=\u0026#34;手机号码\u0026#34;]\u0026#39;))) driver.find_element_by_xpath(\u0026#39;//div[@id=\u0026#34;gt-register-mobile\u0026#34;]//input[@placeholder=\u0026#34;手机号码\u0026#34;]\u0026#39;).send_keys(\u0026#39;13799999999\u0026#39;) WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \u0026#39;//div[@id=\u0026#34;gt-register-mobile\u0026#34;]//div[@class=\u0026#34;sendCode\u0026#34;]\u0026#39;))) driver.find_element_by_xpath(\u0026#39;//div[@id=\u0026#34;gt-register-mobile\u0026#34;]//div[@class=\u0026#34;sendCode\u0026#34;]\u0026#39;).click() WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.XPATH, \u0026#34;//canvas[@class=\u0026#39;geetest_canvas_bg geetest_absolute\u0026#39;]\u0026#34;))) GeetestCaptcha(driver).crack_geetest_captcha() ","permalink":"https://blog.fangjiahui.me/posts/2021-05-05-crack-geetest-captcha/","summary":"破解滑块验证码（geetest极验） 最近写爬虫遇到极验（geetest）的滑块验证码，首先想到的是用Selenium模拟人拖动滑块，那么问题来了其实主要解决下面两个问题\n拖动的距离是多少 怎么模拟出像人一样再滑动 滑动距离 先来解决第一个问题，我们怎么计算拖动距离，打开chrome的审查元素查看需要拖动的图片\n\u0026lt;div class=\u0026#34;geetest_canvas_img geetest_absolute\u0026#34; style=\u0026#34;display: block;\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;geetest_slicebg geetest_absolute\u0026#34;\u0026gt; \u0026lt;canvas class=\u0026#34;geetest_canvas_bg geetest_absolute\u0026#34; height=\u0026#34;160\u0026#34; width=\u0026#34;260\u0026#34;\u0026gt;\u0026lt;/canvas\u0026gt; \u0026lt;canvas class=\u0026#34;geetest_canvas_slice geetest_absolute\u0026#34; width=\u0026#34;260\u0026#34; height=\u0026#34;160\u0026#34;\u0026gt;\u0026lt;/canvas\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;canvas class=\u0026#34;geetest_canvas_fullbg geetest_fade geetest_absolute\u0026#34; height=\u0026#34;160\u0026#34; width=\u0026#34;260\u0026#34; style=\u0026#34;display: none;\u0026#34;\u0026gt;\u0026lt;/canvas\u0026gt; \u0026lt;/div\u0026gt; 发现有三个canvas 对应三张图片大小都是 260* 160 ，我们使用selenium执行 js 转成 base64 后再转成图片都保存下来看一下，第一张 geetest_canvas_bg 是有缺口的图片\nim_bg_b64 = driver.execute_script( \u0026#39;return document.getElementsByClassName(\u0026#34;geetest_canvas_bg geetest_absolute\u0026#34;)[0].toDataURL(\u0026#34;image/png\u0026#34;);\u0026#39;) # base64 encoded image im_bg_b64 = im_bg_b64.split(\u0026#39;,\u0026#39;)[-1] im_bg_bytes = base64.b64decode(im_bg_b64) with open(\u0026#39;./temp_bg.png\u0026#39;, \u0026#39;wb\u0026#39;) as f: f.write(im_bg_bytes) 然后第二张 geetest_canvas_slice 根据上面相同的方法保存到本地是这样的，就是一个滑块","title":"破解滑块验证码（geetest极验）"},{"content":"Mac Launchd 介绍和使用 Linux 上如果想开机开机启动一个服务或者定时运行一个服务有很多的选择比如之前介绍过的Systemd或者用 crontab 也可以，而在 Mac 不同它有一个类似的叫 Launchd 的系统，对应使用launchctl命令控制\nDaemons and Agents Launchd 管理 Daemons 和 Agents 两种类型分别存放在不同的文件夹下，主要的区别是\nAgents 是用户登录后执行的 Daemons 是开机后就执行，可以通过UserName指定用户比如root用户 配置文件 Launchd 配置文件以.plist结尾，本质上是xml格式的文件，Daemons 和 Agents 各存放的路径也不同\n类型 路径 说明 User Agents ~/Library/LaunchAgents 用户 Agents 当前用户登录时运行 Global Agents /Library/LaunchAgents 全局 Agents 任何用户登录时都会运行 System Agents /System/Library/LaunchAgents 系统 Agents 任何用户登录时都会运行 Global Daemons /Library/LaunchDaemons 全局 Daemons 内核初始化加载完后就运行 System Daemons /System/Library/LaunchDaemons 系统 Daemons 内核初始化加载完后就运行 系统运行开机首先会加载内核启动kernel_tas(0)，然后启动launchd(1)好后去启动指定好的 Daemons 最后用户登录再运行相应的 Agents 任务\n一般文件名都以com.domain.programName.plist格式命名，不管是 Daemons 还是 Agents 格式都是一样的，只是存放位置不同。看下面一个 hello world 的例子 ~/Library/LaunchAgents/com.example.hello.plist\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026#34;-//Apple//DTD PLIST 1.0//EN\u0026#34; \u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026#34;\u0026gt; \u0026lt;plist version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Label\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;com.example.hello\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;ProgramArguments\u0026lt;/key\u0026gt; \u0026lt;array\u0026gt; \u0026lt;string\u0026gt;/bin/echo\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;hello world\u0026lt;/string\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; 上面定义了一个最简单的任务只使用了Label和ProgramAgruments两个键\nLabel这是个必须的键，指定这个任务名 ProgramArguments是带参数的可执行文件上面等同于运行/bin/echo hello world命令，如果执行的程序不带参数可以使用Program键，但一个任务中必须包含这两个中的其中一个键 还有一些常用的键名，所有的键可参考man 5 launchd.plist或者这里\nKeys Description EnvironmentVariables 设置运行环境变量 StandardOutPath 标准输出到文件 StandardErrorPath 标准错误到文件 RunAtLoad 是否再加载的时候就运行 StartInterval 设置程序每隔多少秒运行一次 KeepAlive 是否设置程序是一直存活着 如果退出就重启 UserName 设置用户名只在 Daemons 可用 WorkingDirectory 设置工作目录 launchctl 命令 现在我们就加载和运行一个任务，上面定义了~/Library/LaunchAgents/com.example.hello.plist，我们修改一下增加一个键(StandardOutPath)用于标准输出\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026#34;-//Apple//DTD PLIST 1.0//EN\u0026#34; \u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026#34;\u0026gt; \u0026lt;plist version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Label\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;com.example.hello\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;StandardOutPath\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;/tmp/hello.log\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;ProgramArguments\u0026lt;/key\u0026gt; \u0026lt;array\u0026gt; \u0026lt;string\u0026gt;/bin/echo\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;hello world\u0026lt;/string\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; 上面的配置把标准输出重定向到了/tmp/hello.log，我们运行测试下。检查配置文件是否写正确可以使用plutil命令\n❯ plutil ~/Library/LaunchAgents/com.example.hello.plist /Users/fython/Library/LaunchAgents/com.example.hello.plist: OK ❯ launchctl load ~/Library/LaunchAgents/com.example.hello.plist ❯ launchctl start com.example.hello ❯ cat /tmp/hello.log hello world ❯ launchctl list | grep hello -\t0\tcom.example.hello ❯ launchctl remove com.example.hello # remove jobs 一个任务首先需要被加载(load)，然后启动(start)正常运行完退出，所以我们查看/tmp目录下会有日志输出\n任务一般都要手动启动(start)，如果设置了RunAtLoad或者KeepAlive则在launchctl load时就启动 使用launchctl list列出当前加载的任务，第一列代表进程 id，因为上面的程序运行一次就退出了所以显示-，第二列是程序上次运行退出的 code，0代表正常退出，如果是正数代表退出的时候是有错误的，负数代表是接收到信号被终止的 launchctl stop \u0026lt;service_name\u0026gt;可以终止一个在运行中的任务，launchctl unload \u0026lt;path\u0026gt;指定路径卸载一个任务，launchctl remove \u0026lt;service_name\u0026gt;通过服务名卸载任务 launchctl load \u0026lt;path\u0026gt;只会加载没有被disable的任务，可以加-w参数 launchctl load -w \u0026lt;path\u0026gt;覆盖如果设置了 disable 的，下次开机启动一定会起来。launchctl unload \u0026lt;path\u0026gt;只会停止和卸载这个任务，但下次启动还会加载，可以使用-w参数launchctl unload -w \u0026lt;path\u0026gt;停止任务，下次启动也不会起来，也就是标记了disable 调试一个任务可以配合使用plutil命令检查语法，设置StandardOutPath、StandardErrorPath、Debug键，也可以看看苹果自带的Console.app应用中的system.log 一些例子 以下是我一些使用过的配置文件\n调换 mac 键盘右 command 和 option 键 文件路径 ~/Library/LaunchAgents/com.fython.swapKey.plist\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026#34;-//Apple//DTD PLIST 1.0//EN\u0026#34; \u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026#34;\u0026gt; \u0026lt;plist version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Label\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;com.fython.swapKey\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;RunAtLoad\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;ProgramArguments\u0026lt;/key\u0026gt; \u0026lt;array\u0026gt; \u0026lt;string\u0026gt;/usr/bin/hidutil\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;property\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;--set\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;{\u0026#34;UserKeyMapping\u0026#34;: [{\u0026#34;HIDKeyboardModifierMappingSrc\u0026#34;:0x7000000e7, \u0026#34;HIDKeyboardModifierMappingDst\u0026#34;:0x7000000e6}, {\u0026#34;HIDKeyboardModifierMappingSrc\u0026#34;:0x7000000e6, \u0026#34;HIDKeyboardModifierMappingDst\u0026#34;:0x7000000e7}] }\u0026lt;/string\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; 习惯了传统的键盘布局，希望改变右边 option (alt)键的位置，系统设置里面没有开放出来，可以使用上面的命令设置。开机自动执行。\n放在用户目录 ~/Library/LaunchAgents/ 用户登录时执行 hidutil 命令，然后执行 launchctl load -w ~/Library/LaunchAgents/com.fython.swapKey.plist 设置开机启动\n开机启动 clash 代理（TUN 模式） 文件路径： /Library/LaunchDaemons/com.fython.clash.plist\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026#34;-//Apple//DTD PLIST 1.0//EN\u0026#34; \u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026#34;\u0026gt; \u0026lt;plist version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Label\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;com.fython.clash\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;RunAtLoad\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;UserName\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;root\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;StandardErrorPath\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;/Users/fython/bin/clash/stderr.log\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;StandardOutPath\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;/Users/fython/bin/clash/stdout.log\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;WorkingDirectory\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;/Users/fython/bin/clash\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;ProgramArguments\u0026lt;/key\u0026gt; \u0026lt;array\u0026gt; \u0026lt;string\u0026gt;/Users/fython/bin/clash/clash\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;-f\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;config.yaml\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;-d\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;/Users/fython/bin/clash\u0026lt;/string\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;key\u0026gt;KeepAlive\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; 因为要监听 53 端口所以需要 root 用户启动，而且需要用户登录前就运行所以存放在/Library/LaunchDaemons/目录下，配置了KeepAlive和UserName，也设置了工作目录WorkingDirectory，日志也存在这目录下。这个任务加载和其他操作都需要加 sudo，sudo launchctl load /Library/LaunchDaemons/com.fython.clash.plist因为配置了RunAtLoad它会自动启动，不需要在 start 了\nReference https://www.launchd.info/ https://developer.apple.com https://apple.stackexchange.com ","permalink":"https://blog.fangjiahui.me/posts/2021-04-19-mac-launchd-daemons-and-agents-tutorial/","summary":"Mac Launchd 介绍和使用 Linux 上如果想开机开机启动一个服务或者定时运行一个服务有很多的选择比如之前介绍过的Systemd或者用 crontab 也可以，而在 Mac 不同它有一个类似的叫 Launchd 的系统，对应使用launchctl命令控制\nDaemons and Agents Launchd 管理 Daemons 和 Agents 两种类型分别存放在不同的文件夹下，主要的区别是\nAgents 是用户登录后执行的 Daemons 是开机后就执行，可以通过UserName指定用户比如root用户 配置文件 Launchd 配置文件以.plist结尾，本质上是xml格式的文件，Daemons 和 Agents 各存放的路径也不同\n类型 路径 说明 User Agents ~/Library/LaunchAgents 用户 Agents 当前用户登录时运行 Global Agents /Library/LaunchAgents 全局 Agents 任何用户登录时都会运行 System Agents /System/Library/LaunchAgents 系统 Agents 任何用户登录时都会运行 Global Daemons /Library/LaunchDaemons 全局 Daemons 内核初始化加载完后就运行 System Daemons /System/Library/LaunchDaemons 系统 Daemons 内核初始化加载完后就运行 系统运行开机首先会加载内核启动kernel_tas(0)，然后启动launchd(1)好后去启动指定好的 Daemons 最后用户登录再运行相应的 Agents 任务\n一般文件名都以com.domain.programName.plist格式命名，不管是 Daemons 还是 Agents 格式都是一样的，只是存放位置不同。看下面一个 hello world 的例子 ~/Library/LaunchAgents/com.","title":"Mac Launchd 介绍和使用"},{"content":"Golang 中的 Arrays 和 Slices 在 go 语言中，我们经常使用Slices类型因为它的方便和灵活，它和另一个Arrays类型有着密切的关系，Slices 是建立在 Arrays 的基础上的，搞明白它们的原理能使我们更加的轻松的使用它们\nArrays Arrays 和别的语言(C、Java)的类型一样，有固定的长度，在内存里是一块连续的空间，用以存储相同类型的 types。用如下方式申明\nvar array [5]int 像[size]T在 go 中申明array，size 是 type 的一部分 如上面的[5]int代表 5 个 int 元素的 Arrays，和另一个如[10]int是不同的类型，Arrays 有确定的长度。并且申明之后带默认值(各类型的零值)。也可以使用[...]符号省略 size 申明，编译器自动计算 如array := [...]int{1, 2, 3, 4, 5} 变量array引用的是整个 Array 而不是 Array 的第一个元素，如果将一个数组另外赋值是将这个数组拷贝了一份，数组作为函数参数也是将整个数组拷贝一份，非引用数组的指针 Slices 就是因为 Arrays 比较难用，go 在此基础上建立了 Slices，它是可以动态调整长度(dynamically-sized)的描述 Arrays 一部分的 types，Slices 可以使用切片数组的方式得到\narray := [5]int{1, 2, 3, 4, 5} // Arrays var slice = array[1:4] // same as `var slice []int = array[1:4]` fmt.Println(slice) // [2 3 4] fmt.Println(len(slice)) // 3 fmt.Println(cap(slice)) // 4 array[2] = 9 fmt.Println(slice) // [2 9 4] slice = slice[:4] fmt.Println(slice) // [2 9 4 5] fmt.Println(array) // [1 2 9 4 5] Slices 的底层指向的是 Arrays，它描述底层一部分的 Arrays，如果被引用的 array 变化了，引用它的所有 slice 都会随之变化 Slices 有长度(length)和容量(capacity)，分别通过len和cap获取，长度就是切片的长度，容量是从 slice 的第一个元素到底层引用的 Arrays 的末尾元素的个数，也就是这个 slices 最大能达到的长度，例如上面的 slice 从第二个元素2到引用底层 array 末尾的元素5所以 cap 等于 4，所以 slices 可以动态调整但不能大于它的容量 将整个 Arrays 转化成 Slices 可以忽略前后索引slice := array[:]。Slices 以[]T的形式申明\nvar slice1 []int slice2 := []int{1, 2, 3} slice3 := make([]int, 3) 第一种这看起来和申明 Arrays 差不多，就是少了 size。第二种通过:=并初始化了三个值。第三种是通过make可以指定len和cap，格式为make([]T, len, cap)。更加详细的make用法下面再说\nslice header 说了很多知道了 Slices 不是 Arrays，那var slice = array[1:4]中slice引用的是什么呢，我们可以想象成**slice变量是一个存储指向 Slices 头(slice header)的指针加一个长度(length)和容量(capacity)的数据结构**\narray := [5]int{1, 2, 3, 4, 5} type sliceHeader struct { Length int Capacity int ZerothElement *int } slice := sliceHeader{ Length: 3, Capacity: 5, ZerothElement: \u0026amp;array[1], } PS: 我们可以使用unsafe.Pointer和reflect.SliceHeader查看 slice header\nslice := array[1:4] fmt.Printf(\u0026#34;%+v\u0026#34;, *(*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;slice))) // {Data:824634355504 Len:3 Cap:4} 在 Slices 传参给函数当作参数时也是传的 slice 头(slice header)的一个副本给函数，如果有修改 slices 其实是修改了底层的 Arrays，引用这个 Arrays 的所有 Slices 都会随之改变。看下面官方博客上的例子\npackage main import \u0026#34;fmt\u0026#34; func AddOneToEachElement(slice []byte) { for i := range slice { slice[i]++ } } func SubtractOneFromLength(slice []byte) []byte { slice = slice[0: len(slice) - 1] return slice } var buffer [265]byte func main() { slice := buffer[10:20] for i := 0; i \u0026lt; len(slice); i++ { slice[i] = byte(i) } fmt.Println(\u0026#34;before\u0026#34;, slice) AddOneToEachElement(slice) fmt.Println(\u0026#34;after\u0026#34;, slice) fmt.Println(\u0026#34;Before: len(slice) =\u0026#34;, len(slice)) newSlice := SubtractOneFromLength(slice) fmt.Println(\u0026#34;After: len(slice) =\u0026#34;, len(slice)) fmt.Println(\u0026#34;After: len(newSlice) =\u0026#34;, len(newSlice)) } 输出结果\nbefore [0 1 2 3 4 5 6 7 8 9] after [1 2 3 4 5 6 7 8 9 10] Before: len(slice) = 10 After: len(slice) = 10 After: len(newSlice) = 9 调用AddOneToEachElement的 slice 底层还是指向 Arrays，所以改变了之后所有 slice 引用的 Array 都会改变(都增加了 1)\n传给SubtractOneFromLength的是 slice header 的一个拷贝，在函数里面改变了 slice 但在外部的 slice 是不会改变的如果想要更改后的 slice 只能返回值变量重新赋值(newSlice)得到，也就是 pass by value。\nmake 使用内置的make函数可以指定创建固定长度(len)和容量(cap)的 slices\nslice := make([]int, 5, 10) 如上创建了一个 slices 长度为 5，容量为 10，且已经初始化默认值为 type 的零值这里就是 0。如果忽略第三个容量参数时，cap 默认和 len 的值相同。下面创建一个容量两倍新的 slices，填入原来 slice 的值，也就是扩容了一倍\nslice := make([]int, 5, 10) fmt.Printf(\u0026#34;len: %d, cap: %d\\n\u0026#34;, len(slice), cap(slice)) // len: 5, cap: 10 newSlice := make([]int, len(slice), 2*cap(slice)) for i := range slice { newSlice[i] = slice[i] } fmt.Printf(\u0026#34;len: %d, cap: %d\\n\u0026#34;, len(newSlice), cap(newSlice)) // len: 5, cap: 20 copy 上面手动使用 for 循环复制原来的slice，golang 中有自带的copy函数能实现同样的功能\nnewSlice := make([]int, len(slice), 2*cap(slice)) copy(newSlice, slice) copy是很聪明的，他自动判断复制两个 slices 中的最小长度，返回复制个数\nappend make创建的 slices 都是固定容量的如果新增元素容量超了怎么办呢，有个append函数能很好的处理其中的问题\nfunc main() { slice := make([]int, 0, 2) for i := 0; i \u0026lt; 5; i++ { slice = append(slice, i) fmt.Println(\u0026amp;slice[0], slice) } } 输出\n❯ go run code.go 0xc0000140d0 [0] 0xc0000140d0 [0 1] 0xc0000220a0 [0 1 2] 0xc0000220a0 [0 1 2 3] 0xc00001a100 [0 1 2 3 4] 注意上面 slice header 它是不同的，当 slices 的容量不够无法 append 时apped函数会新建一个 slices，增大容量返回新的 slices，所以每次使用append函数时必须把返回结果赋值到 slice 变量\nReference https://blog.golang.org/slices-intro https://blog.golang.org/slices ","permalink":"https://blog.fangjiahui.me/posts/2021-04-08-go-arrays-and-slices/","summary":"Golang 中的 Arrays 和 Slices 在 go 语言中，我们经常使用Slices类型因为它的方便和灵活，它和另一个Arrays类型有着密切的关系，Slices 是建立在 Arrays 的基础上的，搞明白它们的原理能使我们更加的轻松的使用它们\nArrays Arrays 和别的语言(C、Java)的类型一样，有固定的长度，在内存里是一块连续的空间，用以存储相同类型的 types。用如下方式申明\nvar array [5]int 像[size]T在 go 中申明array，size 是 type 的一部分 如上面的[5]int代表 5 个 int 元素的 Arrays，和另一个如[10]int是不同的类型，Arrays 有确定的长度。并且申明之后带默认值(各类型的零值)。也可以使用[...]符号省略 size 申明，编译器自动计算 如array := [...]int{1, 2, 3, 4, 5} 变量array引用的是整个 Array 而不是 Array 的第一个元素，如果将一个数组另外赋值是将这个数组拷贝了一份，数组作为函数参数也是将整个数组拷贝一份，非引用数组的指针 Slices 就是因为 Arrays 比较难用，go 在此基础上建立了 Slices，它是可以动态调整长度(dynamically-sized)的描述 Arrays 一部分的 types，Slices 可以使用切片数组的方式得到\narray := [5]int{1, 2, 3, 4, 5} // Arrays var slice = array[1:4] // same as `var slice []int = array[1:4]` fmt.","title":" Go 中的 Arrays 和 Slices"},{"content":"BASH SHELL cheat sheet 记录一些 bash shell 脚本的奇技淫巧，都是从实际使用中 google 的。bash 各 Linux 发行版都自带方便好用特别是文本处理、一些运维之类的小脚本，但有些语法繁琐不好记容易忘整理一下方便查找。\ntrap trap 命令 用于指定在接收到信号后将要采取的动作，常见的用途是在脚本程序被中断时完成清理工作。当 shell 接收到 sigspec 指定的信号时，arg 参数（命令）将会被读取，并被执行。例如：\ntrap \u0026#34;exit 1\u0026#34; HUP INT PIPE QUIT TERM 表示当 shell 收到HUP,INT,PIPE,QUIT,TERM这几个信号时，当前执行的程序会读取参数\u0026quot;exit 1\u0026quot;，并将它作为命令执行。\n如果要忽略某个信号就参数使用单引号就可以''\ntrap \u0026#39;\u0026#39; signals 如果启动的时候忽略了信号比如使用了nohup，trap 命令是无效的。具体信号可使用man 7 signal或者kill -l查阅\n$*、$@、$# 直接上例子看，如下脚本test.sh\necho 参数总个数 \\$#: $# echo 第0个参数 \\$0: $0 for a in $(seq 1 $#); do eval b=\\$$a echo 第\u0026#34;$a\u0026#34;个参数 \\$\u0026#34;$a\u0026#34;: $b done echo -e \u0026#34;\\nUsing \\\u0026#34;\\$#\\\u0026#34;:\u0026#34; echo \u0026#34;$#\u0026#34; echo -e \u0026#34;\\nUsing \\$#:\u0026#34; echo $# echo -e \u0026#34;\\nUsing \\\u0026#34;\\$*\\\u0026#34;:\u0026#34; for a in \u0026#34;$*\u0026#34;; do echo $a; done echo -e \u0026#34;\\nUsing \\$*:\u0026#34; for a in $*; do echo $a; done echo -e \u0026#34;\\nUsing \\\u0026#34;\\$@\\\u0026#34;:\u0026#34; for a in \u0026#34;$@\u0026#34;; do echo $a; done echo -e \u0026#34;\\nUsing \\$@:\u0026#34; for a in $@; do echo $a; done 然后运行此脚本，注意最后3 4用了双引号\nbash test.sh 1 2 \u0026#34;3 4\u0026#34; 结果如下\n❯ bash test.sh 1 2 \u0026#34;3 4\u0026#34; 参数总个数 $#: 3 第0个参数 $0: test.sh 第1个参数 $1: 1 第2个参数 $2: 2 第3个参数 $3: 3 4 Using \u0026#34;$#\u0026#34;: 3 Using $#: 3 Using \u0026#34;$*\u0026#34;: 1 2 3 4 Using $*: 1 2 3 4 Using \u0026#34;$@\u0026#34;: 1 2 3 4 Using $@: 1 2 3 4 $#是命令的参数总数，不算$0所以是 3，加不加引号效果一样。\n然后$*和$@总结一下就是，在没有双引号的情况下$*和$@效果一样，加上了双引号$*会把参数当成一串字符串一次性处理，$@加双引号会以空格分隔成列表一般也是我们需要的效果。\n$! $!代表最近在后台执行的进程 pid\n❯ nohup sleep 10 \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; [1] 79627 ❯ echo $! 79712 可以配合wait命令一起使用，等待任务结束\n❯ nohup sleep 30 \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; ❯ recent_pid=$! ❯ # do some else ... ❯ wait $recent_pid # wait for complete finish ❯ echo $? # check status 0 计算单词数 可以使用wc -w计算，如\nwc -w \u0026lt;\u0026lt;\u0026lt; \u0026#34;a b c\u0026#34; # 3 read命令 从标准输入（std input）读取一行\nwhile read -r line; do echo \u0026#34;\u0026gt; $line \u0026lt;\u0026#34; done 从管道读取内容到变量 如下面为./run.sh文件\nINPUT=$(\u0026lt;/dev/stdin) echo \u0026#34;$INPUT\u0026#34; 然后echo hello world | ./run.sh，其中INPUT变量就是输入内容\nfd 命令 取代find, 如下一次性把所有当前目录及子目录下的所有apk移动到特定目录\nfind . -type f -name \u0026#39;*.apk\u0026#39; -exec mv -t /target/path {} + # replace use fd fd -t f -e apk --exec-batch mv -t ./target/path ack/ag/rg 命令 ack和ag命令是高级版本的grep，ack使用 Perl 编写更能发挥正则的威力，而ag是ack的高性能版，而且加上了.gitignore搜索速度会更加的快\nack --python 'regex' 或者ag --python 'regex'\n搜索所有 python 文件中包含 regex，ack 默认结果只显示匹配到的内容开头不加行号可以使用-H显示 ag 会默认加上行号，可以使用-l参数只显示文件名，-c显示每个文件匹配到次数，-w只匹配单词\nack -g 'regex' 或者 ag -g 'regex'\n只搜索文件名匹配的，列出文件\nrg 比 ag 还要快，它是用 Rust 写得。\n端口扫描 Nmap nmap -p- -v -A -T4 xxx.xxx.xxx.xxx\n全范围端口扫描，-p指定端口范围-p-为全部范围，-A指定探测系统和各端口对应的服务-T4设定速度但耗时还是会比较长，想要快可以不加参数nmap -v xxx.xxx.xxx.xxx\nnmap -sT xxx.xxx.xxx.xxx\n单独扫描TCP端口，可以把-sT改成-sU就是单独扫描UDP协议的\nnmap -sn 192.168.2.0/24\nping 扫描不做端口扫描，上面检测192.168.2.0/24网段所有可以 ping 通的机器，检测有多少机器在线很有用\nTCP连接 状态统计 ss -nat | awk \u0026#39;NR \u0026gt; 1 { ++counts[$1] } END { for (c in counts) print c, counts[c] }\u0026#39; 特定端口连接查看 ss -o state established \u0026#39;( dport = :22 or sport = :22 )\u0026#39;` 远程机器执行本地脚本 ssh user@machine \u0026#34;$(\u0026lt; script.sh)\u0026#34; 备份远程机器磁盘 ssh user@machine \u0026#34;dd if=/dev/sda | gzip -1 -\u0026#34; | dd of=backup.gz Reference https://www.shellscript.sh https://www.computerhope.com https://securitytrails.com\n","permalink":"https://blog.fangjiahui.me/posts/2021-01-20-bash-shell-cheat-sheet/","summary":"BASH SHELL cheat sheet 记录一些 bash shell 脚本的奇技淫巧，都是从实际使用中 google 的。bash 各 Linux 发行版都自带方便好用特别是文本处理、一些运维之类的小脚本，但有些语法繁琐不好记容易忘整理一下方便查找。\ntrap trap 命令 用于指定在接收到信号后将要采取的动作，常见的用途是在脚本程序被中断时完成清理工作。当 shell 接收到 sigspec 指定的信号时，arg 参数（命令）将会被读取，并被执行。例如：\ntrap \u0026#34;exit 1\u0026#34; HUP INT PIPE QUIT TERM 表示当 shell 收到HUP,INT,PIPE,QUIT,TERM这几个信号时，当前执行的程序会读取参数\u0026quot;exit 1\u0026quot;，并将它作为命令执行。\n如果要忽略某个信号就参数使用单引号就可以''\ntrap \u0026#39;\u0026#39; signals 如果启动的时候忽略了信号比如使用了nohup，trap 命令是无效的。具体信号可使用man 7 signal或者kill -l查阅\n$*、$@、$# 直接上例子看，如下脚本test.sh\necho 参数总个数 \\$#: $# echo 第0个参数 \\$0: $0 for a in $(seq 1 $#); do eval b=\\$$a echo 第\u0026#34;$a\u0026#34;个参数 \\$\u0026#34;$a\u0026#34;: $b done echo -e \u0026#34;\\nUsing \\\u0026#34;\\$#\\\u0026#34;:\u0026#34; echo \u0026#34;$#\u0026#34; echo -e \u0026#34;\\nUsing \\$#:\u0026#34; echo $# echo -e \u0026#34;\\nUsing \\\u0026#34;\\$*\\\u0026#34;:\u0026#34; for a in \u0026#34;$*\u0026#34;; do echo $a; done echo -e \u0026#34;\\nUsing \\$*:\u0026#34; for a in $*; do echo $a; done echo -e \u0026#34;\\nUsing \\\u0026#34;\\$@\\\u0026#34;:\u0026#34; for a in \u0026#34;$@\u0026#34;; do echo $a; done echo -e \u0026#34;\\nUsing \\$@:\u0026#34; for a in $@; do echo $a; done 然后运行此脚本，注意最后3 4用了双引号","title":"Bash备忘录"},{"content":"使用kubeadm在虚拟机本地搭建Kubernetes集群 本文使用ESXi创建3台ubuntu server 虚拟机搭建一个完整的Kubernetes集群，1台master主节点，2台worker做为工作节点。很多地址都是google的域名，安装下面一些环境可能需要科学上网，创建k8s集群需要如下包\ndocker \u0026ndash; 容器运行环境 kubelet \u0026ndash; Kubernets节点代理 kubeadm \u0026ndash; 部署多节点Kubernetes集群的工具 kubectl \u0026ndash; 用于和Kubernetes交互的命令行工具 会创建如下3台机器\n主机名 IP地址 角色 master.k8s 10.0.0.175 主节点 node1.k8s 10.0.0.176 工作节点1 node2.k8s 10.0.0.177 工作节点2 记一下安装时最新的版本号\nubuntu server 20.04.1 kernel version 5.4.0 kubernetes v1.20.0 docker-ce 19.03.14 创建虚拟机配置网址和安装docker 首先在ESXi控制台创建一台ubuntu server虚拟机，配置建议2CPU、2G RAM、20G硬盘，主机名为master.k8s开机更新到最新版本后重启安装docker，切换到root用户，以下所有操作都用root用户\n修改主机名\n# set hostname hostnamectl set-hostname master.k8s 然后修改/etc/hosts域名解析并添加之后两台的ip地址，如下\n10.0.0.175 master.k8s 10.0.0.176 node1.k8s 10.0.0.177 node2.k8s 配置主节点的网络修改/etc/netplan/00-installer-config.yaml如下，我这网卡是ens160\nnetwork: version: 2 renderer: networkd ethernets: ens160: # change your\u0026#39;s dhcp4: no addresses: [10.0.0.175/24] # change your\u0026#39;s gateway4: 10.0.0.1 # change your\u0026#39;s nameservers: addresses: [10.0.0.1] # change your\u0026#39;s 保存后运行\nnetplan apply 可以使用ip a查看修改情况，然后取消系统自带的systemd-resolved.service这个dns解析服务，是可选的\nsystemctl stop systemd-resolved.service systemctl disable systemd-resolved.service rm -rf /etc/resolv.conf echo \u0026#34;nameserver 10.0.0.1\u0026#34; \u0026gt; /etc/resolv.conf # change your\u0026#39;s 重启机器，确保网络畅通\n然后安装docker\napt-get update apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - add-apt-repository \\ \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\u0026#34; apt-get update apt-get install docker-ce docker-ce-cli containerd.io 安装好docker后需要配置下docker和containerd使得和kubelet兼容，增加如下配置文件，使systemd为cgroup驱动\ncat \u0026gt; /etc/docker/daemon.json \u0026lt;\u0026lt;EOF { \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;], \u0026#34;log-driver\u0026#34;: \u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: { \u0026#34;max-size\u0026#34;: \u0026#34;100m\u0026#34; }, \u0026#34;storage-driver\u0026#34;: \u0026#34;overlay2\u0026#34; } EOF # Restart Docker systemctl daemon-reload systemctl restart docker # start on boot systemctl enable docker 配置containerd\ncat \u0026gt; /etc/modules-load.d/containerd.conf \u0026lt;\u0026lt;EOF overlay br_netfilter EOF modprobe overlay modprobe br_netfilter # Setup required sysctl params, these persist across reboots. cat \u0026gt; /etc/sysctl.d/99-kubernetes-cri.conf \u0026lt;\u0026lt;EOF net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-ip6tables = 1 EOF sysctl --system # Configure containerd mkdir -p /etc/containerd containerd config default \u0026gt; /etc/containerd/config.toml 修改/etc/containerd/config.toml中的systemd_cgroup = true使用systemd做为cgroup驱动，最后重启\nsystemctl restart containerd ##　安装 kubeadm, kubelet 和 kubectl\n＃ disable swap swapoff -a \u0026amp;\u0026amp; sed -i \u0026#39;/swap.img/ s/^/# /\u0026#39; /etc/fstab apt-get update \u0026amp;\u0026amp; sudo apt-get install -y apt-transport-https curl curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - cat \u0026lt;\u0026lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list deb https://apt.kubernetes.io/ kubernetes-xenial main EOF apt-get update apt-get install -y kubelet kubeadm kubectl apt-mark hold kubelet kubeadm kubectl # 以下是可选的是为了 kubectl 命令可以自动补全，ubuntu 20.04 已经安装了 bash-completion 不需要手动安装 # 在~/.bashrc下添加 source /usr/share/bash-completion/bash_completion # 运行 kubectl completion bash \u0026gt;/etc/bash_completion.d/kubectl 现在还没有运行kubeadm init所以当你查看systemctl status kubelet会显示启动失败，先不用管他，关机进行下一步克隆两台工作机\n克隆主机 在ESXi web 控制台 Storage \u0026gt; Datastore browser \u0026gt; Create directory 新建node1.k8s和node2.k8s两个文件夹用来存放两台worker机文件，然后将master.k8s文件夹中的master.k8s.vmdk和master.k8s.vmx复制到新建的两个worker文件夹，最后右击worker文件夹中的 master.k8s.vmx \u0026gt; Register VM ，返回主页修改主机名开机后选I Copied It，开机进入后和master一样要修改主机名和IP地址\n运行 kubeadm init 做好上面所有准备后把三台机器都开起来，master是10.0.0.175，worker两台分别为10.0.0.176、10.0.0.177，确保可以相互ping通，然后在master上运行kubeadm init创建Kubernetes control-plane，包括etcd数据库、API Server(与 kubectl 命令交互)等都是以容器的方式运行，第一次运行会拉取镜像可能需要一些时间取决于你的网络，完成后有类似如下的显示\n... Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 10.0.0.175:6443 --token hyq0wa.jdu1ihaf0r3pzemo \\ --discovery-token-ca-cert-hash sha256:90ec90f7a2698e19c3f026b7bc31d86a30a801d20fec7aa17dccfe70ec76e419 加入master节点 之前在kubeadm init提示有加入主节点的命令，分别在两台worker机上运行就行，如果之前没有记可以在master上运行kubeadm token create --print-join-command新生成\nkubeadm join 10.0.0.175:6443 --token vdib2x.qq73s0h8nq70x6er --discovery-token-ca-cert-hash sha256:90ec90f7a2698e19c3f026b7bc31d86a30a801d20fec7aa17dccfe70ec76e419 在两台worker机上运行后 去master节点查看\nexport KUBECONFIG=/etc/kubernetes/admin.conf kubectl get nodes NAME STATUS ROLES AGE VERSION master.k8s NotReady control-plane,master 12s v1.20.0 node1.k8s NotReady \u0026lt;none\u0026gt; 12s v1.20.0 node2.k8s NotReady \u0026lt;none\u0026gt; 12s v1.20.0 有如上输出代表加入master成功，但仔细看会发现他们的状态都是NotReady，那是因为容器网络插件(CNI)还没有安装，接下来安装网络插件我们使用Weaveworks ，在master运行\nkubectl apply -f \u0026#34;https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d \u0026#39;\\n\u0026#39;)\u0026#34; 之后再查看状态就会变成Ready了，到此为止一个两个node节点一个master的本地集群就搭建完成了\n如果需要在另外的机器使用集群 那把/etc/kubernetes/admin.conf复制到机器然后设置KUBECONFIG环境变量即可\nReference https://kubernetes.io/docs/setup/production-environment/container-runtimes/\nhttps://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\nhttps://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/\nhttps://www.weave.works/docs/net/latest/kubernetes/kube-addon/#-installation\n","permalink":"https://blog.fangjiahui.me/posts/2020-12-23-creating-a-kubernetes-cluster-with-kubeadm/","summary":"使用kubeadm在虚拟机本地搭建Kubernetes集群 本文使用ESXi创建3台ubuntu server 虚拟机搭建一个完整的Kubernetes集群，1台master主节点，2台worker做为工作节点。很多地址都是google的域名，安装下面一些环境可能需要科学上网，创建k8s集群需要如下包\ndocker \u0026ndash; 容器运行环境 kubelet \u0026ndash; Kubernets节点代理 kubeadm \u0026ndash; 部署多节点Kubernetes集群的工具 kubectl \u0026ndash; 用于和Kubernetes交互的命令行工具 会创建如下3台机器\n主机名 IP地址 角色 master.k8s 10.0.0.175 主节点 node1.k8s 10.0.0.176 工作节点1 node2.k8s 10.0.0.177 工作节点2 记一下安装时最新的版本号\nubuntu server 20.04.1 kernel version 5.4.0 kubernetes v1.20.0 docker-ce 19.03.14 创建虚拟机配置网址和安装docker 首先在ESXi控制台创建一台ubuntu server虚拟机，配置建议2CPU、2G RAM、20G硬盘，主机名为master.k8s开机更新到最新版本后重启安装docker，切换到root用户，以下所有操作都用root用户\n修改主机名\n# set hostname hostnamectl set-hostname master.k8s 然后修改/etc/hosts域名解析并添加之后两台的ip地址，如下\n10.0.0.175 master.k8s 10.0.0.176 node1.k8s 10.0.0.177 node2.k8s 配置主节点的网络修改/etc/netplan/00-installer-config.yaml如下，我这网卡是ens160\nnetwork: version: 2 renderer: networkd ethernets: ens160: # change your\u0026#39;s dhcp4: no addresses: [10.","title":"使用kubeadm在虚拟机本地搭建Kubernetes集群"},{"content":"正则表达式中的预查 有时候使用正则会用到非获取匹配，就是不进行存储供以后使用，也就是正则中的预查，预查分为正向预查(lookahead)和反向预查(lookbehind)。\n正向预查\n(?=pattern)正向肯定预查(Positive lookahead)。如Python(?=3)匹配Python后跟3的语句，如输入Python3但其中最后的3不算进结果，返回Python\n(?!pattern)正向否定预查(Negative lookahead)。和上面的类似只是否定的，Python(?!3)匹配后面不带3的句子，输入Python2，也是返回Python\n反向预查\n(?\u0026lt;=pattern)反向肯定预查(Positive lookbehind)。如(?\u0026lt;=2)Python其实和上面也差不多反向就是向左匹配就是匹配Python前面是2的语句，如输入2Python，返回Python\n(?\u0026lt;!pattern)反向否定预查(Negative lookbehind)。如(?\u0026lt;!3)Python匹配Python前面不是3的输入，如输入2Python，返回Python\n还有一个长的挺像的这里也记录下\n(?:pattern) 匹配pattern但不获取匹配结果。 (?:t|b)oy只匹配boy或者toy，和toy|boy一样但更简洁，当然如果使用(t|b)oy就会多一个group\n","permalink":"https://blog.fangjiahui.me/posts/2020-10-27-regular-expression-lookarounds/","summary":"正则表达式中的预查 有时候使用正则会用到非获取匹配，就是不进行存储供以后使用，也就是正则中的预查，预查分为正向预查(lookahead)和反向预查(lookbehind)。\n正向预查\n(?=pattern)正向肯定预查(Positive lookahead)。如Python(?=3)匹配Python后跟3的语句，如输入Python3但其中最后的3不算进结果，返回Python\n(?!pattern)正向否定预查(Negative lookahead)。和上面的类似只是否定的，Python(?!3)匹配后面不带3的句子，输入Python2，也是返回Python\n反向预查\n(?\u0026lt;=pattern)反向肯定预查(Positive lookbehind)。如(?\u0026lt;=2)Python其实和上面也差不多反向就是向左匹配就是匹配Python前面是2的语句，如输入2Python，返回Python\n(?\u0026lt;!pattern)反向否定预查(Negative lookbehind)。如(?\u0026lt;!3)Python匹配Python前面不是3的输入，如输入2Python，返回Python\n还有一个长的挺像的这里也记录下\n(?:pattern) 匹配pattern但不获取匹配结果。 (?:t|b)oy只匹配boy或者toy，和toy|boy一样但更简洁，当然如果使用(t|b)oy就会多一个group","title":"正则表达式中的预查"},{"content":"Bash 快捷操作 GUN Bash 是现代操作系统一般都默认自带的 Shell，它兼容 sh 并提供了更多的 feature，如果我们常用命令行那么记住一些快捷键和 trick 能大大提高我们的工作效率，这篇文章就介绍下本人常用的快捷键和一些技巧。\nBash 默认的是 emacs 模式，这里的快捷键以默认的为准，可以使用set -o命令查看，使用set -o emacs设置。\n移动光标 快捷键 描述 Ctrl + a 移动光标到行首 Ctrl + e 移动光标到行尾 Alt + b 移动光标后退一个单词（词首） Alt + f 移动光标前进一个单词（词首） Ctrl + f 光标前进一个字母 Ctrl + b 光标后退一个字母 Ctrl + xx 当前位置与行首之间光标切换 一般配合Ctrl的是单字符移动，Alt是单词为边界。建议将键盘上的caps lock键改成Ctrl这样手指移动距离更短按起来也更加舒服方便。\n剪切（删除）粘贴 快捷键 描述 Ctrl + k 剪切从光标到行尾 Ctrl + u 剪切从光标到行首 Ctrl + w 从光标向前剪切一个单词 Alt + Backspace 与 Ctrl + w 类似，但分隔符是一些特殊字符 Alt + d 从光标向后剪切一个单词 Ctrl + d 删除光标下一个字母，如果没有字符存在，ctrl+d 则会登出该会话 Ctrl + h 删除光标前一个字母 Alt + t swap(当前单词, 上一个单词) Ctrl + t swap(当前字母, 上一个字母) Ctrl + y 粘贴上一次剪切的文本，配合 Ctrl-u、Ctrl-k 效果极好 大小写转换 快捷键 描述 Alt + c 大写当前字母，并移动光标到单词尾 Alt + u 大写从当光标到单词尾 Alt + l 小写从当光标到单词尾 历史命令 快捷键 描述 Ctrl + r 向后搜索历史命令 Ctrl + g 退出搜索 Ctrl + p 历史中上一个命令，代替向上方向键 Ctrl + n 历史中下一个命令，代替乡下方向键 Alt + . 上一个命令的最后一个单词 终端指令 快捷键 描述 Ctrl + l 跳纸，换页，清屏 Ctrl + m 回车（Carriage return） Ctrl + s 停止输出（在 Zsh 中为向前搜索历史命令） Ctrl + q 继续输出 Ctrl + c 终止当前命令 Ctrl + z 挂起当前命令 Ctrl + d 结束输入（产生一个 EOF） Bang (!) 命令 快捷键 描述 !n 执行第 n 条命令 !-n 执行倒数第 n 条命令 !xx 执行最近的以 xx 开头的命令 !xx:p 和上面一样，但仅打印输出，而不执行命令 !! 执行上一条命令, 与 !-1 相同 !$ 上一条命令的最后一个参数，与 Alt + .和$_相同 !:n 上一条命令的第 n 个参数，索引从 0 开始 !* 上一条命令的所有参数 !:1-$ 上一条命令的所有参数同 !* 相同 !-n:$ 倒数第 n 条命令的最后一个参数 !$:h 上一条命令参数的上一级 !#:1 当前行的第 1 个参数 !!:gs/aa/bb/ 替换上一条命令中所有的 aa 为 bb ^blah 删除上一条命令中的 blah ^blah^foo 将上一条命令中的 blah 替换为 foo 执行之前输入过的命令 经常我们会遇到当输入比较长的命令时执行了时，提示需要 sudo 运行，这个时候下面的技巧就很有用了\nsudo !! 只需上面!!两个感叹号，就可代表上一次执行的命令，我们也可以使用sudo !-1代替效果是一样的，!-1代表倒数第一条命令，如果是正数!n那就是执行第 n 条命令，顺序可从history命令获取\n打印而不执行 如果我们只想测试可以在以!开头的命令后面加:p，这只会打印输出而不真正执行\nls -al !!:p # ls -al 如果想要执行打印出来的命令直接使用Ctrl + p或者向上箭头就可以了\n复用历史命令的各参数 有时我们输命令的时候最后一个参数和上一条命令相同，比较常见的是如下情况\nmkdir dirA # 创建文件夹dirA cd !$ # 进入创建的目录 mkdir dirA \u0026amp;\u0026amp; cd $_ # 或者使用$_在一行完成 !$表示上一条命令的最后一个参数（但我更喜欢用Alt + .快捷键），如果是倒数第二条那就是!-2:$，序列号写在:前。如果是第 n 个参数看如下例子\ntar -zcvf abc abc.tgz # 想打包abc为abc.tgz但参数顺序写反了，报No such file or directory tar -zcvf !:3 !:2 # 这就可以了 !:n代表上一条命令的第 n 个参数，注意 n 从 0 开始计数，例如!:0代表上一条 shell 的命令，全部参数用!*或者!:1-$表示\nmv a b !:1-$:p # 输出`a b`，或者使用`!*:p`结果一样，如果是用`!:0:p`会输出`mv` 上一级目录 当我们将文件a.txt移动并重命名/a/b/c.txt时，我们想进入/a/b目录查看文件，可以如下操作\nmv a.txt /a/b/c.txt cd !$:h echo a/b/c/d !-1:$:h:p # a/b/c 上面!$:h代表上一条命令最后一个参数的上一级主要是:h这个作用，!-1:$:h:p看起来很复杂其实是一样的代表倒数第一条命令最后一个参数的上一级目录并把它打印了出来\n顺便说下cd -和cd ~命令，cd -这是快速切换目录，代表马上切到上一次移动过来的目录，没用过的可以试试，使用起来超方便，cd ~是直接回到 home 目录\n当前行的参数 如果我们要复用当前输入行的参数咋办呢，可以用!#，比如备份配置文件cp a.conf a.conf.bak可以如下实现\ncp a.conf !#:1.bak 注意上面#后面不是注释的意思是一起的!#:1.bak，代表当前行第 1 个参数后面加.bak，其实备份可以不用这么麻烦，可以用更方便的，效果一样\ncp a.conf{,.bak} 替换 看下面的例子\necho cat cat cat !!:s/cat/dog/ # 替换首个出现的 cat 为 dog !!:gs/cat/dog/ # 把所有 cat 替换为 dog 替换主要使用:s/old/new/，如果要替换所有出现的就是:gs/old/new/\n!!:s/cat/dog/上面的替换还可以使用^cat^dog更加简单\n使用默认编辑器编辑长命令 在编辑长命令的时候可以按下 ctrl + x, ctrl + e 打开默认的 $EDITOR 编辑命令，编辑好后保存执行\n使用 Aliases alias命令可以轻松自定义属于自己的快捷命令，例如\nalias vi=\u0026#34;vim\u0026#34; alias ll=\u0026#34;ls -alFtr --color=auto\u0026#34; 上面自定义了vi使用vim，ll命令是ls命令的加了参数版。\n像上面的设置只在当前会话有用，想永久有效可以把命令加入~/.bashrc。\n自定义快捷键 Bash 支持自定义快捷键，使用bind命令就可以。Bash 快捷键其实是 GNU Readline 快捷键， GNU Readline Library 是一个来接受用户输入的 GNU 软件包。 它是包括 Bash 在内的绝大多数 Shell 的底层库， 甚至 OSX/Windows/Linux 下的绝大多数软件都采用与之兼容快捷键。快捷键的设置其实就是配置 Readline，Readline 中分两种快捷键，一种是 Readline 内部的函数快捷键，另外一种是执行 Shell 命令，设置的时候稍有不同：\nbind -l # 查看Readline中可以使用的内置函数名称 bind -v # 列出目前的按键配置与其功能 bind -p # 查看已经绑定的快捷键 # 自定义shell命令 bind -x \u0026#39;\u0026#34;\\C-x\\C-l\u0026#34;:ls -al\u0026#39; # 绑定自定义执行命令shell命令的快捷键, 绑定后，按[C-x,C-l]就能执行ls -al bind -X # 列出刚-x绑定的命令 # 自定义内置函数快捷键 bind \u0026#34;\\C-i\u0026#34;:backward-delete-char # 绑定内置函数backward-delete-char快捷键，现在可以使用\u0026#34;\\C-i\u0026#34;删除一个字符 bind -q backward-delete-char # 查询函数名称对应的快捷键，会发现多了一个刚才我们自定义的\u0026#34;\\C-i\u0026#34; 这种设置只是针对当前的会话有效，一旦会话丢失，这样设置的快捷键就会丢失，为了能够让设置的快捷键永久有效，我们就需要将快捷键的配置写入文件。在 Linux 系统中，能永久保存快捷键的地方有两个，全局和用户的配置文件，全局的是/etc/inputrc，而用户的是在用户的根目录下~/.inputrc，全局的会影响所有的用户，而用户根目录下的只会对相应的用户产生影响。\nReference www.codeceo.com mp.weixin.qq.com ","permalink":"https://blog.fangjiahui.me/posts/2020-07-14-bash-tip-and-tricks/","summary":"Bash 快捷操作 GUN Bash 是现代操作系统一般都默认自带的 Shell，它兼容 sh 并提供了更多的 feature，如果我们常用命令行那么记住一些快捷键和 trick 能大大提高我们的工作效率，这篇文章就介绍下本人常用的快捷键和一些技巧。\nBash 默认的是 emacs 模式，这里的快捷键以默认的为准，可以使用set -o命令查看，使用set -o emacs设置。\n移动光标 快捷键 描述 Ctrl + a 移动光标到行首 Ctrl + e 移动光标到行尾 Alt + b 移动光标后退一个单词（词首） Alt + f 移动光标前进一个单词（词首） Ctrl + f 光标前进一个字母 Ctrl + b 光标后退一个字母 Ctrl + xx 当前位置与行首之间光标切换 一般配合Ctrl的是单字符移动，Alt是单词为边界。建议将键盘上的caps lock键改成Ctrl这样手指移动距离更短按起来也更加舒服方便。\n剪切（删除）粘贴 快捷键 描述 Ctrl + k 剪切从光标到行尾 Ctrl + u 剪切从光标到行首 Ctrl + w 从光标向前剪切一个单词 Alt + Backspace 与 Ctrl + w 类似，但分隔符是一些特殊字符 Alt + d 从光标向后剪切一个单词 Ctrl + d 删除光标下一个字母，如果没有字符存在，ctrl+d 则会登出该会话 Ctrl + h 删除光标前一个字母 Alt + t swap(当前单词, 上一个单词) Ctrl + t swap(当前字母, 上一个字母) Ctrl + y 粘贴上一次剪切的文本，配合 Ctrl-u、Ctrl-k 效果极好 大小写转换 快捷键 描述 Alt + c 大写当前字母，并移动光标到单词尾 Alt + u 大写从当光标到单词尾 Alt + l 小写从当光标到单词尾 历史命令 快捷键 描述 Ctrl + r 向后搜索历史命令 Ctrl + g 退出搜索 Ctrl + p 历史中上一个命令，代替向上方向键 Ctrl + n 历史中下一个命令，代替乡下方向键 Alt + .","title":"Bash 快捷操作"},{"content":"UML 类图 统一建模语言（英语：Unified Modeling Language，缩写 UML）是非专利的第三代建模和规约语言。UML是一种开放的方法，用于说明、可视化、构建和编写一个正在开发的、面向对象的、软件密集系统的制品的开放方法。UML展现了一系列最佳工程实践，这些最佳实践在对大规模，复杂系统进行建模方面，特别是在软件架构层次已经被验证有效。\n以上是维基百科上对UML的定义，它定义了很多的图，本文主要介绍类图，是属于结构性图形中的静态图，本文所有图是通过OmniGraffle画的。\n结构性图形（Structure diagrams）强调的是系统式的建模：\n静态图（static diagram） 类图 对象图 包图 实现图（implementation diagram） 组件图 部署图 剖面图 复合结构图 行为式图形（Behavior diagrams）强调系统模型中触发的事件：\n活动图 状态图 用例图 交互性图形（Interaction diagrams），属于行为图形的子集合，强调系统模型中的资料流程：\n通信图 交互概述图（UML 2.0） 时序图（UML 2.0） 时间图（UML 2.0） 定义 UML类图是描述类的内部结构（属性, 方法等）和类与类之间的关系（泛化, 实现，组合, 聚合，关联，依赖），是一种静态结构图。是在面向对象程序设计中建模的常用方法，不仅是系统编码和测试的重要模型，以图的形式展示还可以简化人们对系统的理解。\n格式 一般是用三层矩形框表示，第一层表示类的名称，第二层表示的是字段和属性，第三层则是类的方法，如果某一层没有则可以省略。第一层中，如果是抽象类，名称需用斜体显示。\n属性和方法前面的符号（+、#、-等）代表可见性\nPublic(+) Protected(#) Private(-) Package(~) 第二层属性的格式是\n可见性 名称 : 类型 [= 默认值]\n第三层方法的格式是\n可见性 名称(参数类型 参数, \u0026hellip;) : 返回类型\n类与类之间的关系 类图中类与类之间的关系主要由：继承、实现、依赖、关联、聚合、组合这六大类型。表示方式如下图：\n泛化（generalization/extens） 泛化又称继承，是IS-A的关系，两个对象之间如果可以用IS-A来表示，就是继承关系：（..是..)\n泛化关系用一条带空心箭头的实线表示；如下图表示（猫继承自动物）猫是（IS-A）动物\n实现（realization/implements) 实现关系指的是一个class类实现interface接口（可以是多个）的功能，在Java中可以直接用关键字implements表示，在C++中目标类可用抽象类表示\n实现关系用一条带空心箭头的虚线表示；如下图自行车必须实现车这个抽象类 注意这个车类是斜体代表抽象类\n各种关系的强弱顺序： 泛化 = 实现 \u0026gt; 组合 \u0026gt; 聚合 \u0026gt; 关联 \u0026gt; 依赖\n聚合（aggregation） 聚合关系是整体与部分的关系即HAS-A关系，整体和部分不是强依赖的可以单独存在，此时整体与部分之间是可分离的，他们可以具有各自的生命周期，部分可以属于多个整体对象，也可以为多个整体对象共享，例如公司的部门和员工，即使公司不存在了员工还是存在的。\n聚合关系用一条带空心菱形箭头的实线表示，如下所示部门HAS-A员工\n组合（composition） 组合关系也是整体与部分的关系，但部分不能离开整体而单独存在，整体的生命周期结束也就意味着部分的生命周期结束，他体现的是一种CONTAINS-A的关系。如公司和部门是整体和部分的关系，没有公司就不存在部门。组合关系是一种比聚合更强的关系。\n组合关系用一条带实心菱形箭头的实线表示，如下表示公司CONTAINS-A部门\n依赖（dependency） 依赖关系是一种临时性的关系，通常在运行期间产生，并且随着运行时的变化，可以简单的理解，就是一个类A使用到了另一个类B，而这种使用关系是具有偶然性的、临时性的、非常弱的，但是B类的变化会影响到A。例如程序员依赖电脑工作。\n依赖关系是用一条带箭头的虚线表示，依赖有方向如下程序员依赖电脑，也可以是双向的把箭头去掉，双向依赖是一种非常糟糕的结构，我们总是应该保持单向依赖，杜绝双向依赖的产生\n关联（association） 关联关系是两个类语义级别的一种强依赖关系，这种关系比依赖更强、不存在依赖关系的偶然性、关系也不是临时性的，一般是长期性的，而且双方的关系一般是平等的、关联可以是单向、双向的；表现在代码层面，为被关联类B以类属性或方法的形式出现在关联类A中，也可能是关联类A引用了一个类型为被关联类B的全局变量；\n关联关系是用一条带箭头的实线线表示，如下Person和Cat就是关联关系\n实例 下面看一个实例\nDog和Animal是泛化（继承）关系 Dog和Person是关联关系，Dog的主人是Person，他们是长期的关系 Bike和Vehicle是实现关系，Vehicle是斜体表示abstract Person和Bike是依赖关系，Person依赖Bike是非常弱的关系 School和Class是组合关系，班级离不开学校 Person和Class是聚合关系，学生和班级是互相独立的 Reference zh.wikipedia.org juejin.im design-patterns.readthedocs.io ","permalink":"https://blog.fangjiahui.me/posts/2020-07-09-uml-class-diagram/","summary":"UML 类图 统一建模语言（英语：Unified Modeling Language，缩写 UML）是非专利的第三代建模和规约语言。UML是一种开放的方法，用于说明、可视化、构建和编写一个正在开发的、面向对象的、软件密集系统的制品的开放方法。UML展现了一系列最佳工程实践，这些最佳实践在对大规模，复杂系统进行建模方面，特别是在软件架构层次已经被验证有效。\n以上是维基百科上对UML的定义，它定义了很多的图，本文主要介绍类图，是属于结构性图形中的静态图，本文所有图是通过OmniGraffle画的。\n结构性图形（Structure diagrams）强调的是系统式的建模：\n静态图（static diagram） 类图 对象图 包图 实现图（implementation diagram） 组件图 部署图 剖面图 复合结构图 行为式图形（Behavior diagrams）强调系统模型中触发的事件：\n活动图 状态图 用例图 交互性图形（Interaction diagrams），属于行为图形的子集合，强调系统模型中的资料流程：\n通信图 交互概述图（UML 2.0） 时序图（UML 2.0） 时间图（UML 2.0） 定义 UML类图是描述类的内部结构（属性, 方法等）和类与类之间的关系（泛化, 实现，组合, 聚合，关联，依赖），是一种静态结构图。是在面向对象程序设计中建模的常用方法，不仅是系统编码和测试的重要模型，以图的形式展示还可以简化人们对系统的理解。\n格式 一般是用三层矩形框表示，第一层表示类的名称，第二层表示的是字段和属性，第三层则是类的方法，如果某一层没有则可以省略。第一层中，如果是抽象类，名称需用斜体显示。\n属性和方法前面的符号（+、#、-等）代表可见性\nPublic(+) Protected(#) Private(-) Package(~) 第二层属性的格式是\n可见性 名称 : 类型 [= 默认值]\n第三层方法的格式是\n可见性 名称(参数类型 参数, \u0026hellip;) : 返回类型\n类与类之间的关系 类图中类与类之间的关系主要由：继承、实现、依赖、关联、聚合、组合这六大类型。表示方式如下图：\n泛化（generalization/extens） 泛化又称继承，是IS-A的关系，两个对象之间如果可以用IS-A来表示，就是继承关系：（..是..)\n泛化关系用一条带空心箭头的实线表示；如下图表示（猫继承自动物）猫是（IS-A）动物\n实现（realization/implements) 实现关系指的是一个class类实现interface接口（可以是多个）的功能，在Java中可以直接用关键字implements表示，在C++中目标类可用抽象类表示\n实现关系用一条带空心箭头的虚线表示；如下图自行车必须实现车这个抽象类 注意这个车类是斜体代表抽象类\n各种关系的强弱顺序： 泛化 = 实现 \u0026gt; 组合 \u0026gt; 聚合 \u0026gt; 关联 \u0026gt; 依赖","title":"UML 类图"},{"content":"Flask项目中集成Celery Celery是一个简单高效的实时分布式任务队列系统，我们可以将一些耗时比较长或者计算密集的任务交给celery处理，它也支持定时任务类似于crontab。而web应用中可以将一些任务丢给celery异步处理，比如发邮件消息推送、模型推理等。简单的Flask应用集成Celery比简单，有官方文档可做参考，可较复杂的flask应用如使用了蓝图(blueprint)分了很多模块的怎么组织celery和各种任务就比较复杂官方也没有说明文档，一不小心就会陷入循环导入。下面就介绍一种celery集成方法。\n官方文档demo中有一个make_celery的函数\ndef make_celery(app): celery = Celery( app.import_name, backend=app.config[\u0026#39;CELERY_RESULT_BACKEND\u0026#39;], broker=app.config[\u0026#39;CELERY_BROKER_URL\u0026#39;] ) celery.conf.update(app.config) class ContextTask(celery.Task): def __call__(self, *args, **kwargs): with app.app_context(): return self.run(*args, **kwargs) celery.Task = ContextTask return celery 这个函数主要用来创建Celery对象，并从flask上更新一些配置加入上下文环境，像文档上单文件是不会出问题的返回的celery对象直接在下面定义任务，然后集成到路由中。如果你flask app是使用app factories和蓝图(blueprint)，那在这里定义的task又怎么在路由中引用呢，这就会导致循环引用问题。\n我们可以把make_celery拆开来，首先创建celery对象然后等flask app初始化完成后在更新配置，这就解决问题了，任务单独放在tasks.py文件中也便于管理和查看\n先来看最终项目结构图，就是flask web项目加入了celery\nflask-celery-demo ├── app │ ├── api │ │ ├── __init__.py │ │ └── views.py # 视图 │ ├── __init__.py │ └── tasks.py # celery任务 ├── config.py ├── requirements.txt ├── run.sh └── service.py # 应用入口 先解释下主要service.py创建celery对象，然后把对象传入app/__init__.py文件中的create_app函数在里面更新celery配置。app/tasks.py单独存放给celery的任务，视图函数也可以方便导入。下面一个个文件说明\n先来看service.py文件也是整个应用的主入口\nfrom app import create_app def make_celery(app_name): broker = getattr(config[os.getenv(\u0026#39;FLASK_ENV\u0026#39;) or \u0026#39;default\u0026#39;], \u0026#34;CELERY_BROKER_URL\u0026#34;) backend = getattr(config[os.getenv(\u0026#39;FLASK_ENV\u0026#39;) or \u0026#39;default\u0026#39;], \u0026#34;CELERY_BACKEND_URL\u0026#34;) celery = Celery( app_name, broker=broker, backend=backend ) return celery # share celery object my_celery = make_celery(__name__) flask_app = create_app(os.getenv(\u0026#39;FLASK_ENV\u0026#39;) or \u0026#39;default\u0026#39;, celery=my_celery) 这里的make_celery函数只返回celery对象未更新配置，供tasks.py导入，并传给create_app，接下来看app/__init__.py文件\ndef create_app(config_name, **kwargs): app = Flask(__name__) app.config.from_object(config[config_name]) config[config_name].init_app(app) # initial celery if kwargs.get(\u0026#39;celery\u0026#39;): init_celery(kwargs[\u0026#39;celery\u0026#39;], app) from .api import api as api_blueprint app.register_blueprint(api_blueprint, url_prefix=\u0026#39;/api/v1\u0026#39;) return app def init_celery(celery: Celery, app: Flask) -\u0026gt; None: \u0026#34;\u0026#34;\u0026#34; initial celery object wraps the task execution in an application context \u0026#34;\u0026#34;\u0026#34; celery.conf.update(app.config) class ContextTask(celery.Task): def __call__(self, *args, **kwargs): with app.app_context(): return self.run(*args, **kwargs) celery.Task = ContextTask init_celery函数就是最上面官方文档中make_celery中剩下的部分，用于更新配置加入上下文， create_app函数已经很熟悉了不多做介绍，只增加了一个celery参数在里面调用init_celery初始化celery对象\n然后看tasks.py\nfrom service import my_celery as celery @celery.task() def log(message: Any) -\u0026gt; Any: return message 这个文件单独定义各celery任务，最后看视图函数怎么调用app/api/views.py文件\nfrom app.tasks import log @api.route(\u0026#34;/hello-world\u0026#34;) def hello_world(): result = log.delay(\u0026#39;hello world\u0026#39;) try: r = result.get(timeout=3) except TimeoutError: r = \u0026#39;celery run failed\u0026#39; return jsonify({\u0026#34;info\u0026#34;: r}) 以上就是所有需要注意的地方了，整套代码托管在github可查阅\n运行demo 本示例中包含了docker文件，可以在docker环境方便的启动\n首先clone项目，docker-compose启动就可以\ngit clone https://github.com/fangjh13/flask-celery-demo.git docker-compose build docker-compose up 这里消息代理使用的是redis在config.py中配置，还写了个定时任务也在config.py中启动后每隔1分钟有输出信息，docker-compose会启动四个容器分别是flask服务、celery worker、celery beat和redis服务。当然也可以启动多个celery worker如\ndocker-compose up --scale worker=2 Reference flask.palletsprojects.com medium.com ","permalink":"https://blog.fangjiahui.me/posts/2020-05-24-flask-celery-integrated/","summary":"Flask项目中集成Celery Celery是一个简单高效的实时分布式任务队列系统，我们可以将一些耗时比较长或者计算密集的任务交给celery处理，它也支持定时任务类似于crontab。而web应用中可以将一些任务丢给celery异步处理，比如发邮件消息推送、模型推理等。简单的Flask应用集成Celery比简单，有官方文档可做参考，可较复杂的flask应用如使用了蓝图(blueprint)分了很多模块的怎么组织celery和各种任务就比较复杂官方也没有说明文档，一不小心就会陷入循环导入。下面就介绍一种celery集成方法。\n官方文档demo中有一个make_celery的函数\ndef make_celery(app): celery = Celery( app.import_name, backend=app.config[\u0026#39;CELERY_RESULT_BACKEND\u0026#39;], broker=app.config[\u0026#39;CELERY_BROKER_URL\u0026#39;] ) celery.conf.update(app.config) class ContextTask(celery.Task): def __call__(self, *args, **kwargs): with app.app_context(): return self.run(*args, **kwargs) celery.Task = ContextTask return celery 这个函数主要用来创建Celery对象，并从flask上更新一些配置加入上下文环境，像文档上单文件是不会出问题的返回的celery对象直接在下面定义任务，然后集成到路由中。如果你flask app是使用app factories和蓝图(blueprint)，那在这里定义的task又怎么在路由中引用呢，这就会导致循环引用问题。\n我们可以把make_celery拆开来，首先创建celery对象然后等flask app初始化完成后在更新配置，这就解决问题了，任务单独放在tasks.py文件中也便于管理和查看\n先来看最终项目结构图，就是flask web项目加入了celery\nflask-celery-demo ├── app │ ├── api │ │ ├── __init__.py │ │ └── views.py # 视图 │ ├── __init__.py │ └── tasks.py # celery任务 ├── config.py ├── requirements.txt ├── run.sh └── service.py # 应用入口 先解释下主要service.","title":"Flask项目中集成Celery"},{"content":"TCP连接和各状态浅析 TCP协议中三次握手连接和四次挥手断开和其中的状态变化\nTCP(Transmission Control Protocol)协议在OSI模型中属于传输层的协议(第4层)也是最常用的互联网协议，与UDP相比它是一种可靠的传输协议，建立和断开连接中一共有11种可能发生的状态(states)。\nLinux系统中可以用ss -nat命令查看所有TCP连接情况如果是旧的系统没有此命令可以使用netstat代替只是输出格式不一致，统计当前所有TCP状态可以加管道实现 ss -nat | awk 'NR\u0026gt;1 { d[$1]++ } END { for (i in d) print i, d[i] }'\n建立连接(三次握手） TCP是面向连接的所以传输双方在传输前要建立一条连接后才能通信，建立连接后TCP协议提供全双⼯(就是可以同时发送和接收不影响)的通信服务。建立连接的过程我们给它取了个生动的名字叫“三次握手”，因为从发起到建立连接一共有三个步骤也就是双方会发三个包，先看下面的图\n首先客户端发送SYN(Synchronous)包到服务端告诉服务器开始建立连接，包里面会包含一个随机数(j)序列号(Sequence Number)，此时客户端进入SYC-SENT状态。当然最初服务器是处于LISTEN状态监听某一个端口，本文图片以绿底黑框的都代表TCP状态。 服务端收到SYN发送应答SYN-ACK(Acknowledgement)携带确认号码(Acknowledge Number)为收到的序列号+1也就是j+1，加上一个自己的SYC序列号随机数(k)，服务端把状态置为SYN-RECEIVED 客户端收到SYN-ACK包并发送确认号码k+1，此时客户端的状态为ESTABLISHED，服务器收到ACK后状态也变为ESTABLISHED 以下是wireshake抓包后TCP连接的三次握手，这里序列号码j和k都为0。\nTCP A (port 65525) TCP B (port 443) LISTEN (Start) 1. SYN-SENT --\u0026gt; \u0026lt;SEQ=0\u0026gt;\u0026lt;CTL=SYN\u0026gt; --\u0026gt; SYN-RECEIVE 2. ESTABLISHED \u0026lt;-- \u0026lt;SEQ=0\u0026gt;\u0026lt;ACK=1\u0026gt;\u0026lt;CTL=SYN,ACK\u0026gt; \u0026lt;-- SYN-RECEIVE 3. ESTABLISHED --\u0026gt; \u0026lt;SEQ=1\u0026gt;\u0026lt;ACK=1\u0026gt;\u0026lt;CTL=ACK\u0026gt; --\u0026lt; ESTABLISHED 断开连接(四次挥手) 断开连接称为“挥手”一共有四步每一方向占两步，由于TCP是全双工的所以关闭连接需要双方都完成关闭(close)才算结束，其中会涉及状态也就比握手多。客户端和服务端都可以发起挥手动作，先发送FIN包的动作叫主动关闭(active close)然后另一方回应ACK包叫执行被动关闭(passive colse)，双方各完成一次主动和被动关闭一共四次。\n客户端数据传输完毕发起断开连接(主动关闭)，发送FIN包携带一个序列号(x)到服务端并更新自己的状态为FIN-WAIT-1 服务端收到FIN包返回ACK包(被动关闭)，应答ACK确认序号为x+1，服务端此时的状态为CLOSE-WAIT。另一边客户端收到ACK更新状态为FIN-WAIT-2 服务端准备执行断开连接(主动关闭)，此时服务端的状态还是CLOSE-WAIT，发送FIN包携带序列号(y)到客户端更新服务端状态为LAST-ACK，客户端收到FIN包后状态变为TIME-WAIT。 客户端收到FIN应答ACK(被动关闭)携带确认序号为y+1，服务端收到ACK立即关闭连接状态变为CLOSED 因为客户端最后不知道服务端有没有收到ACK包，所以默认等待两倍的MSL(Maximum Segment Lifetime)，Linux上MSL一般为60s，等待120s使服务器如果没有收到ACK也能重传FIN包，最后把自己的状态置为CLOSED在此之前的MSL时间中一直是TIME-WAIT状态 看一个现实中的例子ssh连接退出\nTCP A (port 49612) TCP B (port 22) 1. ESTABLISHED ESTABLISHED 2. (Close) FIN-WAIT-1 --\u0026gt; \u0026lt;SEQ=277\u0026gt;\u0026lt;ACK=401\u0026gt;\u0026lt;CTL=FIN,ACK\u0026gt; --\u0026gt; CLOSE-WAIT 3. FIN-WAIT-2 \u0026lt;-- \u0026lt;SEQ=401\u0026gt;\u0026lt;ACK=278\u0026gt;\u0026lt;CTL=ACK\u0026gt; \u0026lt;-- CLOSE-WAIT 4. (Close) TIME-WAIT \u0026lt;-- \u0026lt;SEQ=401\u0026gt;\u0026lt;ACK=278\u0026gt;\u0026lt;CTL=FIN,ACK\u0026gt; \u0026lt;-- LAST-ACK 5. TIME-WAIT --\u0026gt; \u0026lt;SEQ=278\u0026gt;\u0026lt;ACK=402\u0026gt;\u0026lt;CTL=ACK\u0026gt; --\u0026lt; CLOSED 6. (2 MSL) CLOSED TCP状态迁移图 TCP一共有11种状态，虚线箭头表示客户端状态转换轨迹，实线表示服务端，但这里的客户端和服务端不是绝对的可以互换。\nCLOSING状态 仔细看你会发现有一个CLOSING状态有些陌生，因为以上介绍的三次握手和四次挥手都是正常且顺序连接或断开中TCP状态，现实应用中比较复杂上面还有一个状态没有涉及到就是CLOSING\n从上面状态转换图中可看到CLOSING状态发生的情况是在首先发起挥手的一方(比如说客户端)正常如上图在FIN-WAIT-1后会进入FIN-WAIT-2，可进入FIN-WAIT-2是有条件的那就是收到第一次发FIN后服务端返回的ACK，可此时客户端没有收到ACK反而收到了服务端的FIN包，按上面讲的这就乱序了，这种特殊情况就是CLOSING状态，也就是说进入CLOSING有下面三个条件\n主动关闭发送FIN包发起后(此时是FIN-WAIT-1) 没有收到另一方的ACK包等待中 收到另一方发送过来的 FIN包 状态表 现在对所有状态做个总结\nTCP connection state Description LISTEN SOCKET监听中等待远程连接 SYN-SENT 发送连接请求SYN包后等待SYN-ACK包，第一次握手 SYN-RECEIVED 连接收到SYN包到并返回SYN-ACK包等待远端ACK，第二次握手 ESTABLISHED 连接已经建立，双方可以传输数据了,第三次握手 FIN-WAIT-1 发起主动关闭发送FIN包后等待ACK包,第一次挥手，另一方一般很快返回很少见到 CLOSE-WAIT 被动关闭收到对方FIN包，返回发送ACK包，在没有发起主动关闭之前一直使这个状态，第二次挥手 FIN-WAIT-2 收到发起主动关闭返回的ACK包，等待对方发送FIN包，现在只能接收数据不能发送数据，也叫半关闭状态，持续时间短，第二次挥手 LAST-ACK 进行一次被动关闭后，发起主动关闭等待ACK，第三次挥手 TIME-WAIT 主动关闭执行后，收到FIN包(第三次挥手)，并返回ACK(第四次挥手) 等待两倍的MSL之后进入CLOSED CLOSING 见上面 CLOSED 连接关闭没有连接 Reference www.ibm.com community.apigee.com blog.confirm.ch blog.csdn.net ","permalink":"https://blog.fangjiahui.me/posts/2020-02-13-tcp-handshake-process-and-state-trainsition/","summary":"TCP连接和各状态浅析 TCP协议中三次握手连接和四次挥手断开和其中的状态变化\nTCP(Transmission Control Protocol)协议在OSI模型中属于传输层的协议(第4层)也是最常用的互联网协议，与UDP相比它是一种可靠的传输协议，建立和断开连接中一共有11种可能发生的状态(states)。\nLinux系统中可以用ss -nat命令查看所有TCP连接情况如果是旧的系统没有此命令可以使用netstat代替只是输出格式不一致，统计当前所有TCP状态可以加管道实现 ss -nat | awk 'NR\u0026gt;1 { d[$1]++ } END { for (i in d) print i, d[i] }'\n建立连接(三次握手） TCP是面向连接的所以传输双方在传输前要建立一条连接后才能通信，建立连接后TCP协议提供全双⼯(就是可以同时发送和接收不影响)的通信服务。建立连接的过程我们给它取了个生动的名字叫“三次握手”，因为从发起到建立连接一共有三个步骤也就是双方会发三个包，先看下面的图\n首先客户端发送SYN(Synchronous)包到服务端告诉服务器开始建立连接，包里面会包含一个随机数(j)序列号(Sequence Number)，此时客户端进入SYC-SENT状态。当然最初服务器是处于LISTEN状态监听某一个端口，本文图片以绿底黑框的都代表TCP状态。 服务端收到SYN发送应答SYN-ACK(Acknowledgement)携带确认号码(Acknowledge Number)为收到的序列号+1也就是j+1，加上一个自己的SYC序列号随机数(k)，服务端把状态置为SYN-RECEIVED 客户端收到SYN-ACK包并发送确认号码k+1，此时客户端的状态为ESTABLISHED，服务器收到ACK后状态也变为ESTABLISHED 以下是wireshake抓包后TCP连接的三次握手，这里序列号码j和k都为0。\nTCP A (port 65525) TCP B (port 443) LISTEN (Start) 1. SYN-SENT --\u0026gt; \u0026lt;SEQ=0\u0026gt;\u0026lt;CTL=SYN\u0026gt; --\u0026gt; SYN-RECEIVE 2. ESTABLISHED \u0026lt;-- \u0026lt;SEQ=0\u0026gt;\u0026lt;ACK=1\u0026gt;\u0026lt;CTL=SYN,ACK\u0026gt; \u0026lt;-- SYN-RECEIVE 3. ESTABLISHED --\u0026gt; \u0026lt;SEQ=1\u0026gt;\u0026lt;ACK=1\u0026gt;\u0026lt;CTL=ACK\u0026gt; --\u0026lt; ESTABLISHED 断开连接(四次挥手) 断开连接称为“挥手”一共有四步每一方向占两步，由于TCP是全双工的所以关闭连接需要双方都完成关闭(close)才算结束，其中会涉及状态也就比握手多。客户端和服务端都可以发起挥手动作，先发送FIN包的动作叫主动关闭(active close)然后另一方回应ACK包叫执行被动关闭(passive colse)，双方各完成一次主动和被动关闭一共四次。\n客户端数据传输完毕发起断开连接(主动关闭)，发送FIN包携带一个序列号(x)到服务端并更新自己的状态为FIN-WAIT-1 服务端收到FIN包返回ACK包(被动关闭)，应答ACK确认序号为x+1，服务端此时的状态为CLOSE-WAIT。另一边客户端收到ACK更新状态为FIN-WAIT-2 服务端准备执行断开连接(主动关闭)，此时服务端的状态还是CLOSE-WAIT，发送FIN包携带序列号(y)到客户端更新服务端状态为LAST-ACK，客户端收到FIN包后状态变为TIME-WAIT。 客户端收到FIN应答ACK(被动关闭)携带确认序号为y+1，服务端收到ACK立即关闭连接状态变为CLOSED 因为客户端最后不知道服务端有没有收到ACK包，所以默认等待两倍的MSL(Maximum Segment Lifetime)，Linux上MSL一般为60s，等待120s使服务器如果没有收到ACK也能重传FIN包，最后把自己的状态置为CLOSED在此之前的MSL时间中一直是TIME-WAIT状态 看一个现实中的例子ssh连接退出","title":"TCP连接和各状态浅析"},{"content":"通过谷歌gRPC部署线上机器学习模型 gRPC是谷歌开发的远程过程调用(RPC)系统，它使用HTTP/2通信，Protocol Buffer作为接口描述语言。分为服务端和客户端，跨平台不受语言限制。\n本文主要在http服务中(以下代码使用的是flask)，使用gPRC Python远程调用训练好的模型返回RESTful接口，机器学习模型是一个已训练好的人脸检测模型(mtcnn)作为演示。\n所有源码托管在github，可按需要查看获取，下文只列出部分主要的代码提供一些思路。\nProto定义 使用gRPC必须先使用protocol buffers定义序列化的结构包括各对象、服务等所有类型，之后通过grpcio-tools生成服务端和客户端可用的代码，使用proto3格式。首先定义存放图片的Image用于请求参数，也就是入参是一张图片\n// request image message Image { bytes raw_data = 1; int32 height = 2; int32 width = 3; string image_id = 4; MetaData _meta_data = 5; } message Image定义了单张图片的存放格式主要包括raw_data存放图片二进制，还有图片的长高和唯一id，_meta_data记录各种元数据具体实现可查看上面github源码infer.proto\n// each message Result message Result { Box box = 1; Landmarks landmarks = 2; double confidence = 3; } // return results message InferResults { string image_id = 1; MetaData _meta_data = 2; repeated Result results = 3; } message Result定义单张人脸格式每张人脸包括bounding box人脸框,landmarks5个点和置信度confidence，message InferResults定义了单张图上所有人脸和各种元数据。\n// run inference service Inference { rpc Predict (Image) returns (InferResults) {} } service Inference定义了一个最简单的服务，输入一张图片输出是包含所有人脸信息的InferResults，就像一个函数调用一样，gRPC还支持复杂的服务比如streaming。\nprotobuf的具体格式可以查看谷歌官网介绍\n定义完.proto文件后就可以生成客户端和服务端可用的接口了，需要安装grpcio-tools包。\npython3 -m grpc_tools.protoc \\ -I ./protos \\ --python_out=./protos \\ --grpc_python_out=./protos \\ ./protos/infer.proto 以上命令会生成infer_pb2.py和infer_pb2_grpc.py两个文件。\ninfer_pb2.py中包含了我们在proto文件中定义的所有以message开头的类型，每个都是一个python类 infer_pb2_grpc.py中包含了在proto文件中以service开头的类型，包括服务端需要引用...Servicer的类重写方法，下文重写了Predict方法，add_...Servicer_to_server也是在服务端需要添加服务到grpc.Server，...Stub类是客户端需要导入的类与服务端交互。 加载模型启动gRPC服务 服务端主要是继承上文生成的infer_pb2_grpc.py中的InferenceServicer重写在infer.proto中定义的Predict方法，返回指定的类型也就是InferResults。\nfrom protos.infer_pb2 import Point, Box, Landmarks, Result, InferResults from protos import infer_pb2_grpc class InferenceServicer(infer_pb2_grpc.InferenceServicer): \u0026#34;\u0026#34;\u0026#34; inference server \u0026#34;\u0026#34;\u0026#34; def __init__(self) -\u0026gt; None: self.detector = MTCNN() # init model def Predict(self, request, context): metadata = dict(context.invocation_metadata()) print(f\u0026#34;remote metada {list(metadata.items())}\u0026#34;) image = Image.open(BytesIO(request.raw_data)).convert(\u0026#39;RGB\u0026#39;) print(f\u0026#39;receive a image size {image.width}x{image.height}\u0026#39;) infer_result_list = self.detector.detect_faces(np.array(image)) return_results = InferResults(image_id=request.image_id) add_meta_data(return_results) for r in infer_result_list: x1, y1 = r[\u0026#39;box\u0026#39;][:2] x2, y2 = r[\u0026#39;box\u0026#39;][2] + x1, r[\u0026#39;box\u0026#39;][3] + y1 nose = r[\u0026#39;keypoints\u0026#39;][\u0026#39;nose\u0026#39;] mouth_right = r[\u0026#39;keypoints\u0026#39;][\u0026#39;mouth_right\u0026#39;] right_eye = r[\u0026#39;keypoints\u0026#39;][\u0026#39;right_eye\u0026#39;] left_eye = r[\u0026#39;keypoints\u0026#39;][\u0026#39;left_eye\u0026#39;] mouth_left = r[\u0026#39;keypoints\u0026#39;][\u0026#39;mouth_left\u0026#39;] return_results.results.append( Result(box=Box(up_left=Point(x=x1, y=y1), lower_right=Point(x=x2, y=y2)), landmarks=Landmarks( left_eye=Point(x=left_eye[0], y=left_eye[1]), right_eye=Point(x=right_eye[0], y=right_eye[1]), nose=Point(x=nose[0], y=nose[1]), mouth_left=Point(x=mouth_left[0], y=mouth_left[1]), mouth_right=Point(x=mouth_right[0], y=mouth_right[1]) ), confidence=r[\u0026#39;confidence\u0026#39;]) ) return return_results InferenceServicer类中__init__方法加载模型初始化，因为本文用的mtcnn有提供pip包使用tensorflow实现，就使用默认的模型，当然你也可以使用自己的权重文件。Predict方法主要进行推理返回proto格式的InferResult。\n最后一步就是启动服务端监听一个端口，客户端可以连接过来。\nserver = grpc.server(futures.ThreadPoolExecutor(max_workers=10)) server.add_insecure_port(\u0026#39;[::]:50051\u0026#39;) infer_pb2_grpc.add_InferenceServicer_to_server( InferenceServicer(), server) server.start() server.wait_for_termination() 服务端代码inference_server.py，之后启动即可。\npython3 inference_server.py PS: 本文tf使用的是cpu版本，你也可以用gpu版本加速\n使用gRPC客户端测试 客户端的代码简单许多构建Image对象给Stub调用即可，代码如下inference_client\nfrom protos.infer_pb2 import Point, Box, Landmarks, Result, InferResults from protos import infer_pb2_grp with open(\u0026#39;peoples.jpg\u0026#39;, \u0026#39;rb\u0026#39;) as f: raw_image = f.read() with grpc.insecure_channel(\u0026#39;localhost:50051\u0026#39;) as channel: stub = infer_pb2_grpc.InferenceStub(channel) im = infer_pb2.Image(raw_data=raw_image, image_id=\u0026#39;1111\u0026#39;) add_meta_data(im) print(stub.Predict(im)) 以上和服务端建立连接，传入Image，注意得到的结果也是proto格式的，可以使用MessageToJson和 MessageToDict转换成json或者dict，还有上面Image中没有传width和height两个属性但我们在proto中定义了，如果不传默认就是默认值如果没有指定认值那就按照不同类型指定，参看官方文档，只要不影响服务端处理使用默认值就没什么影响。\n服务端启动后，执行测试\npython3 inference_client.py gRPC服务使用多进程 想启动多个模型，也就是使用多进程，一开始以为把上面服务端futures.ThreadPoolExecutor改成futures.ProcessPoolExecutor就可以了，但事实没有这么简单，不信自己动手试试就知道。\ngoogle一番后找到了答案，有两种方法可以实现参考此issue。以下使用第一种即pre-fork + SO_REUSEPORT\ndef startGrpcServer(): server = grpc.server(futures.ThreadPoolExecutor(max_workers=5)) server.add_insecure_port(\u0026#39;[::]:50051\u0026#39;) infer_pb2_grpc.add_InferenceServicer_to_server(InferenceServer(), server) server.start() server.wait_for_termination() if __name__ == \u0026#39;__main__\u0026#39;: for i in range(3): p = multiprocessing.Process(target=startGrpcServer, args=()) p.start() inference_server_multiprocess.py启动三个进程，需要注意的是使用此方法需要编译安装grpcio,否者会报grpc._channel._InactiveRpcError错，之后以上面相同的方式启动即可\npip install grpcio --no-binary grpcio 运行Flask服务 使用flask创建最简单的路由/predict\nfrom utils.label import ServiceClient, image_preprocess app = Flask(__name__) app.config[\u0026#39;predict\u0026#39;] = ServiceClient( infer_pb2_grpc, \u0026#39;InferenceStub\u0026#39;, \u0026#39;localhost\u0026#39;, 50051) @app.route(\u0026#39;/predict\u0026#39;, methods=[\u0026#34;POST\u0026#34;]) def predict(): res = {\u0026#34;message\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;results\u0026#34;: []} if request.json: req_dict = request.get_json() try: # convert image to protobuffer image = image_preprocess(req_dict) except Exception as e: current_app.logger.error(f\u0026#39;pre handler image error: {str(e)}\u0026#39;) res[\u0026#39;message\u0026#39;] = str(e) return jsonify(res) # put to predict try: remote_results = app.config[\u0026#39;predict\u0026#39;].Predict(image) res[\u0026#39;results\u0026#39;] = MessageToDict(remote_results)[\u0026#39;results\u0026#39;] except Exception as e: current_app.logger.error(e.details) res[\u0026#39;message\u0026#39;] = f\u0026#34;inference failed: {e.code()}\u0026#34; return jsonify(res) else: res[\u0026#39;message\u0026#39;] = \u0026#39;please post JSON format data\u0026#39; return jsonify(res) 上面只是在路由中使用gRPC调用，ServiceClient类定义了错误处理和超时处理方便调用，代码如下\nclass ServiceClient: \u0026#34;\u0026#34;\u0026#34; gRPC client wrapper, capture errror and can init call timeout \u0026#34;\u0026#34;\u0026#34; def __init__(self, module: infer_pb2_grpc, stub: str, host: str, port: int, timeout: int = 5) -\u0026gt; None: \u0026#34;\u0026#34;\u0026#34; :param module: module Generated by the gRPC Python protocol compiler :param stub: stub name \u0026#34;\u0026#34;\u0026#34; channel = grpc.insecure_channel(f\u0026#39;{host}:{port}\u0026#39;) try: grpc.channel_ready_future(channel).result(timeout=10) except grpc.FutureTimeoutError: sys.exit(f\u0026#39;Error connecting to {host}:{port} gRPC server, exit.\u0026#39;) self.stub = getattr(module, stub)(channel) self.timeout = timeout def __getattr__(self, attr): return partial(self._wrapped_call, self.stub, attr) # args[0]: stub, args[1]: function to call, args[3]: Request # kwargs: keyword arguments def _wrapped_call(self, *args, **kwargs): try: return getattr(args[0], args[1])( args[2], **kwargs, timeout=self.timeout ) except grpc.RpcError as e: print(\u0026#39;Call {0} failed with {1}\u0026#39;.format( args[1], e.code()) ) raise 以上代码在web_app.py和lable.py两个文件中，测试脚本在test_web.py中。\nReference medium.com\ngithub.com\n","permalink":"https://blog.fangjiahui.me/posts/2019-12-31-python-web-grpc-inference/","summary":"通过谷歌gRPC部署线上机器学习模型 gRPC是谷歌开发的远程过程调用(RPC)系统，它使用HTTP/2通信，Protocol Buffer作为接口描述语言。分为服务端和客户端，跨平台不受语言限制。\n本文主要在http服务中(以下代码使用的是flask)，使用gPRC Python远程调用训练好的模型返回RESTful接口，机器学习模型是一个已训练好的人脸检测模型(mtcnn)作为演示。\n所有源码托管在github，可按需要查看获取，下文只列出部分主要的代码提供一些思路。\nProto定义 使用gRPC必须先使用protocol buffers定义序列化的结构包括各对象、服务等所有类型，之后通过grpcio-tools生成服务端和客户端可用的代码，使用proto3格式。首先定义存放图片的Image用于请求参数，也就是入参是一张图片\n// request image message Image { bytes raw_data = 1; int32 height = 2; int32 width = 3; string image_id = 4; MetaData _meta_data = 5; } message Image定义了单张图片的存放格式主要包括raw_data存放图片二进制，还有图片的长高和唯一id，_meta_data记录各种元数据具体实现可查看上面github源码infer.proto\n// each message Result message Result { Box box = 1; Landmarks landmarks = 2; double confidence = 3; } // return results message InferResults { string image_id = 1; MetaData _meta_data = 2; repeated Result results = 3; } message Result定义单张人脸格式每张人脸包括bounding box人脸框,landmarks5个点和置信度confidence，message InferResults定义了单张图上所有人脸和各种元数据。","title":"通过谷歌gRPC部署线上机器学习模型"},{"content":"Python 描述符(descriptor) Python 中有一个很少被使用或者用户自定义的特性，那就是描述符(descriptor)，但它是@property, @classmethod, @staticmethod和super的底层实现机制，我今天就扒一扒它，官方文档对描述符的介绍如下\nIn general, a descriptor is an object attribute with “binding behavior”, one whose attribute access has been overridden by methods in the descriptor protocol: __get__(), __set__(), and __delete__(). If any of those methods are defined for an object, it is said to be a descriptor.\n描述符是绑定了行为的对象属性(object attribute)，实现了描述符协议(descriptor protocol)，描述符协议就是定义了__get__(),__set__(),__delete__()中的一个或者多个方法，将描述符对象作为其他对象的属性进行访问时，就会产生一些特殊的效果。\n上面的定义可能还是有些晦涩，一步步来\n默认查找属性 在没有描述符定义情况下，我们访问属性的顺序如下，以a.x为例\n查找实例字典里的属性就是a.__dict__['x']有就返回 往上查找父类的字典就是a.__class__.__dict__['x']有就返回 上面都没有就查找父类的基类(不包括元类(metaclass)) 如果定义了__getattr__就会返回此方法 最后都没有抛出AttributeError \u0026gt;\u0026gt;\u0026gt; class A: ... x = 8 ... ... \u0026gt;\u0026gt;\u0026gt; class B(A): ... pass ... \u0026gt;\u0026gt;\u0026gt; class C(B): ... def __getattr__(self, name): ... if name == \u0026#39;y\u0026#39;: ... print(\u0026#34;call getattr method\u0026#34;) ... else: ... raise AttributeError ... ... ... \u0026gt;\u0026gt;\u0026gt; C.__mro__ (\u0026lt;class \u0026#39;__main__.C\u0026#39;\u0026gt;, \u0026lt;class \u0026#39;__main__.B\u0026#39;\u0026gt;, \u0026lt;class \u0026#39;__main__.A\u0026#39;\u0026gt;, \u0026lt;class \u0026#39;object\u0026#39;\u0026gt;) \u0026gt;\u0026gt;\u0026gt; a = C() \u0026gt;\u0026gt;\u0026gt; a.x 8 \u0026gt;\u0026gt;\u0026gt; a.y call getattr method \u0026gt;\u0026gt;\u0026gt; a.__dict__ {} \u0026gt;\u0026gt;\u0026gt; a.x = 99 \u0026gt;\u0026gt;\u0026gt; a.x 99 \u0026gt;\u0026gt;\u0026gt; a.__dict__ {\u0026#39;x\u0026#39;: 99} __getattr__是实例访问没有定义的属性时调用的方法，需要特别定义\n描述符协议 object.__get__(self, instance, owner=None)\n在访问属性时被调用 self是描述符本身，instance是使用描述符的实例，owner是使用描述符的类。 这里调用要分为类属性的调用(调用owner上)和实例对象属性(instance上)的调用。当调用类属性的时候instance=None。 返回值或者AttributeError object.__set__(self, instance, value)\n在属性赋值时被调用 value为赋的值 无返回值 object.__delete__(self, instance)\n在属性被删除时调用 无返回值 object.__set_name__(self, owner, name)\n在owner类创建时被调用，给描述符命名，python3.6 新增 name为使用描述符的类的类属性的名字 无返回值 某个类只要定义了以上方法的一个或者多个就是实现了描述符协议，在作为某个对象属性时就是描述符，从而这个对象属性被重写默认的查找行为(上文所述)。描述符分数据描述符(data descriptors)和非数据描述符(non-data descriptors)，仅定义了__get__方法的叫非数据描述符，其它情况都是数据描述符，一般定义了__get__和__set__方法。数据描述符和非数据描述符对属性的查找顺序影响很大\n当访问访问属性时，如a.x，a为实例访问x属性，如果x是描述符就不再遵守默认的查找行为，看情况优先级如下\n如果a中的实例字典有同名的x描述符，且为数据描述符，则数据描述符优先访问 如果a中的实例字典有同名的x描述符，且为非数据描述符，则实例字典里面的优先访问 所以在有描述符的情况下实例属性的查找顺序：数据描述符 \u0026gt; 实例字典 \u0026gt; 非数据描述符\n描述符实例 有了上面的理论，我们来看实例\n数据描述符（Data Descriptors） class DataDescriptor: \u0026#34;\u0026#34;\u0026#34;A data descriptor that sets and returns values normally and prints a message logging their access. \u0026#34;\u0026#34;\u0026#34; def __init__(self, initval): self.initval = initval def __get__(self, instance, owner): print(f\u0026#34;get ... instance: {instance!r}, owner: {owner!r}\u0026#34;) return self.initval def __set__(self, instance, value): print(f\u0026#34;set ... instance: {instance!r}, value: {value!r}\u0026#34;) self.initval = value 以上DataDescriptor定义了__get__和__set__方法，当用作一个对象属性时就是一个数据描述符\n\u0026gt;\u0026gt;\u0026gt; class Person: ... age = DataDescriptor(10) ... ... \u0026gt;\u0026gt;\u0026gt; p = Person() \u0026gt;\u0026gt;\u0026gt; p.__dict__ {} \u0026gt;\u0026gt;\u0026gt; p.age get ... instance: \u0026lt;__main__.Person object at 0x110a68590\u0026gt;, owner: \u0026lt;class \u0026#39;__main__.Person\u0026#39;\u0026gt; 10 \u0026gt;\u0026gt;\u0026gt; p.age = 18 set ... instance: \u0026lt;__main__.Person object at 0x110a68590\u0026gt;, value: 18 \u0026gt;\u0026gt;\u0026gt; p.__dict__ {} \u0026gt;\u0026gt;\u0026gt; p.__dict__[\u0026#39;age\u0026#39;] = 100 \u0026gt;\u0026gt;\u0026gt; p.age get ... instance: \u0026lt;__main__.Person object at 0x110a68590\u0026gt;, owner: \u0026lt;class \u0026#39;__main__.Person\u0026#39;\u0026gt; 18 DataDescriptor(10)对象(age)就是一个数据描述符，根据上文的优先级实例字典是不会对它产生影响的所以p.age还是返回18\n需要注意的是描述符作用在对象属性(类属性)上才是描述符，也就是说不能定义在__init__方法下\n\u0026gt;\u0026gt;\u0026gt; class Person: ... age = DataDescriptor(10) ... ... def __init__(self): ... self.weight = DataDescriptor(50) ... ... ... \u0026gt;\u0026gt;\u0026gt; p = Person() \u0026gt;\u0026gt;\u0026gt; p.weight \u0026lt;__main__.DataDescriptor object at 0x1085a2250\u0026gt; 上面age是描述符，weight不是。访问p.weight属性只返回DataDescriptor的实例对象\n还有一个问题是age其实是一个类属性，Person的所有实例共享age这个实例变量，任何一个实例修改会导致所有的实例都更改。具体参看Python 中的类变量(class variables)和实例变量(instance variables)\n\u0026gt;\u0026gt;\u0026gt; class Person: ... age = DataDescriptor(10) ... ... \u0026gt;\u0026gt;\u0026gt; p1 = Person() \u0026gt;\u0026gt;\u0026gt; p2 = Person() \u0026gt;\u0026gt;\u0026gt; p1.age get ... instance: \u0026lt;__main__.Person object at 0x10817b090\u0026gt;, owner: \u0026lt;class \u0026#39;__main__.Person\u0026#39;\u0026gt; 10 \u0026gt;\u0026gt;\u0026gt; p2.age get ... instance: \u0026lt;__main__.Person object at 0x108159210\u0026gt;, owner: \u0026lt;class \u0026#39;__main__.Person\u0026#39;\u0026gt; 10 \u0026gt;\u0026gt;\u0026gt; p1.age = 18 set ... instance: \u0026lt;__main__.Person object at 0x10817b090\u0026gt;, value: 18 \u0026gt;\u0026gt;\u0026gt; p1.age get ... instance: \u0026lt;__main__.Person object at 0x10817b090\u0026gt;, owner: \u0026lt;class \u0026#39;__main__.Person\u0026#39;\u0026gt; 18 \u0026gt;\u0026gt;\u0026gt; p2.age get ... instance: \u0026lt;__main__.Person object at 0x108159210\u0026gt;, owner: \u0026lt;class \u0026#39;__main__.Person\u0026#39;\u0026gt; 18 p1.age更改后p2.age的值也随之改变了，可以使用一个字典存储每个实例对应的值\nfrom weakref import WeakKeyDictionary class DataDescriptor: def __init__(self, default): self.default = default self.data = WeakKeyDictionary() def __get__(self, instance, owner): return self.data.get(instance, self.default) def __set__(self, instance, value): if value \u0026lt; 0: raise ValueError(f\u0026#34;Negative value not allowed: {value}\u0026#34;) self.data[instance] = value 这样确保了每个实例对应的值都相互不影响，这里使用了弱引用字典防止内存爆表。还在赋值的时候做了非负检查\n\u0026gt;\u0026gt;\u0026gt; class Person: ... age = DataDescriptor(1) ... ... \u0026gt;\u0026gt;\u0026gt; p1 = Person() \u0026gt;\u0026gt;\u0026gt; p2 = Person() \u0026gt;\u0026gt;\u0026gt; p1.age 1 \u0026gt;\u0026gt;\u0026gt; p2.age 1 \u0026gt;\u0026gt;\u0026gt; p1.age = 18 \u0026gt;\u0026gt;\u0026gt; p1.age 18 \u0026gt;\u0026gt;\u0026gt; p2.age 1 最后一个问题就是正因为用的是字典存储专属于实例的数据，特殊情况是如果实例对象(instance)不可哈希，那就会报错\n\u0026gt;\u0026gt;\u0026gt; class MyList(list): ... x = DataDescriptor(10) ... ... \u0026gt;\u0026gt;\u0026gt; m = MyList() \u0026gt;\u0026gt;\u0026gt; m.x Traceback (most recent call last): ... TypeError: unhashable type: \u0026#39;MyList\u0026#39; Mylist继承自list，所以传入的实例instance是不可哈希的，一个解决办法就是每次使用描述符的时候给它取个名字加标签\nclass DataDescriptor: def __init__(self, default, name): self.default = default self.name = name def __get__(self, instance, owner): return instance.__dict__.get(self.name, self.default) def __set__(self, instance, value): if value \u0026lt; 0: raise ValueError(f\u0026#34;Negative value not allowed: {value}\u0026#34;) instance.__dict__[self.name] = value class MyList(list): x = DataDescriptor(1, \u0026#39;x\u0026#39;) m = MyList() print(m.x) # 1 m.x = 8 print(m.x) # 8 用一开始传入的name作为键，就避免了有可能键是不可哈希的问题，另一方面此方法涉及到每个实例的字典__dict__，因为这是一个数据描述符访问属性的时候优先调用__get__或者__set__方法，查找顺序优先于实例字典，然后我们在方法里面可以安全的访问对象的实例字典instance.__dict__，这有点绕但没有问题。把值存储在各对象的实例字典里面即解决不同实例相互影响问题又解决内存问题。但每次传name会有点麻烦可不可以不传呢，python3.6 中对描述符协议新增了__set_name__特殊方法可以轻松获取描述符的名字，所以也可以这么写\nclass DataDescriptor: def __init__(self, default): self.default = default def __get__(self, instance, owner): return instance.__dict__.get(self.name, self.default) def __set__(self, instance, value): if value \u0026lt; 0: raise ValueError(f\u0026#34;Negative value not allowed: {value}\u0026#34;) instance.__dict__[self.name] = value def __set_name__(self, owner, name): print(f\u0026#34;set name called name: {name!r}\u0026#34;) self.name = name __set_name__方法会在类属性定义的时候被调用，获取名字(x)\n\u0026gt;\u0026gt;\u0026gt; class MyList(list): ... x = DataDescriptor(10) ... ... set name called owner: \u0026lt;class \u0026#39;__main__.MyList\u0026#39;\u0026gt;, name: \u0026#39;x\u0026#39; \u0026gt;\u0026gt;\u0026gt; m1 = MyList() \u0026gt;\u0026gt;\u0026gt; m2 = MyList() \u0026gt;\u0026gt;\u0026gt; m1.x 10 \u0026gt;\u0026gt;\u0026gt; m2.x 10 \u0026gt;\u0026gt;\u0026gt; m1.x = 99 \u0026gt;\u0026gt;\u0026gt; m1.x 99 \u0026gt;\u0026gt;\u0026gt; m2.x 10 \u0026gt;\u0026gt;\u0026gt; m1.__dict__ {\u0026#39;x\u0026#39;: 99} 以上DataDescriptor可以在任何对象上使用，并且不受多个实例相互影响了。\n非数据描述符（Non-Data Descriptors） 再来看一个非数据描述符\nclass NonDataDescriptor: \u0026#34;\u0026#34;\u0026#34;A non-data descriptor \u0026#34;\u0026#34;\u0026#34; def __init__(self, initval): self.initval = initval def __get__(self, instance, owner): print(f\u0026#34;get ... instance: {instance!r}, owner: {owner!r}\u0026#34;) return self.initval 只定义一个__get__方法的为非数据描述符\n\u0026gt;\u0026gt;\u0026gt; class Student: ... age = NonDataDescriptor(13) ... ... \u0026gt;\u0026gt;\u0026gt; s = Student() \u0026gt;\u0026gt;\u0026gt; s.age get ... instance: \u0026lt;__main__.Student object at 0x1109c3e10\u0026gt;, owner: \u0026lt;class \u0026#39;__main__.Student\u0026#39;\u0026gt; 13 \u0026gt;\u0026gt;\u0026gt; s.__dict__ {} \u0026gt;\u0026gt;\u0026gt; s.age = 18 \u0026gt;\u0026gt;\u0026gt; s.__dict__ {\u0026#39;age\u0026#39;: 18} \u0026gt;\u0026gt;\u0026gt; s.age 18 \u0026gt;\u0026gt;\u0026gt; Student.age get ... instance: None, owner: \u0026lt;class \u0026#39;__main__.Student\u0026#39;\u0026gt; 13 可以看出非数据描述符的优先级比实例字典低，赋值会存放到__dict__中，也是这个原因如果有多个实例相互之间赋值也不影响，不需要像上面那样单独为每个实例保存一份值，Student.age访问的是类变量所以instance为None\n描述符的调用 访问属性时obj.d，如果d是描述符定义了__get__方法，要分两种情况因为obj可以是类或者实例，也就是说obj.d可能是类属性或者实例属性\n对于obj是实例时，底层调用object.__getattribute__()实现，把obj.b转化成type(obj).__dict__['b'].__get__(obj, type(obj)) 对于obj是类时，调用object.__getattribute__()时，如把Cls.b转化成Cls.__dict__['b'].__get__(None, Cls) 描述符的创建 有多个方式可以创建描述符\n通过使用property()创建 创建一个类并实现描述符协议 通过使用property()创建 python 提供了property()函数，可以用来创建描述符\nclass Person: def __init__(self, initval): self._x = initval def get_x(self): print(\u0026#34;get ...\u0026#34;) return self._x def set_x(self, value): print(\u0026#34;set ...\u0026#34;) self._x = value def del_x(self): print(\u0026#34;del ...\u0026#34;) del self._x age = property(get_x, set_x, del_x, \u0026#34;I\u0026#39;m the \u0026#39;age\u0026#39; property.\u0026#34;) 类Person定义了age属性，其实age就是一个描述符\n\u0026gt;\u0026gt;\u0026gt; Person.age \u0026lt;property object at 0x10310b290\u0026gt; \u0026gt;\u0026gt;\u0026gt; p = Person(10) \u0026gt;\u0026gt;\u0026gt; p.age get ... 10 \u0026gt;\u0026gt;\u0026gt; p.__dict__ {\u0026#39;_x\u0026#39;: 10} \u0026gt;\u0026gt;\u0026gt; del p.age del ... \u0026gt;\u0026gt;\u0026gt; p.age = 18 set ... \u0026gt;\u0026gt;\u0026gt; p.__dict__ {\u0026#39;_x\u0026#39;: 18} \u0026gt;\u0026gt;\u0026gt; p.age get ... 18 此方法可以看到age是property object，property()函数实现为数据描述符。因此，实例字典是无法覆盖的(name不在__dict__中)，但从上面发现其实我们引入了_x私有变量。这种方法对某个属性的定义非常好用，python 还特地提供了语法糖@property写起来更加方便，以前文章也有介绍 Python 中@propery 使用\nclass Person: def __init__(self, initval): self.__age = initval @property def age(self): print(\u0026#34;get ...\u0026#34;) return self.__age @age.setter def age(self, value): print(\u0026#34;set ...\u0026#34;) self.__age = value @age.deleter def age(self): print(\u0026#34;del ...\u0026#34;) del self.__age 创建一个类并实现描述符协议 创建一个类并覆盖任意一个描述符方法__set__、__ get__ 、 __delete__和__set_name__，之前我们创建的DataDescriptor和NonDataDescriptor都是用的此方法，当需要某个属性在多个不同的类或者实例都可以使用时，例如类型验证，值检查，都可以使用该方法创建。\n试想如果我们需要类型验证很多的属性用上述@property的方法就写起来比较繁琐了要写多个@property块定义，用此方法就很简单，如\nclass Foo: a = DataDescriptor(1) b = DataDescriptor(2) .... 实际使用 只读属性和惰性求值 class ReadonlyNumber(object): \u0026#34;\u0026#34;\u0026#34; 实现只读属性(实例属性初始化后无法被修改) 利用了 data descriptor 优先级高于 obj.__dict__ 的特性 当试图对属性赋值时，总会先调用 __set__ 方法从而抛出异常 \u0026#34;\u0026#34;\u0026#34; def __init__(self, value): self.value = value def __get__(self, instance, owner): return self.value def __set__(self, instance, value): raise AttributeError( \u0026#34;\u0026#39;%s\u0026#39; is not modifiable\u0026#34; % self.value ) class LazyProperty(object): \u0026#34;\u0026#34;\u0026#34; 实现惰性求值(访问时才计算，并将值缓存) 利用了 obj.__dict__ 优先级高于 non-data descriptor 的特性 第一次调用 __get__ 以同名属性存于实例字典中，之后就不再调用 __get__ \u0026#34;\u0026#34;\u0026#34; def __init__(self, fun): self.fun = fun def __get__(self, instance, owner): if instance is None: return self value = self.fun(instance) setattr(instance, self.fun.__name__, value) return value class Circle(object): pi = ReadonlyNumber(3.14) def __init__(self, radius): self.radius = radius @LazyProperty def area(self): print(\u0026#39;Computing area\u0026#39;) return self.pi * self.radius ** 2 y = Circle(3) y.area # 28.26 ReadonlyNumber描述符实现了只读属性，LazyProperty实现了属性值缓存这里用到了装饰器\n函数与方法 上面我们已经看到property是一个数据描述符。接下来我们看看函数。\n类中的函数就是方法，其实函数就是一个非数据描述符只定义了__get__()方法，所以能被实例字典覆盖\n\u0026gt;\u0026gt;\u0026gt; class D: ... def f(self, x): ... return x ... ... \u0026gt;\u0026gt;\u0026gt; d = D() \u0026gt;\u0026gt;\u0026gt; D.__dict__[\u0026#39;f\u0026#39;] # 通过类字典访问f，不调用__get__ \u0026lt;function D.f at 0x108b17e60\u0026gt; \u0026gt;\u0026gt;\u0026gt; D.f # 通过类属性访问，调用__get__ \u0026lt;function D.f at 0x108b17e60\u0026gt; \u0026gt;\u0026gt;\u0026gt; D.__dict__[\u0026#39;f\u0026#39;].__get__(None, D) # 手动调用__get__方法 \u0026lt;function D.f at 0x108b17e60\u0026gt; \u0026gt;\u0026gt;\u0026gt; D.f.__qualname__ \u0026#39;D.f\u0026#39; \u0026gt;\u0026gt;\u0026gt; d \u0026lt;__main__.D object at 0x108486710\u0026gt; \u0026gt;\u0026gt;\u0026gt; d.f # 实例属性调用__get__，返回bound method \u0026lt;bound method D.f of \u0026lt;__main__.D object at 0x108486710\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; type(d).__dict__[\u0026#39;f\u0026#39;].__get__(d, type(d)) # 手动调用 \u0026lt;bound method D.f of \u0026lt;__main__.D object at 0x108486710\u0026gt;\u0026gt; # 绑定的方法内部存储了函数地址、绑定此方法的实例、以及绑定实例的类 \u0026gt;\u0026gt;\u0026gt; d.f.__func__ # 函数 \u0026lt;function D.f at 0x108b17e60\u0026gt; \u0026gt;\u0026gt;\u0026gt; d.f.__self__ # 实例对象 \u0026lt;__main__.D object at 0x108486710\u0026gt; \u0026gt;\u0026gt;\u0026gt; d.f.__class__ # 类 \u0026lt;class \u0026#39;method\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; d.f = 100 \u0026gt;\u0026gt;\u0026gt; d.f 100 我们知道类方法就是定义在类内部的函数只是第一个参数(self)接收自身实例对象，当使用 dot notation(.)访问时，把实例对象传给第一个参数。因为函数f是一个非数据描述符，当调用d.f(*args)时，内部的__get__方法会把d.f(*args)转化成f(d, *args)，当调用D.f(*args)是转化成f(*args)，这就是非数据描述符干的事情。\n静态方法和类方法 没错静态方法和类方法也是和上面函数调用同样的原理，如类方法调用（从类调用）内部__get__就是把OneClass.f(*args)转化成f(OneClass, *args)，静态方法同理，官方文档提供了如下的转化表格\n转型 从实例对象调用 从类调用 函数 f(ojb, *args) f(*args) 静态方法 f(*args) f(*args) 类方法 f(type(obj), *args) f(kclass, *args) 小结 描述符要实现描述符协议（实现__set__, __get__, __delete__, __set_name__方法） 描述符必须作为对象属性（类属性） 描述符的查找顺序：数据描述符 \u0026gt; 实例字典 \u0026gt; 非数据描述符 Reference docs.python.org realpython.com www.ibm.com www.jianshu.com zhuanlan.zhihu.com ","permalink":"https://blog.fangjiahui.me/posts/2019-12-17-python-descriptor/","summary":"Python 描述符(descriptor) Python 中有一个很少被使用或者用户自定义的特性，那就是描述符(descriptor)，但它是@property, @classmethod, @staticmethod和super的底层实现机制，我今天就扒一扒它，官方文档对描述符的介绍如下\nIn general, a descriptor is an object attribute with “binding behavior”, one whose attribute access has been overridden by methods in the descriptor protocol: __get__(), __set__(), and __delete__(). If any of those methods are defined for an object, it is said to be a descriptor.\n描述符是绑定了行为的对象属性(object attribute)，实现了描述符协议(descriptor protocol)，描述符协议就是定义了__get__(),__set__(),__delete__()中的一个或者多个方法，将描述符对象作为其他对象的属性进行访问时，就会产生一些特殊的效果。\n上面的定义可能还是有些晦涩，一步步来\n默认查找属性 在没有描述符定义情况下，我们访问属性的顺序如下，以a.x为例\n查找实例字典里的属性就是a.__dict__['x']有就返回 往上查找父类的字典就是a.__class__.__dict__['x']有就返回 上面都没有就查找父类的基类(不包括元类(metaclass)) 如果定义了__getattr__就会返回此方法 最后都没有抛出AttributeError \u0026gt;\u0026gt;\u0026gt; class A: ... x = 8 ... .","title":"Python描述符(descriptor)"},{"content":"使用 Core dump 解密加密的脚本 之前遇到网上的集成的shell脚本有点问题想手动修改下，发现脚本是加密的，网上找了好久发现有gzexe、shc加密方法都尝试了一遍，可惜解密都不成功，最后用了一个粗暴的办法就是任何程序总要加载到内存运行的吧，那就直接中断coredump查看内存里的内容，以下是具体方法。\nroot用户执行如下命令\nulimit -c unlimited echo \u0026#34;/core_dump/%e-%p-%t.core\u0026#34; \u0026gt; /proc/sys/kernel/core_pattern mkdir /core_dump 以上第一句是设置内核coredump大小，这里设置不限制。第二句是设置coredump存储位置和格式，%e代表可执行程序名，%p代表pid， %t代表生成时间。然后去执行脚本如xxx.sh\n./xxx.sh 6 start \u0026amp; (sleep 0.01 \u0026amp;\u0026amp; kill -SIGSEGV $!) 之后会输出类似[1]+ Segmentation fault (core dumped)...的提示，然后查看/core_dump文件夹下，就会有dump出来的文件了，直接vim打开查看会有一些乱码手动处理一下就可以了。\n如果在core_dump文件夹下没有dump出来的文件，可使用如下命令测试然后查看是否有文件生成。\nsleep 15 \u0026amp; killall -SIGSEGV sleep 正常情况下core_dump文件夹下会有以sleep开头的文件。\n","permalink":"https://blog.fangjiahui.me/posts/2019-10-16-linux-core-dump-decrypt-script/","summary":"使用 Core dump 解密加密的脚本 之前遇到网上的集成的shell脚本有点问题想手动修改下，发现脚本是加密的，网上找了好久发现有gzexe、shc加密方法都尝试了一遍，可惜解密都不成功，最后用了一个粗暴的办法就是任何程序总要加载到内存运行的吧，那就直接中断coredump查看内存里的内容，以下是具体方法。\nroot用户执行如下命令\nulimit -c unlimited echo \u0026#34;/core_dump/%e-%p-%t.core\u0026#34; \u0026gt; /proc/sys/kernel/core_pattern mkdir /core_dump 以上第一句是设置内核coredump大小，这里设置不限制。第二句是设置coredump存储位置和格式，%e代表可执行程序名，%p代表pid， %t代表生成时间。然后去执行脚本如xxx.sh\n./xxx.sh 6 start \u0026amp; (sleep 0.01 \u0026amp;\u0026amp; kill -SIGSEGV $!) 之后会输出类似[1]+ Segmentation fault (core dumped)...的提示，然后查看/core_dump文件夹下，就会有dump出来的文件了，直接vim打开查看会有一些乱码手动处理一下就可以了。\n如果在core_dump文件夹下没有dump出来的文件，可使用如下命令测试然后查看是否有文件生成。\nsleep 15 \u0026amp; killall -SIGSEGV sleep 正常情况下core_dump文件夹下会有以sleep开头的文件。","title":"使用 Core dump 解密加密的sh脚本"},{"content":"Python实现单例(Singleton)的几种方法 单例是一种比较简单的设计模式，每次实例化只提供一个相同的实例对象，对于保证实例唯一和节约系统资源的时候十分有用，下面就看看python中实现单例的几种方法\n使用__new__方法 因为在类的实例化过程中__new__方法会比__init__提前调用，我们在类属性中保存一个_singleton每次只返回这个。\nclass Singleton: def __new__(cls, *args, **kwargs): if not getattr(cls, \u0026#39;_singleton\u0026#39;, None): cls._singleton = super().__new__(cls, *args, **kwargs) return cls._singleton class MyClass(Singleton): pass a = MyClass() b = MyClass() print(id(a)) # 4433117872 print(id(b)) # 4433117872 print(a is b) # True 使用装饰器 from functools import wraps def singleton(cls): _singleton = {} @wraps(cls) def wrapper(*args, **kwargs): if not _singleton.get(cls): _singleton[cls] = cls(*args, **kwargs) return _singleton[cls] return wrapper @singleton class MyClass: pass 利用装饰器中的_singleton变量存储所有类的实例\n利用python模块 python模块（module）是天然的单例模式\n# singleton.py class Singleton: def foo(self): print(\u0026#34;I\u0026#39;m singleton\u0026#34;) instance = Singleton() del Singleton 然后利用模块导入\nfrom single import instance instance.foo() # I\u0026#39;m singleton ","permalink":"https://blog.fangjiahui.me/posts/2019-02-27-python-singleton/","summary":"Python实现单例(Singleton)的几种方法 单例是一种比较简单的设计模式，每次实例化只提供一个相同的实例对象，对于保证实例唯一和节约系统资源的时候十分有用，下面就看看python中实现单例的几种方法\n使用__new__方法 因为在类的实例化过程中__new__方法会比__init__提前调用，我们在类属性中保存一个_singleton每次只返回这个。\nclass Singleton: def __new__(cls, *args, **kwargs): if not getattr(cls, \u0026#39;_singleton\u0026#39;, None): cls._singleton = super().__new__(cls, *args, **kwargs) return cls._singleton class MyClass(Singleton): pass a = MyClass() b = MyClass() print(id(a)) # 4433117872 print(id(b)) # 4433117872 print(a is b) # True 使用装饰器 from functools import wraps def singleton(cls): _singleton = {} @wraps(cls) def wrapper(*args, **kwargs): if not _singleton.get(cls): _singleton[cls] = cls(*args, **kwargs) return _singleton[cls] return wrapper @singleton class MyClass: pass 利用装饰器中的_singleton变量存储所有类的实例","title":"Python实现单例(Singleton)的几种方法"},{"content":"Mac不安装第三方应用读写NTFS格式硬盘 首先插入硬盘或者U盘，现在的盘只能读取，我们先umount以/dev/disk3s2分区为例\n❯ mount # 列出挂载分区 /dev/disk1s5 on / (apfs, local, read-only, journaled) devfs on /dev (devfs, local, nobrowse) /dev/disk1s1 on /System/Volumes/Data (apfs, local, journaled, nobrowse) /dev/disk1s4 on /private/var/vm (apfs, local, journaled, nobrowse) /dev/disk3s2 on /Volumes/TOSHIBA EXT (ntfs, local, nodev, nosuid, read-only, noowners) ❯ sudo umount /Volumes/TOSHIBA\\ EXT 创建挂在路径，然后手动挂载\nsudo mkdir /Volumes/mount sudo mount -t ntfs -o rw,auto,nobrowse /dev/disk3s2 /Volumes/mount cd /Volumes/mount 就这样移动硬盘可读写了，也可以打开Finder试试\n","permalink":"https://blog.fangjiahui.me/posts/2019-01-25-mac-mount-ntfs/","summary":"Mac不安装第三方应用读写NTFS格式硬盘 首先插入硬盘或者U盘，现在的盘只能读取，我们先umount以/dev/disk3s2分区为例\n❯ mount # 列出挂载分区 /dev/disk1s5 on / (apfs, local, read-only, journaled) devfs on /dev (devfs, local, nobrowse) /dev/disk1s1 on /System/Volumes/Data (apfs, local, journaled, nobrowse) /dev/disk1s4 on /private/var/vm (apfs, local, journaled, nobrowse) /dev/disk3s2 on /Volumes/TOSHIBA EXT (ntfs, local, nodev, nosuid, read-only, noowners) ❯ sudo umount /Volumes/TOSHIBA\\ EXT 创建挂在路径，然后手动挂载\nsudo mkdir /Volumes/mount sudo mount -t ntfs -o rw,auto,nobrowse /dev/disk3s2 /Volumes/mount cd /Volumes/mount 就这样移动硬盘可读写了，也可以打开Finder试试","title":"Mac不安装第三方应用读写NTFS格式硬盘"},{"content":"Mysql(mysqldump)备份脚本 记录下服务器上一个备份 mysql 数据库的脚本，使用 mysql 自带的mysqldump命令\n!/usr/bin/env bash USER=username PASSWORD=password MAXIMUM_BACKUP_FILES=10 BACKUP_FOLDER=/path/to/save/folder DATABASES=( db_name_0 db_name_1 ) # check mysqldump instlled _=$(command -v mysqldump) if [[ $? != 0 ]] then printf \u0026#34;You don\u0026#39;t seem to mysqldump installed, exit..\\n\u0026#34; exit 1 fi # create backup folder if [ ! -d $BACKUP_FOLDER ] then mkdir $BACKUP_FOLDER fi # backup for DB in ${DATABASES[@]} do echo backing up ${DB} database ... if $(mysqldump --host=localhost --user=${USER} --password=${PASSWORD} ${DB} | gzip -9 \u0026gt; ${BACKUP_FOLDER}/db_${DB}_$(date +\u0026#34;%Y%m%d\u0026#34;).sql.gz) then echo dump db_${DB}_$(date +\u0026#34;%Y%m%d\u0026#34;).sql.gz done. else echo dump db_${DB}_$(date +\u0026#34;%Y%m%d\u0026#34;).sql.gz failed. fi done # remove older files find ${BACKUP_FOLDER} -type f -name *.sql.gz -mtime +${MAXIMUM_BACKUP_FILES} -delete 脚本就是使用 mysqldump 备份指定的数据库（在 DATABASES 使用空格分隔）然后 gzip 压缩保存到指定目录，使用系统自带的 find 命令删除旧文件\n最后加入 crontab，设置每天凌晨 3 点备份\n* 3 * * * bash /path/to/mysql_backup.sh 数据恢复可以使用如下命令\ngzip -dc db_dbName_20181012.sql.gz | mysql -u userName -p dbName 如果跑在 docker 环境下可用如下脚本\n#!/usr/bin/env bash CONTAINER_NAME=docker-db-container-name USER=username PASSWORD=password MAXIMUM_BACKUP_FILES=10 BACKUP_FOLDER=/path/to/save/folder DATABASES=( db_name_0 db_name_1 ) # create backup folder if [ ! -d $BACKUP_FOLDER ]; then mkdir $BACKUP_FOLDER fi # check container running n=$(docker ps -f name=${CONTAINER_NAME} -q | wc -l) if [ \u0026#34;$n\u0026#34; -eq 0 ]; then echo \u0026#34;Contaniner ${CONTAINER_NAME} is not running, please check it\u0026#34; exit 1 fi # backup for DB in ${DATABASES[@]} do echo backing up ${DB} database ... EXEC_SH=\u0026#34;docker exec -i ${CONTAINER_NAME} sh -c \u0026#39;mysqldump --user=${USER} --password=${PASSWORD} ${DB}\u0026#39; | gzip -9 \u0026gt; ${BACKUP_FOLDER}/db_${DB}_$(date +\u0026#34;%Y%m%d\u0026#34;).sql.gz\u0026#34; eval $EXEC_SH if [ $? -eq 0 ] then echo dump db_${DB}_$(date +\u0026#34;%Y%m%d\u0026#34;).sql.gz done. else echo dump db_${DB}_$(date +\u0026#34;%Y%m%d\u0026#34;).sql.gz failed. fi done # remove older files find ${BACKUP_FOLDER} -type f -name *.sql.gz -mtime +${MAXIMUM_BACKUP_FILES} -delete ","permalink":"https://blog.fangjiahui.me/posts/2018-11-08-mysqldump-backup-script/","summary":"Mysql(mysqldump)备份脚本 记录下服务器上一个备份 mysql 数据库的脚本，使用 mysql 自带的mysqldump命令\n!/usr/bin/env bash USER=username PASSWORD=password MAXIMUM_BACKUP_FILES=10 BACKUP_FOLDER=/path/to/save/folder DATABASES=( db_name_0 db_name_1 ) # check mysqldump instlled _=$(command -v mysqldump) if [[ $? != 0 ]] then printf \u0026#34;You don\u0026#39;t seem to mysqldump installed, exit..\\n\u0026#34; exit 1 fi # create backup folder if [ ! -d $BACKUP_FOLDER ] then mkdir $BACKUP_FOLDER fi # backup for DB in ${DATABASES[@]} do echo backing up ${DB} database ... if $(mysqldump --host=localhost --user=${USER} --password=${PASSWORD} ${DB} | gzip -9 \u0026gt; ${BACKUP_FOLDER}/db_${DB}_$(date +\u0026#34;%Y%m%d\u0026#34;).","title":"Mysql数据库备份脚本(使用mysqldump)"},{"content":"最近公司需要将 python 代码部署到端上查了各种加密方法说到底 python 其实是不建议加密部署的，像什么生成.pyc其实都是很容易反编译直接运行的，因为它是解释型语言。不像 C 或者 java 可以编译后生成机器码直接部署。还有看到把项目打包成.exe文件，在 windows 上运行，由于我们使用 Linux 平台没有尝试，最后选择了使用Cython这个库来加密(编译成二进制)。\nCython其实就是把py 代码编译成 C或者 C++代码来执行，在Linux 上会生成.so二进制文件，Windows下为.pyd，所以还有一个作用是加速代码的执行效率。但还有一些限制如项目中不能删除__init__.py否者包导入会失败。详细可参考官方文档，Cython 还在持续开发中支持 Python3，下面也用Python3演示。\n先来做一些准备工作定义编译后的文件夹build和一些部署不需要的文件和文件夹，将待编译的.py文件加入ext_modules列表\ncur_dir = os.path.abspath(os.path.dirname(__file__)) setup_file = os.path.split(__file__)[1] build_dir = os.path.join(cur_dir, \u0026#39;build\u0026#39;) build_tmp_dir = os.path.join(build_dir, \u0026#34;temp\u0026#34;) # define exclude dirs, these dirs will be deleted exclude_dirs = [\u0026#39;.git\u0026#39;, \u0026#39;__pycache__\u0026#39;, \u0026#39;test\u0026#39;, \u0026#39;logs\u0026#39;, \u0026#39;venv\u0026#39;, \u0026#39;tests\u0026#39;] # defile exclude files, these files will be deleted exclude_files = [\u0026#39;*.md\u0026#39;, \u0026#39;.gitignore\u0026#39;, \u0026#39;.python-version\u0026#39;, \u0026#39;requirements.txt\u0026#39;, \u0026#39;*.pyc\u0026#39;, \u0026#39;*.c\u0026#39;] # these `.py` files will be retained and don\u0026#39;t compile to `.so` ignore_py_files = [\u0026#39;config.py\u0026#39;] ext_modules = [] # get all build files for path, dirs, files in os.walk(cur_dir, topdown=True): dirs[:] = [d for d in dirs if d not in exclude_dirs] # touch a new file when __init__.py not exists for _dir in dirs: init_file = os.path.join(path, _dir, \u0026#39;__init__.py\u0026#39;) if not os.path.isfile(init_file): print(\u0026#39;WARNING: create new empty [{}] file.\u0026#39;.format(init_file)) with open(init_file, \u0026#39;a\u0026#39;) as f: pass # create target folder if not os.path.isdir(build_dir): os.mkdir(build_dir) # make empty dirs for dir_name in dirs: dir = os.path.join(path, dir_name) target_dir = dir.replace(cur_dir, build_dir) os.mkdir(target_dir) for file_name in files: file = os.path.join(path, file_name) if os.path.splitext(file)[1] == \u0026#39;.py\u0026#39;: if file_name in ignore_py_files: # don\u0026#39;t compile to .so if file_name not in exclude_files: shutil.copy(file, path.replace(cur_dir, build_dir)) elif file_name in exclude_files: # remove it pass else: # add to compile if file_name == \u0026#39;__init__.py\u0026#39;: # copy __init__.py resolve package cannot be imported shutil.copy(file, path.replace(cur_dir, build_dir)) if file_name != setup_file: ext_modules.append(file) else: _exclude = False for pattern in exclude_files: if fnmatch.fnmatch(file_name, pattern): _exclude = True if not _exclude: shutil.copy(file, path.replace(cur_dir, build_dir)) 我们需要把原来的每个文件夹下__init__.py拷贝一份，不然项目中相对导入这些会失效。然后把ext_modules列表传给cythonize生成distutils Extension objects再传给setup函数。\nfrom distutils.core import setup from Cython.Build import cythonize from Cython.Distutils import build_ext setup( ext_modules=cythonize( ext_modules, compiler_directives=dict( always_allow_keywords=True, c_string_encoding=\u0026#39;utf-8\u0026#39;, language_level=3 ) ), cmdclass=dict( build_ext=build_ext ), script_args=[\u0026#34;build_ext\u0026#34;, \u0026#34;-b\u0026#34;, build_dir, \u0026#34;-t\u0026#34;, build_tmp_dir] ) ..... 需要注意的是传给setup时需要加always_allow_keywords=True参数否者默认的python 特性关键字参数编译后运行是会报TypeError: ... takes no keyword arguments错的，如 fask 应用上。还有在运行的时候指定了build_dir是编译后存放的目录，不指定默认存放当前目录下，还有临时目录build_tmp_dir稍后可以删除。\n完整代码可以参考我Github上的代码，拷贝本脚本到项目根目录可以适当修改如哪些不需要放到部署环境的，安装 Cython 后确保每个子文件夹下有__init__.py内容为空的也行，不然生成的.so会路径不对。运行python3 build_it.py会生成一个build文件夹，之后删掉除 build 文件夹所有源文件进入 build 文件夹运行即可（需要启动脚本）。\nReference https://bucharjan.cz https://web.archive.org https://laucyun.com https://www.cnblogs.com ","permalink":"https://blog.fangjiahui.me/posts/2018-11-03-encrypt-protect-python-code/","summary":"最近公司需要将 python 代码部署到端上查了各种加密方法说到底 python 其实是不建议加密部署的，像什么生成.pyc其实都是很容易反编译直接运行的，因为它是解释型语言。不像 C 或者 java 可以编译后生成机器码直接部署。还有看到把项目打包成.exe文件，在 windows 上运行，由于我们使用 Linux 平台没有尝试，最后选择了使用Cython这个库来加密(编译成二进制)。\nCython其实就是把py 代码编译成 C或者 C++代码来执行，在Linux 上会生成.so二进制文件，Windows下为.pyd，所以还有一个作用是加速代码的执行效率。但还有一些限制如项目中不能删除__init__.py否者包导入会失败。详细可参考官方文档，Cython 还在持续开发中支持 Python3，下面也用Python3演示。\n先来做一些准备工作定义编译后的文件夹build和一些部署不需要的文件和文件夹，将待编译的.py文件加入ext_modules列表\ncur_dir = os.path.abspath(os.path.dirname(__file__)) setup_file = os.path.split(__file__)[1] build_dir = os.path.join(cur_dir, \u0026#39;build\u0026#39;) build_tmp_dir = os.path.join(build_dir, \u0026#34;temp\u0026#34;) # define exclude dirs, these dirs will be deleted exclude_dirs = [\u0026#39;.git\u0026#39;, \u0026#39;__pycache__\u0026#39;, \u0026#39;test\u0026#39;, \u0026#39;logs\u0026#39;, \u0026#39;venv\u0026#39;, \u0026#39;tests\u0026#39;] # defile exclude files, these files will be deleted exclude_files = [\u0026#39;*.md\u0026#39;, \u0026#39;.gitignore\u0026#39;, \u0026#39;.python-version\u0026#39;, \u0026#39;requirements.txt\u0026#39;, \u0026#39;*.pyc\u0026#39;, \u0026#39;*.c\u0026#39;] # these `.","title":"使用 Cython 加密 Python 项目"},{"content":" 今年的中秋和国庆只隔了一周的工作日，故中秋没回老家和两朋友去了东极岛看看海和吃了点海鲜惶惶三日，途中大巴车上用 kobo（类似 kindle）看了一半，国庆长假回乡见父母同学抽空书架上取出又看了一半。我可能守旧，能用实体书看的时候还是喜欢实体书的质感，捧着本书比 kobo 感觉更真实，但 kobo 能装下我书架上的所有书也方便易带和搜索，或许多年后实体书也会成为奢侈品吧。\n这是本两代人中间差了 30 年的一共 36 封家书，但读来会惊讶母亲和儿子竟可以如此像朋友般对话沟通，涵盖了政治、艺术、人生、生活等等。于儿子更能明白为人父母的殷切期望不是能成才取得多大多大的成就而是只要你过得开心。当安德烈说我这辈子可能达不到父母的成就，可能只是一个平庸人时。龙妈妈这样回答\n对我最重要的，安德烈，不是你有否成就，而是你是否快乐。而在现代的生活架构里，什么样的工作比较可能给你快乐？第一，它给你意义；第二，它给你时间。你的工作是你觉得有意义的，你的工作不绑架你使你成为工作的俘虏，容许你去充分体验生活，你就比较可能是快乐的。至于金钱和名声，哪里是快乐的核心元素呢？……我也要求你读书用功，不是因为我要你跟别人比成就，而是因为，我希望你将来有选择的权利，选择有意义、有时间的工作，而不是被迫谋生。……『平庸』是跟别人比，心灵的安适是跟自己比。我们最终极的负责对象，安德烈，千山万水走到最后，还是『自己』二字。\n而在儿子为情所困时，妈妈等了好久既激动又兴奋\n我愿意和你分享的是我自己的『心得报告』，那就是，人生就像条大河，可能风景清丽，更可能惊涛骇浪。你需要的伴侣，最好是那能够和你并肩而立在船头，浅吟低唱两岸风光，同时更能在惊涛骇浪中紧紧握住你的手不放的人。换句话说，最好她本身不是你必须应付的惊涛骇浪。\n于父母时要明白当孩子已经 18 岁成人时他已经是一个独立的个体，他要为自己做的事情付全部的责任。如安德烈常抽烟，而且在母亲面前抽。每次见到妈妈恨不得跑过去抽两个耳光但你不能马上上去制止，因为他已成人已是一个独立的个体。\n父母也会认识到孩子慢慢的长大，像小鸟一样终会飞走。当父母五六十岁孩子就会意识到回国头来慢慢看看，我还有父母这个窝。\n","permalink":"https://blog.fangjiahui.me/posts/2018-10-07-read-dear-andreas-walther/","summary":"今年的中秋和国庆只隔了一周的工作日，故中秋没回老家和两朋友去了东极岛看看海和吃了点海鲜惶惶三日，途中大巴车上用 kobo（类似 kindle）看了一半，国庆长假回乡见父母同学抽空书架上取出又看了一半。我可能守旧，能用实体书看的时候还是喜欢实体书的质感，捧着本书比 kobo 感觉更真实，但 kobo 能装下我书架上的所有书也方便易带和搜索，或许多年后实体书也会成为奢侈品吧。\n这是本两代人中间差了 30 年的一共 36 封家书，但读来会惊讶母亲和儿子竟可以如此像朋友般对话沟通，涵盖了政治、艺术、人生、生活等等。于儿子更能明白为人父母的殷切期望不是能成才取得多大多大的成就而是只要你过得开心。当安德烈说我这辈子可能达不到父母的成就，可能只是一个平庸人时。龙妈妈这样回答\n对我最重要的，安德烈，不是你有否成就，而是你是否快乐。而在现代的生活架构里，什么样的工作比较可能给你快乐？第一，它给你意义；第二，它给你时间。你的工作是你觉得有意义的，你的工作不绑架你使你成为工作的俘虏，容许你去充分体验生活，你就比较可能是快乐的。至于金钱和名声，哪里是快乐的核心元素呢？……我也要求你读书用功，不是因为我要你跟别人比成就，而是因为，我希望你将来有选择的权利，选择有意义、有时间的工作，而不是被迫谋生。……『平庸』是跟别人比，心灵的安适是跟自己比。我们最终极的负责对象，安德烈，千山万水走到最后，还是『自己』二字。\n而在儿子为情所困时，妈妈等了好久既激动又兴奋\n我愿意和你分享的是我自己的『心得报告』，那就是，人生就像条大河，可能风景清丽，更可能惊涛骇浪。你需要的伴侣，最好是那能够和你并肩而立在船头，浅吟低唱两岸风光，同时更能在惊涛骇浪中紧紧握住你的手不放的人。换句话说，最好她本身不是你必须应付的惊涛骇浪。\n于父母时要明白当孩子已经 18 岁成人时他已经是一个独立的个体，他要为自己做的事情付全部的责任。如安德烈常抽烟，而且在母亲面前抽。每次见到妈妈恨不得跑过去抽两个耳光但你不能马上上去制止，因为他已成人已是一个独立的个体。\n父母也会认识到孩子慢慢的长大，像小鸟一样终会飞走。当父母五六十岁孩子就会意识到回国头来慢慢看看，我还有父母这个窝。","title":"读《亲爱的安德烈》"},{"content":"Systemd 中的 timer 单元 上一篇讲了 systemd 中的 service 单元，这次记录一下 timer 单元。timer 必须依赖 service 单元来配置，可以用来做替代 crontab 的选择。\ntimer 单元以.timer结尾，中间包含[Timer]块如下面所示是 Ubuntu 下的apt-daily.timer，该目录下也存在一个apt-daily.service服务文件配合一起使用。\n[Unit] Description=Daily apt activities [Timer] OnCalendar=*-*-* 6,18:00 RandomizedDelaySec=12h AccuracySec=1h Persistent=true [Install] WantedBy=timers.target 上面的[Timer]块代表每天上午 6 点和下午 6 点都运行 apt 脚本，具体[Timer]块可配置以下参数\n单调定时器(Monotonic timer) Option Description OnActiveSec= 相对计时器开始后多少时间执行，格式如 2h、2s、2w、2d OnBootSec= 相对系统启动后多少时间执行 OnStartupSec= 相对 systemd 启动多少时间后执行 OnUnitActiveSec= 每隔多少时间再次运行一次 OnUnitInactiveSec= 服务在最后一次停止后，隔多久再执行一次 可以两个参数一起使用，如下每周开机 15 分钟后执行 foo\n[Unit] Description=Run foo weekly and on boot [Timer] OnBootSec=15min OnUnitActiveSec=1w [Install] WantedBy=timers.target 实时定时器(Realtime timer) Option Description OnCalendar= 相对系统时间指定特定时刻运行，它接受如 2h、2s 的格式也可以是 星期 年-月-日 时:分:秒的格式，..指定区间，*代表所有的。可参考 systemd.time(7) Persistent= 是一个布尔值，默认为 no，当使用 OnCalendar 的设置时，指定该功能要不要持续进行。如断电恢复后是不是要执行上次没执行的 AccuracySec= 设置定时器的触发精度。默认值是一分钟。定时器并不必然在所设置的精准时间点上启动匹配单元， 而是在所设置的精准时间点为起点的一小段时间窗口范围内的某个时间点上启动匹配单元， 这个时间窗口的起点由 OnCalendar=, OnActiveSec=, OnBootSec=, OnStartupSec=, OnUnitActiveSec= or OnUnitInactiveSec= 决定， 而这个时间窗口的长度则由该指令决定。 RandomizedDelaySec= 将此单元的定时器随机延迟一小段时间， 这一小段时间的长度介于零到该指令设置的时间长度之间， 以均匀概率分布。 如下是每月的 1 到 4 号 12 点周一和周二运行 foo，格式如OnCalendar=*-*-* 4:00:00代表每天 4 点\n[Unit] Description=Run foo weekly [Timer] OnCalendar=Mon,Tue *-*-01..04 12:00:00 Persistent=true [Install] WantedBy=timers.target 所有timer单元可以像service一样使用systemctl status|enable|disable name.timer查看信息，可以使用systemctl list-timers列出运行中的 timer，加--all参数列出包含未激活的。\nubuntu➜ ~ ᐅ sudo systemctl list-timers --all NEXT LEFT LAST PASSED UNIT ACTIVATES Thu 2018-08-16 06:52:42 CST 7h left Wed 2018-08-15 06:22:54 CST 17h ago apt-daily-upgrade.timer apt-daily-upgrade.service Thu 2018-08-16 09:48:35 CST 10h left Wed 2018-08-15 20:15:54 CST 3h 10min ago apt-daily.timer apt-daily.service Thu 2018-08-16 21:34:50 CST 22h left Wed 2018-08-15 21:34:50 CST 1h 51min ago systemd-tmpfiles-clean.timer systemd-tmpfiles-clean.service n/a n/a n/a n/a snapd.refresh.timer n/a n/a n/a n/a snapd.snap-repair.timer snapd.snap-repair.service n/a n/a n/a n/a ureadahead-stop.timer ureadahead-stop.service 6 timers listed. ","permalink":"https://blog.fangjiahui.me/posts/2018-08-16-systemd-timer-unit/","summary":"Systemd 中的 timer 单元 上一篇讲了 systemd 中的 service 单元，这次记录一下 timer 单元。timer 必须依赖 service 单元来配置，可以用来做替代 crontab 的选择。\ntimer 单元以.timer结尾，中间包含[Timer]块如下面所示是 Ubuntu 下的apt-daily.timer，该目录下也存在一个apt-daily.service服务文件配合一起使用。\n[Unit] Description=Daily apt activities [Timer] OnCalendar=*-*-* 6,18:00 RandomizedDelaySec=12h AccuracySec=1h Persistent=true [Install] WantedBy=timers.target 上面的[Timer]块代表每天上午 6 点和下午 6 点都运行 apt 脚本，具体[Timer]块可配置以下参数\n单调定时器(Monotonic timer) Option Description OnActiveSec= 相对计时器开始后多少时间执行，格式如 2h、2s、2w、2d OnBootSec= 相对系统启动后多少时间执行 OnStartupSec= 相对 systemd 启动多少时间后执行 OnUnitActiveSec= 每隔多少时间再次运行一次 OnUnitInactiveSec= 服务在最后一次停止后，隔多久再执行一次 可以两个参数一起使用，如下每周开机 15 分钟后执行 foo\n[Unit] Description=Run foo weekly and on boot [Timer] OnBootSec=15min OnUnitActiveSec=1w [Install] WantedBy=timers.","title":"Systemd 中的timer单元"},{"content":"Mac 终端(Terminal)配置 平时工作中命令行用的比图形界面多，所以有必要配置一个赏心悦目的终端界面来提高工作效率(^_^)。\niTerm 第一步就是替换原来的自带终端(Terminal)，换成iTerm。iTerm 是一个深受广大开发者欢迎的终端 App，代码托管在Github，可以直接在官网下载安装。最新版为 Build 3.4.23\n打开iTerm2 \u0026gt; Preferences \u0026gt; General，在Selection下勾上Applications in terminal may access clipboard使在iTerm中鼠标选中就能复制到系统剪切板使用command+v粘贴\n打开iTerm2 \u0026gt; Preferences \u0026gt; Profiles，右边点Keys把左右 option 键设为Esc+，取消勾选Apps can change this来启用 Unix 的Alt + B和Alt + F前进和后退一个单词。\n打开iTerm2 \u0026gt; Preferences \u0026gt; Terminal，底部 Shell Integration 取消勾选 Show mark indicators 不然每次执行命令会出现一个小箭头影响美观\nZsh \u0026amp; Oh My Zsh 打开 iTerm 安装Homebrew\n/bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; 使用 Homebrew 安装 zsh，设为默认的终端。从 Big Sur 已经设置 zsh 为默认的终端了，可以跳过此步骤，可以使用echo $SHELL检查\nbrew install zsh oh-my-zsh是 zsh 的配置文件，使用下面命令安装\nsh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; 打开 iTerm 会耐看很多，应该长成这个样子了\n配置.zshrc文件可以更改主题或者增加插件，默认启用 robbyrussell 主题和开启了 git 插件，可以根据需要更改主题和插件。\nSH_THEME=\u0026#34;robbyrussell\u0026#34; ... plugins=( git ) 然后加第三方插件\nzsh-autosuggestions 自动提示插件，根据你输入的历史命令给出提示 git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions zsh-syntax-highlighting 高亮不同的命令插件 git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting zsh-history-substring-search 高亮查找匹配前缀的历史输入 git clone https://github.com/zsh-users/zsh-history-substring-search ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-history-substring-search 配置 ctrl+p 和 ctrl+n 触发，在 .zshrc 增加如下配置\nbindkey -M emacs \u0026#39;^P\u0026#39; history-substring-search-up bindkey -M emacs \u0026#39;^N\u0026#39; history-substring-search-down 最后加入到plugins启用\nplugins=( git zsh-autosuggestions zsh-syntax-highlighting zsh-history-substring-search ) zsh-completions 原生 zsh 功能补充，可以认为某些功能的尝鲜版稳定了会被加入的官方版本中 git clone https://github.com/zsh-users/zsh-completions ${ZSH_CUSTOM:=~/.oh-my-zsh/custom}/plugins/zsh-completions 这个插件安装方式有些不同不能加到 plugins 需要在 source \u0026quot;$ZSH/oh-my-zsh.sh\u0026quot; 之前添加下面这一行\n... fpath+=${ZSH_CUSTOM:-${ZSH:-~/.oh-my-zsh}/custom}/plugins/zsh-completions/src ... source $ZSH/oh-my-zsh.sh 效果图\nPure Pure是一个 zsh 提示，使用brew安装\nbrew install pure 在.zshrc后添加\n... fpath+=(\u0026#34;$(brew --prefix)/share/zsh/site-functions\u0026#34;) ... autoload -U promptinit; promptinit prompt pure iterm2-snazzy \u0026amp; Menlo-for-Powerline fonts iterm2-snazzy是一个 iTerm 配色方案 下载Github页上的Snazzy.itermcolors到本地，iTerm2 \u0026gt; Profiles \u0026gt; Colors Tab页右下角在Color Presets...导入Snazzy并选择启用。\nMenlo-for-Powerline 是 Menlo 的 Powerline 的字体。 下载到本地并双击安装字体。iTerm2 \u0026gt; Profiles \u0026gt; Text Tab修改字体为menlo for powerline，字体大小选13。\n也可以选 Nerd Fonts 为字体它打得补钉支持更多得图标和符号\n最终效果\nPS: 上面第一张图是Hyper加hyper-snazzy插件的效果\n","permalink":"https://blog.fangjiahui.me/posts/2018-07-23-mac-config-terminal/","summary":"Mac 终端(Terminal)配置 平时工作中命令行用的比图形界面多，所以有必要配置一个赏心悦目的终端界面来提高工作效率(^_^)。\niTerm 第一步就是替换原来的自带终端(Terminal)，换成iTerm。iTerm 是一个深受广大开发者欢迎的终端 App，代码托管在Github，可以直接在官网下载安装。最新版为 Build 3.4.23\n打开iTerm2 \u0026gt; Preferences \u0026gt; General，在Selection下勾上Applications in terminal may access clipboard使在iTerm中鼠标选中就能复制到系统剪切板使用command+v粘贴\n打开iTerm2 \u0026gt; Preferences \u0026gt; Profiles，右边点Keys把左右 option 键设为Esc+，取消勾选Apps can change this来启用 Unix 的Alt + B和Alt + F前进和后退一个单词。\n打开iTerm2 \u0026gt; Preferences \u0026gt; Terminal，底部 Shell Integration 取消勾选 Show mark indicators 不然每次执行命令会出现一个小箭头影响美观\nZsh \u0026amp; Oh My Zsh 打开 iTerm 安装Homebrew\n/bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; 使用 Homebrew 安装 zsh，设为默认的终端。从 Big Sur 已经设置 zsh 为默认的终端了，可以跳过此步骤，可以使用echo $SHELL检查","title":"Mac终端(Terminal)配置"},{"content":"Systemd中Service单元介绍 Systemd是一个系统管理守护进程、工具和库的集合，用于取代System V初始进程，集中管理和配置类UNIX系统，可见它非常的强大。\nSystemd分为多个单元（unit）如服务（.service），挂载点（.mount），套接口（.socket）和设备（.device）等，这里记录使用最多的服务（service）文件的编写。用户自定义的一般存放在/etc/systemd/sytem/文件夹下，还有另外的文件夹类debian系列的如下。\nDirectory Description /lib/systemd/system/ 系统自带的或者程序自带安装的单元存放在此 /etc/systemd/system/ 用户自定义的，此文件夹优先级最高，可以覆盖上面文件夹的内容 下面是系统安装openssh-server后，在/lib/systemd/system/ssh.service下的服务。\n[Unit] Description=OpenBSD Secure Shell server After=network.target auditd.service ConditionPathExists=!/etc/ssh/sshd_not_to_be_run [Service] EnvironmentFile=-/etc/default/ssh ExecStart=/usr/sbin/sshd -D $SSHD_OPTS ExecReload=/bin/kill -HUP $MAINPID KillMode=process Restart=on-failure RestartPreventExitStatus=255 Type=notify [Install] WantedBy=multi-user.target Alias=sshd.service 如上所示一般每个Unit都有各个块(section)组成，由[]包裹就是块名。下面的就是配置，直到另一个块开始为止。\n[Unit] section\n[Unit]一般是第一个块文件配置，配置各种元数据(metadata)和其他单元的关系\nOption Description Description= 这个单元的描述字符串 Documentation= 文档链接 Requires= 运行这个单元所需要的依赖单元，否则启动失败 Wants= 和上面Requires相似，但是非强限制。如果列出在此的单元没有启动，本单元也还是能启动持续运行 BindsTo= 和上面Requires相似，区别是列出在此的单元终止了，本单元也会停止 Before= 在此列出的单元，只有在本单元启动后才会启动。但不是依赖关系，如需依赖配置上述Requires命令 After= 在启动本单元之前，先要启动在此列出的单元。但不是依赖关系，如需依赖配置上述Requires命令 Conflicts= 在此列出的单元，不能和本单元同时运行，和Requires相反 OnFailure= 在此列出的单元将会在本单元失败后激活 还有很多的如Condition...和Assert...配置详情可以查看手册man 5 systemd.unit\n[Install] section\n[Install]一般是最后一个块文件配置，这个是可选项，也就是说可以不配置。只有在开机启动激活(enable)时触发。\nOption Description WantedBy= 指定该单元如何开机启动(enable)，依赖在此列出的单元，有点类似[Unit]块中的Wants，不同的是它会创建软链接到.wants文件夹，如上sshd如果被enable，该单元会创建一个软链接到/etc/systemd/system/multi-user.target.wants文件夹下，如果文件夹不存在则创建文件夹再软链接。 RequiredBy= 和上面WantedBy类似，但如果在此列出的单元没有激活，本单元会激活失败，同样在.requires文件夹下创建软链接。 Alias= 设置改单元的别名，可以给systemctl使用，例如上面sshd的开机启动可以使用 systemctl enable ssh.service和systemctl enable sshd.service是一样的 Also= 列在此的单元，会随着本单元一起激活。 [Service] section\n以上[Unit],[Install]一般是通用的，[Service]是单独的服务配置一般在[Unit]和[Install]之间，只用来配置服务(.service)。\n其中Type=选项指定此服务的类型，Systemd通过此类型管理服务。默认Type为simple其他如下。\nsimple 默认选项，以ExecStart设置的指令运行程序。 forking 程序从ExecStartfork一个子进程，之后父进程退出。 oneshot 一次性进程和simple类似但直到程序运行退出systemd才会开始下一个单元，如果没有设置simple和ExecStart默认为oneshot dbus 通过D-Bus启动，等待D-Bus返回名称后systemd才会启动下一个单元 notify 通过sd_notify()发送一个消息通知后，systemd才会启动下一个单元 idle 所有其他单元任务执行完毕后才会启动此单元 Option Description Type= 为simple，forking，oneshot ，dbus，notify或idle ExecStart= 指定启用某个程序或者脚本的命令，如果在命令之前加-指定脚本运行非零退出也不标记faild，必须使用绝对路径 ExecStartPre= 启动程序之前执行的命令，可以指定多条。前面加-非零退出也继续执行 ExecStartPost= 启动程序后执行的命令。 ExecStop= 指定systemctl stop unit-name时运行的命令，如不指定执行stop时直接发送kill信号 ExecReload= 指定systemctl reload unit-name时运行的命令如更新配置文件 Restart= 当服务进程正常退出、异常退出、被杀死、超时的时候， 是否重新启动该服务。该值可以是 always， on-success， on-failure， on-abnormal，on-abort，或者 on-watchdog，如on-failure表示仅在服务进程异常退出时重启， 所谓\u0026quot;异常退出\u0026quot;是指： 退出码不为\u0026quot;0\u0026quot; RestartSec= 重启间隔时间 TimeoutStartSec= 配置等待启动的时间。如果守护程序服务未在配置的时间内发出启动完成信号，则该服务将被视为失败，并将再次关闭。 RemainAfterExit= 一般与Type=onshot使用，当设置为yes时，服务即使退出也为active状态，默认为no Environment= 指定环境变量 EnvironmentFile= 指定环境变量文件 还有一些可执行文件的特殊前缀，比如上面提到的-\n前缀 效果 @ 如果在绝对路径前加上可选的 \u0026ldquo;@\u0026rdquo; 前缀，则可执行文件中argv[0]为第二个参数传递给被执行的进程(而不是实际的文件名)，后面跟着指定的进一步参数。 - 如果在绝对路径前加上可选的 \u0026ldquo;-\u0026rdquo; 前缀，那么即使该进程以失败状态(例如非零的返回值或者出现异常)退出，也会被视为成功退出 + 如果在绝对路径前加上可选的 \u0026ldquo;+\u0026rdquo; 前缀，那么进程将拥有完全的权限(超级用户的特权)，并且 User=, Group=, CapabilityBoundingSet= 选项所设置的权限限制以及 PrivateDevices=, PrivateTmp= 等文件系统名字空间的配置将被该命令行启动的进程忽略(但仍然对其他 ExecStart=, ExecStop= 有效) ! 与 + 类似(进程仍然拥有超级用户的身份)，不同之处在于仅忽略 User=, Group=, SupplementaryGroups= 选项的设置，而例如名字空间之类的其他限制依然有效。注意，当与 DynamicUser= 一起使用时，将会在执行该命令之前先动态分配一对 user/group ，然后将身份凭证的切换操作留给进程自己去执行。 !! 与 ! 极其相似，仅用于让利用 ambient capability 限制进程权限的单元兼容不支持 ambient capability 的系统(也就是不支持 AmbientCapabilities= 选项)。如果在不支持 ambient capability 的系统上使用此前缀，那么 SystemCallFilter= 与 CapabilityBoundingSet= 将被隐含的自动修改为允许进程自己丢弃 capability 与特权用户的身份(即使原来被配置为禁止这么做)，并且 AmbientCapabilities= 选项将会被忽略。此前缀在支持 ambient capability 的系统上完全没有任何效果。 更具体可参考systemd.service(5)\n实例\n如下一个最简单启动脚本的例子，依赖是network-online.target\n[Unit] Description=My Miscellaneous Service Requires=network-online.target After=network-online.target [Service] Type=simple User=anonymous WorkingDirectory=/home/anonymous ExecStart=some_can_execute --option=123 Restart=on-failure [Install] WantedBy=multi-user.target 加一个守护gunicorn的服务，我一般用在部署flask应用上。\n[Unit] Description=Gunicorn instance to serve myproject Requires=network-online.target After=network.target [Service] User=project user Group=www-data # nginx group WorkingDirectory=/path/to/your/project Environment=\u0026#34;PATH=/path/to/venv/bin\u0026#34; ExecStart=/path/to/venv/bin/gunicorn --workers 4 --bind unix:ftown.sock -m 007 manage:app Restart=on-failure [Install] WantedBy=multi-user.target 如果需要添加多个环境变量一种方法是在.service文件中添加多条Environment，另一种可以创建一个以.d结尾的文件夹，存放命名local.conf的配置，如上面的service名为my-app.service则创建my-app.service.d的空文件夹，再创建my-app.service.d/local.conf文件如下\n[Service] Environment=\u0026#34;PATH=/new/path\u0026#34; Environment=\u0026#34;LD_LIBRARY_PATH=/new/path\u0026#34; ","permalink":"https://blog.fangjiahui.me/posts/2018-07-08-systemd-service-unit/","summary":"Systemd中Service单元介绍 Systemd是一个系统管理守护进程、工具和库的集合，用于取代System V初始进程，集中管理和配置类UNIX系统，可见它非常的强大。\nSystemd分为多个单元（unit）如服务（.service），挂载点（.mount），套接口（.socket）和设备（.device）等，这里记录使用最多的服务（service）文件的编写。用户自定义的一般存放在/etc/systemd/sytem/文件夹下，还有另外的文件夹类debian系列的如下。\nDirectory Description /lib/systemd/system/ 系统自带的或者程序自带安装的单元存放在此 /etc/systemd/system/ 用户自定义的，此文件夹优先级最高，可以覆盖上面文件夹的内容 下面是系统安装openssh-server后，在/lib/systemd/system/ssh.service下的服务。\n[Unit] Description=OpenBSD Secure Shell server After=network.target auditd.service ConditionPathExists=!/etc/ssh/sshd_not_to_be_run [Service] EnvironmentFile=-/etc/default/ssh ExecStart=/usr/sbin/sshd -D $SSHD_OPTS ExecReload=/bin/kill -HUP $MAINPID KillMode=process Restart=on-failure RestartPreventExitStatus=255 Type=notify [Install] WantedBy=multi-user.target Alias=sshd.service 如上所示一般每个Unit都有各个块(section)组成，由[]包裹就是块名。下面的就是配置，直到另一个块开始为止。\n[Unit] section\n[Unit]一般是第一个块文件配置，配置各种元数据(metadata)和其他单元的关系\nOption Description Description= 这个单元的描述字符串 Documentation= 文档链接 Requires= 运行这个单元所需要的依赖单元，否则启动失败 Wants= 和上面Requires相似，但是非强限制。如果列出在此的单元没有启动，本单元也还是能启动持续运行 BindsTo= 和上面Requires相似，区别是列出在此的单元终止了，本单元也会停止 Before= 在此列出的单元，只有在本单元启动后才会启动。但不是依赖关系，如需依赖配置上述Requires命令 After= 在启动本单元之前，先要启动在此列出的单元。但不是依赖关系，如需依赖配置上述Requires命令 Conflicts= 在此列出的单元，不能和本单元同时运行，和Requires相反 OnFailure= 在此列出的单元将会在本单元失败后激活 还有很多的如Condition...和Assert...配置详情可以查看手册man 5 systemd.unit\n[Install] section\n[Install]一般是最后一个块文件配置，这个是可选项，也就是说可以不配置。只有在开机启动激活(enable)时触发。\nOption Description WantedBy= 指定该单元如何开机启动(enable)，依赖在此列出的单元，有点类似[Unit]块中的Wants，不同的是它会创建软链接到.wants文件夹，如上sshd如果被enable，该单元会创建一个软链接到/etc/systemd/system/multi-user.target.wants文件夹下，如果文件夹不存在则创建文件夹再软链接。 RequiredBy= 和上面WantedBy类似，但如果在此列出的单元没有激活，本单元会激活失败，同样在.requires文件夹下创建软链接。 Alias= 设置改单元的别名，可以给systemctl使用，例如上面sshd的开机启动可以使用 systemctl enable ssh.","title":"Systemd中Service单元介绍"},{"content":"XPath语法 XPath是在XML中检索信息的语言，也就是遍历XML文档，找出有用的信息。这里记录下XPath的语法\n选取节点 XPath 使用路径表达式在 XML 文档中选取节点。节点是通过沿着路径或者 step 来选取的。\n表达式 描述 nodename 选取此节点的所有子节点 / 从根节点选取 // 从整个文档选取，不考虑它们的位置 . 选取当前节点 .. 选取当前节点的父节点 @ 选取属性 实例 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;bookstore\u0026gt; \u0026lt;book category=\u0026#34;cooking\u0026#34;\u0026gt; \u0026lt;title lang=\u0026#34;en\u0026#34;\u0026gt;Everyday Italian\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;Giada De Laurentiis\u0026lt;/author\u0026gt; \u0026lt;year\u0026gt;2005\u0026lt;/year\u0026gt; \u0026lt;price\u0026gt;30.00\u0026lt;/price\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book category=\u0026#34;children\u0026#34;\u0026gt; \u0026lt;title lang=\u0026#34;zh\u0026#34;\u0026gt;哈利波特\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;J K. Rowling\u0026lt;/author\u0026gt; \u0026lt;year\u0026gt;2005\u0026lt;/year\u0026gt; \u0026lt;price\u0026gt;29.99\u0026lt;/price\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book category=\u0026#34;web\u0026#34;\u0026gt; \u0026lt;title lang=\u0026#34;en\u0026#34;\u0026gt;XQuery Kick Start\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;James McGovern\u0026lt;/author\u0026gt; \u0026lt;author\u0026gt;Per Bothner\u0026lt;/author\u0026gt; \u0026lt;author\u0026gt;Kurt Cagle\u0026lt;/author\u0026gt; \u0026lt;author\u0026gt;James Linn\u0026lt;/author\u0026gt; \u0026lt;author\u0026gt;Vaidyanathan Nagarajan\u0026lt;/author\u0026gt; \u0026lt;year\u0026gt;2003\u0026lt;/year\u0026gt; \u0026lt;price\u0026gt;49.99\u0026lt;/price\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book category=\u0026#34;web\u0026#34; cover=\u0026#34;paperback\u0026#34;\u0026gt; \u0026lt;title lang=\u0026#34;en\u0026#34;\u0026gt;Learning XML\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;Erik T. Ray\u0026lt;/author\u0026gt; \u0026lt;year\u0026gt;2003\u0026lt;/year\u0026gt; \u0026lt;price\u0026gt;39.95\u0026lt;/price\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;/bookstore\u0026gt; 路径表达式 结果 bookstore 选取 bookstore 元素的所有子节点 /bookstore 选取根元素 bookstore/book 选取属于 bookstore 的子元素的所有 book 元素 //book 选取所有 book 子元素，而不管它们在文档中的位置 bookstore//book 选择属于 bookstore 元素的后代的所有 book 元素，而不管它们位于 bookstore 之下的什么位置。 //@lang 选取名为 lang 的所有属性 使用上面的xml文档作为测试，node.js可以使用xpath，Python可以使用lxml库\nPS: 如果在chrome调试可以直接使用$x(\u0026quot;some xpath\u0026quot;)表达式\n谓语（Predicates） 谓语用来查找某个特定的节点或者包含某个指定的值的节点，用来筛选。\n谓语被嵌在方括号中。\n实例 路径表达式 结果 /bookstore/book[1] 选取属于 bookstore 子元素的第一个 book 元素。注意索引从1开始。 /bookstore/book[last()] 选取属于 bookstore 子元素的最后一个 book 元素。 /bookstore/book[last()-1] 选取属于 bookstore 子元素的倒数第二个 book 元素。 /bookstore/book[position()\u0026lt;3] 选取最前面的两个属于 bookstore 元素的子元素的 book 元素。 //title[@lang] 选取所有拥有名为 lang 的属性的 title 元素。 //title[@lang=\u0026lsquo;en\u0026rsquo;] 选取所有 title 元素，且这些元素拥有值为 en 的 lang 属性。 /bookstore/book[price\u0026gt;35.00] 选取 bookstore 元素的所有 book 元素，且其中的 price 元素的值须大于 35.00。 /bookstore/book[price\u0026gt;35.00]/title 选取 bookstore 元素中的 book 元素的所有 title 元素，且其中的 price 元素的值须大于 35.00。 选取未知节点 XPath 通配符可用来选取未知的 XML 元素。\n通配符 描述 * 匹配任何元素节点。 @* 匹配任何属性节点。 node() 匹配任何类型的节点。 text() 匹配任何文本类型的节点。 实例 路径表达式 结果 /bookstore/* 选取 bookstore 元素的所有子元素。 //* 选取文档中的所有元素。 //title[@*] 选取所有带有属性的 title 元素。 //title/text() 选取所有title元素下的文本 选取若干路径 通过在路径表达式中使用“|”运算符，您可以选取若干个路径。\n实例 路径表达式 结果 `//book/title //book/price` `//title //price` 轴（axes） 轴可定义相对于当前节点的节点集。\n轴名称 结果 ancestor 选取当前节点的所有先辈（父、祖父等）。 ancestor-or-self 选取当前节点的所有先辈（父、祖父等）以及当前节点本身。 attribute 选取当前节点的所有属性。 child 选取当前节点的所有子元素。 descendant 选取当前节点的所有后代元素（子、孙等）。 descendant-or-self 选取当前节点的所有后代元素（子、孙等）以及当前节点本身。 following 选取文档中当前节点的结束标签之后的所有节点。 namespace 选取当前节点的所有命名空间节点。 parent 选取当前节点的父节点。 preceding 选取文档中当前节点的开始标签之前的所有节点。 preceding-sibling 选取当前节点之前的所有同级节点。 self 选取当前节点。 实例 轴的使用语法如下\n轴名称::节点测试[谓语]\n例子 结果 child::book 选取所有属于当前节点的子元素的 book 节点。 attribute::lang 选取当前节点的 lang 属性。 child::* 选取当前节点的所有子元素。 attribute::* 选取当前节点的所有属性。 child::text() 选取当前节点的所有文本子节点。 child::node() 选取当前节点的所有子节点。 descendant::book 选取当前节点的所有 book 后代。 ancestor::book 选择当前节点的所有 book 先辈。 ancestor-or-self::book 选取当前节点的所有 book 先辈以及当前节点（如果此节点是 book 节点） child::*/child::price 选取当前节点的所有 price 孙节点。 XPath 运算符 XPath支持\u0026gt;，\u0026lt;，\u0026gt;=，\u0026lt;=，or，and运算符\n实例 例子 结果 /bookstore/book[price\u0026gt;35]/title 选取 price 大于35的 title 节点 常用函数 XPaht内置了很多函数，上面我们已经接触国一些如last()、position()以下列出常用的函数，完整可以查看W3C文档\n路径表达式 结果 count(node-set) 返回节点的数量 contains(string1, string2) 返回 boolean 值，string1 是否包含 string2 的内容 last() 返回最后一个节点的索引 not(boolean) 取反 string-length(string) 返回字符长度 实例 例子 结果 count(//book[price\u0026gt;35]) 统计 price 大于 35 的 book 节点一共有几个 //book[contains(author, \u0026lsquo;Ray\u0026rsquo;)] 选取 author 节点包含 \u0026lsquo;Ray\u0026rsquo; 的 book 节点 //title[contains(@lang, \u0026lsquo;zh\u0026rsquo;)] 选取 lang 属性包含 \u0026lsquo;zh\u0026rsquo; 的 title 节点 //title[contains(text(), \u0026lsquo;波特\u0026rsquo;)] 选取 title 节点内容包含 \u0026lsquo;波特\u0026rsquo; 的 title 节点 //title[not(@lang=\u0026lsquo;en\u0026rsquo;)] 选取 lang 属性不等于 \u0026rsquo;en\u0026rsquo; 的 title 节点 string-length(//book[2]/title/text()) 第二个 book 节点中 title 节点下的文本字符长度 Reference www.w3school.com.cn docs.oracle.com ","permalink":"https://blog.fangjiahui.me/posts/2018-06-01-xpath-syntax/","summary":"XPath语法 XPath是在XML中检索信息的语言，也就是遍历XML文档，找出有用的信息。这里记录下XPath的语法\n选取节点 XPath 使用路径表达式在 XML 文档中选取节点。节点是通过沿着路径或者 step 来选取的。\n表达式 描述 nodename 选取此节点的所有子节点 / 从根节点选取 // 从整个文档选取，不考虑它们的位置 . 选取当前节点 .. 选取当前节点的父节点 @ 选取属性 实例 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;bookstore\u0026gt; \u0026lt;book category=\u0026#34;cooking\u0026#34;\u0026gt; \u0026lt;title lang=\u0026#34;en\u0026#34;\u0026gt;Everyday Italian\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;Giada De Laurentiis\u0026lt;/author\u0026gt; \u0026lt;year\u0026gt;2005\u0026lt;/year\u0026gt; \u0026lt;price\u0026gt;30.00\u0026lt;/price\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book category=\u0026#34;children\u0026#34;\u0026gt; \u0026lt;title lang=\u0026#34;zh\u0026#34;\u0026gt;哈利波特\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;J K. Rowling\u0026lt;/author\u0026gt; \u0026lt;year\u0026gt;2005\u0026lt;/year\u0026gt; \u0026lt;price\u0026gt;29.99\u0026lt;/price\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book category=\u0026#34;web\u0026#34;\u0026gt; \u0026lt;title lang=\u0026#34;en\u0026#34;\u0026gt;XQuery Kick Start\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;James McGovern\u0026lt;/author\u0026gt; \u0026lt;author\u0026gt;Per Bothner\u0026lt;/author\u0026gt; \u0026lt;author\u0026gt;Kurt Cagle\u0026lt;/author\u0026gt; \u0026lt;author\u0026gt;James Linn\u0026lt;/author\u0026gt; \u0026lt;author\u0026gt;Vaidyanathan Nagarajan\u0026lt;/author\u0026gt; \u0026lt;year\u0026gt;2003\u0026lt;/year\u0026gt; \u0026lt;price\u0026gt;49.99\u0026lt;/price\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book category=\u0026#34;web\u0026#34; cover=\u0026#34;paperback\u0026#34;\u0026gt; \u0026lt;title lang=\u0026#34;en\u0026#34;\u0026gt;Learning XML\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;Erik T.","title":"XPath语法"},{"content":"使用 usb 转 TTL(PL2303 模块) 串口连接树莓派 3B By default, on Raspberry Pis equipped with the wireless/Bluetooth module (Raspberry Pi 3 and Raspberry Pi Zero W), the PL011 UART is connected to the BT module, while the mini UART is used for Linux console output. On all other models the PL011 is used for the Linux console output.\n在树莓派 3 以前，官方是将“硬件串口”分配给 GPIO 中的 UART(GPIO14\u0026amp;GPIO15)，因此可以独立调整串口的速率和模式，直接连接就可以。而在 3 以后的树莓派中因为新增了蓝牙使用掉了 UART。这样默认就不开启了，以下是手动开启的方法。\n使用 HDMI 启动树莓派编辑/boot/config.txt在后面新增以下两行\n# 激活串口输出 enable_uart=1 # 禁用蓝牙 dtoverlay=pi3-disable-bt 运行sudo systemctl disable hciuart禁用蓝牙服务，然后重启\n运行ls -l /dev/serial*查看是否是这个样子\npi@raspberrypi:~$ ls -l /dev/serial* lrwxrwxrwx 1 root root 7 Mar 13 23:23 /dev/serial0 -\u0026gt; ttyAMA0 lrwxrwxrwx 1 root root 5 Mar 13 23:23 /dev/serial1 -\u0026gt; ttyS0 以上就是树莓派上所有的设置了，mac 和 windows 如何使用 PL2303 模块连接请参考以下链接\nMac\nhttps://pbxbook.com/other/mac-tty.html\nWindows\nhttps://blog.csdn.net/cugbabybear/article/details/23048741\nReference https://www.raspberrypi.org ","permalink":"https://blog.fangjiahui.me/posts/2018-04-02-raspberry-pi-3b-uart-serial-connect/","summary":"使用 usb 转 TTL(PL2303 模块) 串口连接树莓派 3B By default, on Raspberry Pis equipped with the wireless/Bluetooth module (Raspberry Pi 3 and Raspberry Pi Zero W), the PL011 UART is connected to the BT module, while the mini UART is used for Linux console output. On all other models the PL011 is used for the Linux console output.\n在树莓派 3 以前，官方是将“硬件串口”分配给 GPIO 中的 UART(GPIO14\u0026amp;GPIO15)，因此可以独立调整串口的速率和模式，直接连接就可以。而在 3 以后的树莓派中因为新增了蓝牙使用掉了 UART。这样默认就不开启了，以下是手动开启的方法。\n使用 HDMI 启动树莓派编辑/boot/config.txt在后面新增以下两行\n# 激活串口输出 enable_uart=1 # 禁用蓝牙 dtoverlay=pi3-disable-bt 运行sudo systemctl disable hciuart禁用蓝牙服务，然后重启","title":"使用usb转TTL(PL2303模块) 串口连接树莓派3B"},{"content":"collections模块中的namedtuple和defaultdict collections模块是Python中对内置类型(dict, list, tuple)的拓展。就是说它们本身具有普通内置类型的所有特性，并添加了新的功能。\nnamedtuple() namedtuple(typename, field_names)是tuple的子类，定义的元组可以通过属性访问，也易于理解，self-document。field_names可以是列表或者是通过空格或者逗号分隔的字符串。\n\u0026gt;\u0026gt;\u0026gt; from collections import namedtuple \u0026gt;\u0026gt;\u0026gt; Point = namedtuple(\u0026#39;point\u0026#39;, \u0026#39;x, y\u0026#39;) \u0026gt;\u0026gt;\u0026gt; p = Point(3, y=4) \u0026gt;\u0026gt;\u0026gt; p point(x=3, y=4) \u0026gt;\u0026gt;\u0026gt; p[0] 3 \u0026gt;\u0026gt;\u0026gt; p.x 3 \u0026gt;\u0026gt;\u0026gt; x, y = p \u0026gt;\u0026gt;\u0026gt; print(x, y) 3 4 namedtuple有几个比较有用的方法和属性\nSomeNamedTuple._make(iterable)类方法，从可迭代对象中取值，长度必须和传入的field_names一致，返回一个新的对象 somenamedtuple._asdict()方法返回一个有序字典(OrderedDict) somenamedtuple._replace(**kwargs)方法替换值，返回一个新的对象，原来的不变 somenamedtuple._fields属性返回键名(field name)，可用于创建新的named tuple 再来看两个官方文档上的例子读取csv文件或者从sqlite读取\nEmployeeRecord = namedtuple(\u0026#39;EmployeeRecord\u0026#39;, \u0026#39;name, age, title, department, paygrade\u0026#39;) import csv for emp in map(EmployeeRecord._make, csv.reader(open(\u0026#34;employees.csv\u0026#34;, \u0026#34;rb\u0026#34;))): print(emp.name, emp.title) import sqlite3 conn = sqlite3.connect(\u0026#39;/companydata\u0026#39;) cursor = conn.cursor() cursor.execute(\u0026#39;SELECT name, age, title, department, paygrade FROM employees\u0026#39;) for emp in map(EmployeeRecord._make, cursor.fetchall()): print(emp.name, emp.title) defaultdict defaultdict([default_factory[,...]])顾名思义继承自dict它接收一个函数(default_factory)作为参数但它除了dict所有的属性和方法外，另外加了__missing__方法和default_factory属性。这两个的作用就是访问不存在的key时它会新增一个key，value为调用default_factory的值。\n\u0026gt;\u0026gt;\u0026gt; from collections import defaultdict \u0026gt;\u0026gt;\u0026gt; d = defaultdict(list) # 默认函数为list \u0026gt;\u0026gt;\u0026gt; print(d.items()) # 创建空字典 dict_items([]) \u0026gt;\u0026gt;\u0026gt; d.default_factory \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; d[\u0026#39;key\u0026#39;] # 调用会设置该key的值为空list并返回 [] \u0026gt;\u0026gt;\u0026gt; print(d.items()) dict_items([(\u0026#39;key\u0026#39;, [])]) 我们可以利用这个特性来做很多事，比如说给一个包含元组的的列表分类整理。\n\u0026gt;\u0026gt;\u0026gt; s = [(\u0026#39;yellow\u0026#39;, 1), (\u0026#39;blue\u0026#39;, 2), (\u0026#39;yellow\u0026#39;, 3), (\u0026#39;blue\u0026#39;, 4), (\u0026#39;red\u0026#39;, 1)] \u0026gt;\u0026gt;\u0026gt; d = defaultdict(list) \u0026gt;\u0026gt;\u0026gt; for k, v in s: ... d[k].append(v) \u0026gt;\u0026gt;\u0026gt; sorted(d.items()) [(\u0026#39;blue\u0026#39;, [2, 4]), (\u0026#39;red\u0026#39;, [1]), (\u0026#39;yellow\u0026#39;, [1, 3])] 上面的代码其实可以用dict的setdefault实现，但效率和可读性差点，如下\n\u0026gt;\u0026gt;\u0026gt; d = {} \u0026gt;\u0026gt;\u0026gt; for k, v in s: ... d.setdefault(k, []).append(v) \u0026gt;\u0026gt;\u0026gt; sorted(d.items()) [(\u0026#39;blue\u0026#39;, [2, 4]), (\u0026#39;red\u0026#39;, [1]), (\u0026#39;yellow\u0026#39;, [1, 3])] 最后看一下自定义default_factory参数\n\u0026gt;\u0026gt;\u0026gt; def constant_factory(value): ... return lambda: value \u0026gt;\u0026gt;\u0026gt; d = defaultdict(constant_factory(\u0026#39;\u0026lt;missing\u0026gt;\u0026#39;)) \u0026gt;\u0026gt;\u0026gt; d.update(name=\u0026#39;John\u0026#39;, action=\u0026#39;ran\u0026#39;) \u0026gt;\u0026gt;\u0026gt; \u0026#39;%(name)s %(action)s to %(object)s\u0026#39; % d \u0026#39;John ran to \u0026lt;missing\u0026gt;\u0026#39; 一个是比较讨巧的例子，利用了递归。\n\u0026gt;\u0026gt;\u0026gt; tree = lambda: defaultdict(tree) \u0026gt;\u0026gt;\u0026gt; d = tree() \u0026gt;\u0026gt;\u0026gt; d[\u0026#39;colours\u0026#39;][\u0026#39;favourite\u0026#39;] = \u0026#39;yellow\u0026#39; \u0026gt;\u0026gt;\u0026gt; d[\u0026#39;animals\u0026#39;][\u0026#39;pets\u0026#39;][\u0026#39;name\u0026#39;] = [\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;] \u0026gt;\u0026gt;\u0026gt; import json \u0026gt;\u0026gt;\u0026gt; print(json.dumps(d)) {\u0026#34;colours\u0026#34;: {\u0026#34;favourite\u0026#34;: \u0026#34;yellow\u0026#34;}, \u0026#34;animals\u0026#34;: {\u0026#34;pets\u0026#34;: {\u0026#34;name\u0026#34;: [\u0026#34;cat\u0026#34;, \u0026#34;dog\u0026#34;]}}} References https://docs.python.org/ https://github.com/ ","permalink":"https://blog.fangjiahui.me/posts/2018-02-09-python-collections-namedtuple-and-defaultdict/","summary":"collections模块中的namedtuple和defaultdict collections模块是Python中对内置类型(dict, list, tuple)的拓展。就是说它们本身具有普通内置类型的所有特性，并添加了新的功能。\nnamedtuple() namedtuple(typename, field_names)是tuple的子类，定义的元组可以通过属性访问，也易于理解，self-document。field_names可以是列表或者是通过空格或者逗号分隔的字符串。\n\u0026gt;\u0026gt;\u0026gt; from collections import namedtuple \u0026gt;\u0026gt;\u0026gt; Point = namedtuple(\u0026#39;point\u0026#39;, \u0026#39;x, y\u0026#39;) \u0026gt;\u0026gt;\u0026gt; p = Point(3, y=4) \u0026gt;\u0026gt;\u0026gt; p point(x=3, y=4) \u0026gt;\u0026gt;\u0026gt; p[0] 3 \u0026gt;\u0026gt;\u0026gt; p.x 3 \u0026gt;\u0026gt;\u0026gt; x, y = p \u0026gt;\u0026gt;\u0026gt; print(x, y) 3 4 namedtuple有几个比较有用的方法和属性\nSomeNamedTuple._make(iterable)类方法，从可迭代对象中取值，长度必须和传入的field_names一致，返回一个新的对象 somenamedtuple._asdict()方法返回一个有序字典(OrderedDict) somenamedtuple._replace(**kwargs)方法替换值，返回一个新的对象，原来的不变 somenamedtuple._fields属性返回键名(field name)，可用于创建新的named tuple 再来看两个官方文档上的例子读取csv文件或者从sqlite读取\nEmployeeRecord = namedtuple(\u0026#39;EmployeeRecord\u0026#39;, \u0026#39;name, age, title, department, paygrade\u0026#39;) import csv for emp in map(EmployeeRecord._make, csv.reader(open(\u0026#34;employees.csv\u0026#34;, \u0026#34;rb\u0026#34;))): print(emp.name, emp.title) import sqlite3 conn = sqlite3.","title":"collections模块中的namedtuple和defaultdict"},{"content":"Python 中的特殊方法 python 在定义 class 时有很多特殊方法可以定义，它们一般都是以双下划线开头和结尾如__init__、__call__、__lt__、__iter__、__setattr__、__setitem__等，下面将对这些常用方法作一些总结。\nclass 基本方法 __new__(cls[, ...]) 我们都知道__init__会在类初始化的时候被调用其实它不是第一个被调用的，第一个是__new__会在对象创建的时候被调用，这时还没有实例化所以它的第一个参数是cls。\n__init__(self[, ...]) 最常用的类方法不用过多介绍，对象初始化时自动调用，也就是在__new__之后才会调用。第一个参数是self实例本身。有一点要注意的是它不能返回(return)值，不然会报TypeError记住它是用来初始化对象的。\nclass A: def __new__(cls): print(\u0026#39;__new__ called\u0026#39;) return super(A, cls).__new__(cls) def __init__(self): print(\u0026#39;__init__ called\u0026#39;) a = A() 返回如下，注意这是 Python3 的写法默认A继承自object，如果使用 Python2 的需要指定A继承自object基类，使用新类。不然__new__是不会被调用的。\n__new__ called __init__ called 需要注意的是上面我们定义了__new__接收类对象(cls)，必须返回return super(A, cls).__new__(cls)这个类实例也就是下面方法的self，因为__new__会被首先调用返回实例对象以供下面的方法如__init__这些使用。如果去掉这一句其他方法会返回None。默认未定义__new__方法时，默认返回父类实例super().__new__(cls, *args, **kwargs)\n__str__(self) 调用print(obj)或str(obj)时返回的字符串是对人类友好的(human readable string)。\n__repr__(self) 调用repr(obj)或obj返回的字符串，比较偏向机器。\n__format__(self, format_spec) 调用f string或format时调用，format(value, format_spec)相当于value.__format__(format_spec)\nclass Animal: def __init__(self, name): self.name = name def __format__(self, format_spec): if format_spec == \u0026#39;view\u0026#39;: return f\u0026#34;this is {self.name}\u0026#34; else: raise ValueError(\u0026#39;invalid format spec.\u0026#39;) dog = Animal(\u0026#39;Labrador\u0026#39;) print(format(dog, \u0026#34;view\u0026#34;)) print(\u0026#34;{0:view}\u0026#34;.format(dog)) print(f\u0026#34;{dog:view}\u0026#34;) 三种方式返回都一样如下\nthis is Labrador this is Labrador this is Labrador __bytes__(self) 调用bytes(obj)时返回，返回对象必须是bytes\n__bool__(self) 调用bool(obj)时返回，返回值是True或者False，在 python2 中方法名为__nonzero__。如果调用bool(obj)时，没有定义__boo__时会会去调用__len__方法返回非零为True，如果这两个方法都没有定义那么默认返回True。\n比较(comparison) __lt__(sel, other) 小于\n__le__(self, other) 小于等于\n__eq__(self, other) 等于\n__ne__(self, other) 不等于\n__gt__(self, other) 大于\n__ge__(self, other) 大于等于\nPython2 中有__cmp__方法和cmp()函数，在 Python3 中已经废弃没有了代替的是以上 6 个方法分别对应\u0026lt;，\u0026lt;=，==，!=，\u0026gt;，\u0026gt;=操作符时返回的值，通常情况下要求返回True或False，但其实可以返回任何值。在if语句中如果返回非True或False，会自动对返回调用bool来判断。\n哈希 __hash__(self) 调用hash(obj)时返回的值，是一个整数。当两个对象是相等(==)时，他们的 hash 值也必定相等也就是hash(obj) == hash(obj)为True。\n使用hash时记得定义eq方法\n描述符(descriptor) 描述符属于 py 中比较高级的主题，单独记录了一篇文章，以下只列出特殊方法\n__get__(self, instance, owner=None) 用于访问属性，返回属性的值。\n__set__(self, instance, value) 将在属性分配操作中调用。不会返回任何内容。\n__delete__(self, instance) 控制删除操作。不会返回内容。\n__set_name__(self, owner, name) Python3.6 中对描述符新增的方法，在owner创建时被调用，给描述符命名。\n属性(attribute) __getattr__(self, name) 当访问属性没有按正常检索顺序检索到时被调用的方法。\nclass A: def __getattr__(self, name): if name == \u0026#39;foo\u0026#39;: return \u0026#39;foo attribute\u0026#39; else: raise AttributeError a= A() print(a.foo) a.foo = 8 #正常赋值 print(a.foo) print(a.bar) 返回如下，只有在没有被检索到时才会被调用。\nfoo attribute 8 Traceback (most recent call last): File \u0026#34;/Users/fython/Documents/testDemo/test.py\u0026#34;, line 12, in \u0026lt;module\u0026gt; print(a.bar) File \u0026#34;/Users/fython/Documents/testDemo/test.py\u0026#34;, line 6, in __getattr__ raise AttributeError AttributeError __getattribute__(self, name) 无论访问存在或者不存在的属性时都会被调用，即使访问对象方法时也会被调用，所以这个是无条件优先级最高的使用这个方法要十分小心防止进入无限循环调用\nclass A: def __init__(self): self.foo = \u0026#39;foo\u0026#39; def __getattribute__(self, name): return self.__dict__[name] def __getattr__(self, name): return \u0026#39;default\u0026#39; def bar(self): return \u0026#39;test normal method\u0026#39; a= A() print(a.foo) # 访问存在的属性 print(a.fake_foo) # 访问不存在的属性 print(a.bar()) # 调用方法 如上就会掉入__getattribute__的陷阱，以上三种调用方式都会引发无限循环引用RecursionError。因为__getattribute__第一个被调用返回self.__dict__[name]，这就等于又去访问self的__dict__属性，又会陷入__getattribute__方法，循环不断。。。。就算定义了__getattr__方法也是会被忽略。值得注意的是调用其他方法a.bar()也会出问题。那么如何解决呢，一般都是调用基类相同方法就可以，可以用super实现。\nclass A: ... def __getattribute__(self, name): if name == \u0026#39;fake_foo\u0026#39;: return \u0026#39;fake_foo\u0026#39; else: return super(A, self).__getattribute__(name) ... 改成以上的运行就没有什么问题\nfoo fake_foo test normal method __setattr__(self, name, value) 在对象属性被赋值时被调用的方法，这也容易引发无限循环调用\nclass A: def __setattr__(self, name, value): self.name = value a= A() a.foo = \u0026#39;foo\u0026#39; # 无限循环 和之前一样self.name = value又会调用__setattr__，解决方法也是一样换成super(A, self).__setattr__(name, value)\nclass A: def __setattr__(self, name, value): if isinstance(value, str): return super(A, self).__setattr__(name, value + \u0026#39;_suffix\u0026#39;) else: raise TypeError a= A() a.foo = \u0026#39;foo\u0026#39; print(a.foo) # 返回\u0026#34;foo_suffix\u0026#34; __delattr__(self, name) 属性删除，一样有循环引用的问题(return del self.name)，记得用super()解决。\n类创建 __init_subclass__(cls) 这是 python3.6 中新加的方法，它会在以这个类为基类创建子类时被调用。cls是新的子类。\nclass Philosopher: def __init_subclass__(cls, default_name, **kwargs): super().__init_subclass__(**kwargs) cls.default_name = default_name class AustralianPhilosopher(Philosopher, default_name=\u0026#34;Bruce\u0026#34;): pass print(AustralianPhilosopher.default_name) AustralianPhilosopher继承自Philosopher而后者定义了__init_subclass__，此方法接收子类定义时继承的参数。\n可调用对象(callable objects) __call__(self[,args...]) 使实例对象可以像函数一样调用，x(arg1, arg2, ...)就等于调用x.__call__(arg1, arg2, ...)\nclass A: def __call__(self, *args, **kwargs): print(args, kwargs) a = A() a(\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, c=\u0026#39;d\u0026#39;) # 可被调用 输出(\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;) {\u0026#39;c\u0026#39;: \u0026#39;d\u0026#39;} 容器(container)类型 容器类代表的是 sequences(list, tuples)，mappings(dict, set)\n__len__(self) 当调用len()时会调用，应该返回对象的长度是一个整数。\n__getitem__(self, key) 当调用self[key]时会调用，对于 sequences 类来说 key 是索引值\n__setitem__(self, key, value) 当self[key]被赋值时会调用。\n__delitem__(self, key) 当del self[key]时被调用\n__missing__(self, key) 当调用self[key]时__gititem__字典中间值不存在时返回的值\nclass A: def __setitem__(self, key, value): if key == \u0026#39;foo\u0026#39;: self.__dict__[key] = \u0026#39;value\u0026#39; else: self.__dict__[key] = value def __getitem__(self, key): if key == \u0026#39;bar\u0026#39;: return \u0026#39;custom value\u0026#39; else: return self.__dict__[key] def __delitem__(self, key): del self.__dict__[key] a = A() a[\u0026#39;foo\u0026#39;] = 1234 # 调用__setitem__ print(a[\u0026#39;foo\u0026#39;]) # \u0026#34;value\u0026#34; print(a[\u0026#39;bar\u0026#39;]) # \u0026#34;custom value\u0026#34; del a[\u0026#39;foo\u0026#39;] print(a[\u0026#39;foo\u0026#39;]) # rasie KeyError __reversed__(self) 当调用reversed()时被调用，返回一个与之前相反的序列列表。\n__contains__(self, item) 当调用in或not in时返回的值，检测元素或者 key 是否存在于列表或字典中。返回True或False。\n__iter__(self) 当定义了一个__iter__方法后，这个对象就是可迭代的(iterable)，也就是说可以用于for这种循环。该方法应该返回一个新的可迭代对象(函数iter可生成)。\n__next__(self) 当一个对象即定义了__iter__又定义了__next__方法后，我们称它为迭代器(iterator)，注意与上面 iterable 的区别。本质上是 iterator 可以使用next(obj)来调用而 iterable 对象不可以。但双方都可以用for循环迭代。\nclass MyIterator: def __init__(self, letters): self.letters = letters self.position = 0 def __iter__(self): return self # 注意这里 def __next__(self): if self.position \u0026gt; len(self.letters) - 1: raise StopIteration rs = self.letters[self.position] self.position += 1 return rs m = MyIterator(\u0026#39;abcdefg\u0026#39;) for i in m: print(i, end=\u0026#39;, \u0026#39;) # a, b, c, d, e, f, g, n = MyIterator(\u0026#39;xy\u0026#39;) print(next(n)) # x print(next(n)) # y print(next(n)) # raise StopIteration 上面就是一个迭代器同时定义了__iter__和__next__方法。注意两个都定义时在__iter__中只要返回self本身就可以了。\n__reversed__(self) 当调用reversed()时被调用，返回一个与之前相反的序列列表。\n用户定义的函数（functions） __doc__ 用户定义的文档，没有就返回None\n__name__ 函数名\n__closure__ 用户定义的函数都有一个__closure__属性，如果这个函数是一个闭包的话，那么它返回的是一个由cell对象组成的元组对象。cell对象的cell_contents属性就是闭包中的自由变量。\ndef foo(): a = \u0026#39;hello world\u0026#39; b = 1.0 def bar(c): return a, b, c return bar x = foo() # closure print([i.cell_contents for i in x.__closure__]) # [\u0026#39;hello world\u0026#39;, 1.0] 上面 x 就是一个闭包里面包含了bar函数和a,b变量。\nReference http://spyhce.com/ https://docs.python.org/ https://stackoverflow.com/ https://www.blog.pythonlibrary.org/ ","permalink":"https://blog.fangjiahui.me/posts/2018-01-28-python-magical-special-methods/","summary":"Python 中的特殊方法 python 在定义 class 时有很多特殊方法可以定义，它们一般都是以双下划线开头和结尾如__init__、__call__、__lt__、__iter__、__setattr__、__setitem__等，下面将对这些常用方法作一些总结。\nclass 基本方法 __new__(cls[, ...]) 我们都知道__init__会在类初始化的时候被调用其实它不是第一个被调用的，第一个是__new__会在对象创建的时候被调用，这时还没有实例化所以它的第一个参数是cls。\n__init__(self[, ...]) 最常用的类方法不用过多介绍，对象初始化时自动调用，也就是在__new__之后才会调用。第一个参数是self实例本身。有一点要注意的是它不能返回(return)值，不然会报TypeError记住它是用来初始化对象的。\nclass A: def __new__(cls): print(\u0026#39;__new__ called\u0026#39;) return super(A, cls).__new__(cls) def __init__(self): print(\u0026#39;__init__ called\u0026#39;) a = A() 返回如下，注意这是 Python3 的写法默认A继承自object，如果使用 Python2 的需要指定A继承自object基类，使用新类。不然__new__是不会被调用的。\n__new__ called __init__ called 需要注意的是上面我们定义了__new__接收类对象(cls)，必须返回return super(A, cls).__new__(cls)这个类实例也就是下面方法的self，因为__new__会被首先调用返回实例对象以供下面的方法如__init__这些使用。如果去掉这一句其他方法会返回None。默认未定义__new__方法时，默认返回父类实例super().__new__(cls, *args, **kwargs)\n__str__(self) 调用print(obj)或str(obj)时返回的字符串是对人类友好的(human readable string)。\n__repr__(self) 调用repr(obj)或obj返回的字符串，比较偏向机器。\n__format__(self, format_spec) 调用f string或format时调用，format(value, format_spec)相当于value.__format__(format_spec)\nclass Animal: def __init__(self, name): self.name = name def __format__(self, format_spec): if format_spec == \u0026#39;view\u0026#39;: return f\u0026#34;this is {self.","title":"Python中的特殊方法"},{"content":"0x01. ssh-agent转发 经常使用SSH而且私钥设置了passphrase的同学会遇到一个问题，就是每次登录主机都要输入一遍passphrase会很麻烦，这时ssh-agent命令就有用了。\nssh-agent是OpenSSH默认自带的并且在后台一直运行的daemon。假设已经通过ssh-keygen生成了自己的私钥，可以在GitHub上传公钥后使用ssh -T git@github.com命令测试通过。\n$ ssh-agent SSH_AUTH_SOCK=/var/folders/k6/k5s6nj_j2k70jzp7plv120y40000gn/T//ssh-fcn9OCl9La13/agent.2462; export SSH_AUTH_SOCK; SSH_AGENT_PID=2463; export SSH_AGENT_PID; echo Agent pid 2463; 但上面的命令没用，我们需要eval命令导入环境变量\n$ eval $(ssh-agent) Agent pid 2533 $ echo $SSH_AGENT_PID 2553 $ echo $SSH_AUTH_SOCK /var/folders/k6/k5s6nj_j2k70jzp7plv120y40000gn/T//ssh-6bHKwvKJ6AO1/agent.2532 ssh-agent已经运行了，最后需要把私钥加入cache。\n$ ssh-add ~/.ssh/id_rsa Enter passphrase for /Users/fython/.ssh/id_rsa: Identity added: /Users/fython/.ssh/id_rsa (/Users/fython/.ssh/id_rsa) 可以使用ssh-add -l查看缓存的私钥。现在再登录使用公钥认证的主机不需要输入passphrase了。\n这个每次开机都要运行一遍上面的命令好像有点麻烦，值得高兴的是大多数的linux发行版都在登录图形界面时都会启动一个ssh-agent进程，你不需要任何操作，可以使用ps -ef | grep ssh-agent查看。如果你的系统没有这个功能，请在~/.xsession文件中加入：\nssh-agent gnome-session Note：请使用你自己的窗口管理器取代gnome-session。\n本人使用Arch，i3桌面环境的时候需要在～/.profile中加入才能启用\nexport $(gnome-keyring-daemon --start --components=secrets,ssh) 0x02. 使用SSH agent forwarding多机器转发 设想一下当你有两台server如A和B，你都可以ssh上去但你已经登入了上了A想从A上面ssh到B又不想将私钥上传到A该怎么办，一个很好的办法是开启ForwardAgent yes。\n修改全局配置/etc/ssh/ssh_config或修改个人~/.ssh/config配置推荐第二种，没有就新建文件，然后加入\nHost * ForwardAgent yes 最后去A和B服务器上~/.ssh/config也加入如上的配置。现在可以愉快的在A上免密连接到B了，当然在B上面也可以ssh到A，其实只要在服务器配置中加入了ForwardAgent yes这样就能传递了。\n0x03. 在MacOS上的设置 由于MacOS上每次开机都会忘记Key，只要在~/.ssh/config中添加如下配置即可和实现上面的效果\nHost * AddKeysToAgent yes UseKeychain yes ForwardAgent yes IdentityFile ~/.ssh/id_rsa 或者手动运行ssh-add -K yourkey将key加入到Keychain也可以。\n参考 https://wiki.archlinux.org/index.php/SSH_keys\nhttp://mah.everybody.org/docs/ssh\nhttps://developer.github.com/v3/guides/using-ssh-agent-forwarding/\n","permalink":"https://blog.fangjiahui.me/posts/2017-12-27-ssh-agent-and-ssh-agent-forwarding/","summary":"0x01. ssh-agent转发 经常使用SSH而且私钥设置了passphrase的同学会遇到一个问题，就是每次登录主机都要输入一遍passphrase会很麻烦，这时ssh-agent命令就有用了。\nssh-agent是OpenSSH默认自带的并且在后台一直运行的daemon。假设已经通过ssh-keygen生成了自己的私钥，可以在GitHub上传公钥后使用ssh -T git@github.com命令测试通过。\n$ ssh-agent SSH_AUTH_SOCK=/var/folders/k6/k5s6nj_j2k70jzp7plv120y40000gn/T//ssh-fcn9OCl9La13/agent.2462; export SSH_AUTH_SOCK; SSH_AGENT_PID=2463; export SSH_AGENT_PID; echo Agent pid 2463; 但上面的命令没用，我们需要eval命令导入环境变量\n$ eval $(ssh-agent) Agent pid 2533 $ echo $SSH_AGENT_PID 2553 $ echo $SSH_AUTH_SOCK /var/folders/k6/k5s6nj_j2k70jzp7plv120y40000gn/T//ssh-6bHKwvKJ6AO1/agent.2532 ssh-agent已经运行了，最后需要把私钥加入cache。\n$ ssh-add ~/.ssh/id_rsa Enter passphrase for /Users/fython/.ssh/id_rsa: Identity added: /Users/fython/.ssh/id_rsa (/Users/fython/.ssh/id_rsa) 可以使用ssh-add -l查看缓存的私钥。现在再登录使用公钥认证的主机不需要输入passphrase了。\n这个每次开机都要运行一遍上面的命令好像有点麻烦，值得高兴的是大多数的linux发行版都在登录图形界面时都会启动一个ssh-agent进程，你不需要任何操作，可以使用ps -ef | grep ssh-agent查看。如果你的系统没有这个功能，请在~/.xsession文件中加入：\nssh-agent gnome-session Note：请使用你自己的窗口管理器取代gnome-session。\n本人使用Arch，i3桌面环境的时候需要在～/.profile中加入才能启用\nexport $(gnome-keyring-daemon --start --components=secrets,ssh) 0x02. 使用SSH agent forwarding多机器转发 设想一下当你有两台server如A和B，你都可以ssh上去但你已经登入了上了A想从A上面ssh到B又不想将私钥上传到A该怎么办，一个很好的办法是开启ForwardAgent yes。\n修改全局配置/etc/ssh/ssh_config或修改个人~/.ssh/config配置推荐第二种，没有就新建文件，然后加入\nHost * ForwardAgent yes 最后去A和B服务器上~/.","title":"配置SSH agent 和 SSH agent forwarding转发"},{"content":"Git是当今最流行的开源版本控制系统，使用git的每个团队应该也有固定的工作流。今天就介绍一个现有普遍使用的工作流git-flow。\n分支（branch） 如上图一般分支有*master、develop、feature/xxx、release/xxx、hotfixes*，下面一一介绍。\n长期分支 长期分支是跟着产品长期存在的不会删除。\n*master*只能用来包括产品代码，不要在这上面做任何的改动。\n*develop开发主分支，所有新功能的分支从这里checkout，所以这是开发的基础分支。该分支也是汇集所有开发新功能后最后merge到master*的分支。\n临时分支 临时分支只用来开发新功能、修复bug和发布产品用最后删除。\n*feature/xxx开发新功能的分支从develop分支checkout每个功能创建一个分支是一个良好的习惯。开发测试完后merge到develop*分支进行更全面的测试。\n*release/xxx产品预发布分支，一般以版本号为分支名，需要合并到master*分支发布。\n*hotfixes紧急修复bug的分支基于master分支，修复完后一定要合并到master分支和develop*分支。\nGit-flow工作流程 基本步骤 开发人员首先从*develop*分支checkout -b feature/xxx一个待开发的分支，开发和测试。 当开发和测试都完成后将*feature/xxx合并到develop并删除清理。当然其中有新功能时可以再新建一个feature*分支并最后合并到开发分支。 终于等到release了，现在开发分支汇集了所有新开发的功能并无重大bug，我们从*develop分支checkout一个release/v1.0.0的分支进行更加全面的测试准备发布，有bug就在release分支修复，正式发布就是把这个release分支合并到master分支打上tag。当然不要忘记将发布分支合并到develop分支以保持和master*代码同步一致。 可能发布后有紧急的bug需要修复那就从*master分支checkout一个hotfixes/missing-link分支修复bug并合并到master和develop*最后删除。 总结一下 以上就是Git-flow方案的所有流程，优点是分支清晰各干各的看名字就知道，最后只留下*master和develop*分枝。缺点当然是步骤比较繁琐咯，开发要新建很多分支然后切换和删除。我们可以还有很多方案选择GitHub flow、GitLab flow等，或者理解熟练了之后自创一套也是可以的。\nGitHub协同工作 身为一个开发者一定想为开源项目贡献自己的代码，下面是基本步骤可做参考。也可以作为团队协作的基本流程。\nFork到自己帐号下并Clone到本地 git remote add upstream https://github.com/... 添加上游项目地址（源项目地址）以便更新到最新的代码，添加完可用git remote -v查看除了origin应该还有upstream远程地址 git pull upstream master从刚才添加的upstream拉取最新代码 git checkout -b feature/some-feature 新建一个你要添加新功能的分支，开发就在这上面进行 git add . \u0026amp;\u0026amp; git commit -m 'some feature add'测试通过后提交代码 git checkout master \u0026amp;\u0026amp; git pull upstream master这主要是从源仓库拉取最新代码，在你开发期间，如果源项目有改动提交pull就能拉取下来 git checkout feature/some-feature \u0026amp;\u0026amp; git rebase master 然后执行一次变基更新代码 git push origin feature/some-feature推送你开发完并更新到最新的分支到GitHub 去自己GitHub帐号下 pull request等review合并 一具话就是先在本地新建一个分支开发最后提交这个分支发PR，需要注意的是提交到远程的时候记得先pull更新代码然后rebase使分支清晰可读。\n参考 https://datasift.github.io/\nhttps://www.git-tower.com/\nhttp://www.ruanyifeng.com/\n","permalink":"https://blog.fangjiahui.me/posts/2017-11-21-git-workflow/","summary":"Git是当今最流行的开源版本控制系统，使用git的每个团队应该也有固定的工作流。今天就介绍一个现有普遍使用的工作流git-flow。\n分支（branch） 如上图一般分支有*master、develop、feature/xxx、release/xxx、hotfixes*，下面一一介绍。\n长期分支 长期分支是跟着产品长期存在的不会删除。\n*master*只能用来包括产品代码，不要在这上面做任何的改动。\n*develop开发主分支，所有新功能的分支从这里checkout，所以这是开发的基础分支。该分支也是汇集所有开发新功能后最后merge到master*的分支。\n临时分支 临时分支只用来开发新功能、修复bug和发布产品用最后删除。\n*feature/xxx开发新功能的分支从develop分支checkout每个功能创建一个分支是一个良好的习惯。开发测试完后merge到develop*分支进行更全面的测试。\n*release/xxx产品预发布分支，一般以版本号为分支名，需要合并到master*分支发布。\n*hotfixes紧急修复bug的分支基于master分支，修复完后一定要合并到master分支和develop*分支。\nGit-flow工作流程 基本步骤 开发人员首先从*develop*分支checkout -b feature/xxx一个待开发的分支，开发和测试。 当开发和测试都完成后将*feature/xxx合并到develop并删除清理。当然其中有新功能时可以再新建一个feature*分支并最后合并到开发分支。 终于等到release了，现在开发分支汇集了所有新开发的功能并无重大bug，我们从*develop分支checkout一个release/v1.0.0的分支进行更加全面的测试准备发布，有bug就在release分支修复，正式发布就是把这个release分支合并到master分支打上tag。当然不要忘记将发布分支合并到develop分支以保持和master*代码同步一致。 可能发布后有紧急的bug需要修复那就从*master分支checkout一个hotfixes/missing-link分支修复bug并合并到master和develop*最后删除。 总结一下 以上就是Git-flow方案的所有流程，优点是分支清晰各干各的看名字就知道，最后只留下*master和develop*分枝。缺点当然是步骤比较繁琐咯，开发要新建很多分支然后切换和删除。我们可以还有很多方案选择GitHub flow、GitLab flow等，或者理解熟练了之后自创一套也是可以的。\nGitHub协同工作 身为一个开发者一定想为开源项目贡献自己的代码，下面是基本步骤可做参考。也可以作为团队协作的基本流程。\nFork到自己帐号下并Clone到本地 git remote add upstream https://github.com/... 添加上游项目地址（源项目地址）以便更新到最新的代码，添加完可用git remote -v查看除了origin应该还有upstream远程地址 git pull upstream master从刚才添加的upstream拉取最新代码 git checkout -b feature/some-feature 新建一个你要添加新功能的分支，开发就在这上面进行 git add . \u0026amp;\u0026amp; git commit -m 'some feature add'测试通过后提交代码 git checkout master \u0026amp;\u0026amp; git pull upstream master这主要是从源仓库拉取最新代码，在你开发期间，如果源项目有改动提交pull就能拉取下来 git checkout feature/some-feature \u0026amp;\u0026amp; git rebase master 然后执行一次变基更新代码 git push origin feature/some-feature推送你开发完并更新到最新的分支到GitHub 去自己GitHub帐号下 pull request等review合并 一具话就是先在本地新建一个分支开发最后提交这个分支发PR，需要注意的是提交到远程的时候记得先pull更新代码然后rebase使分支清晰可读。","title":"Git工作流"},{"content":"Python中@propery 装饰器的使用 python是面向对象的语言，当我们想在类中封装一个变量，并提供设置和获取值的时候，往往会使用如下方法。\nclass Student: def __init__(self, score): self.__score = score def get_score(self): return self.__score def set_score(self, score): self.__score = score 然后如下输出\n\u0026gt;\u0026gt;\u0026gt; s = Student(99) \u0026gt;\u0026gt;\u0026gt; s.get_score() 99 \u0026gt;\u0026gt;\u0026gt; s.set_score(100) \u0026gt;\u0026gt;\u0026gt; s.get_score() 100 这是最简单的封装，但有没有像s.score这样属性直接调用s.score = 100直接赋值的呢，有！而且很简单。\nclass Student: def __init__(self, score): self.score = score 没错就是__init__方法直接设置。\n\u0026gt;\u0026gt;\u0026gt; s = Student(99) \u0026gt;\u0026gt;\u0026gt; s.score 99 \u0026gt;\u0026gt;\u0026gt; s.score = 100 \u0026gt;\u0026gt;\u0026gt; s.score 100 以上的方法没有封装，而且如果我想要判断score的值范围（0~100）也无法做到，使用第一种set_score倒是可以做到。\nclass Student: def __init__(self, score): self.set_score(score) def get_score(self): return self.__score def set_score(self, score): if score \u0026lt; 0: self.__score = 0 elif score \u0026gt; 100: self.__score = 100 else: self.__score = score 效果\n\u0026gt;\u0026gt;\u0026gt; s = Student(1000) \u0026gt;\u0026gt;\u0026gt; s.get_score() 100 \u0026gt;\u0026gt;\u0026gt; s.set_score(80) \u0026gt;\u0026gt;\u0026gt; s.get_score() 80 看起来已经满足我们的需求但不够Pythonic，所以Python提供了@propery装饰器\nclass Student: def __init__(self, score): self.score = score @property def score(self): return self.__score @score.setter def score(self, score): if score \u0026lt; 0: self.__score = 0 elif score \u0026gt; 100: self.__score = 100 else: self.__score = score 运用了Python提供的property装饰器，结果和上面一样。但更优雅可读\n\u0026gt;\u0026gt;\u0026gt; s = Student(101) \u0026gt;\u0026gt;\u0026gt; s.score 100 \u0026gt;\u0026gt;\u0026gt; s.score = -99 \u0026gt;\u0026gt;\u0026gt; s.score 0 使用propery需要注意以下几点\n使用property的两个方法都是相同的名字(score)只是参数不同，设置(setter)方法上的装饰器要用score.setter装饰 在__init__方法中self.score = score是初始化self.__score的值 在另外两个名称相同的方法中使用self.__score私有变量储存值 还有一种写法参考官方文档个人感觉比较繁琐。\nclass Student: def __init__(self, score): self.score = score def __get_score(self): return self.__score def __set_score(self, score): if score \u0026lt; 0: self.__score = 0 elif score \u0026gt; 100: self.__score = 100 else: self.__score = score score = property(__get_score, __set_score) 注意使用了__get_score和__set_score成为私有方法(前面加__)，使用户不能访问。\n参考：\nhttps://www.python-course.eu/\nhttps://docs.python.org/3/\n","permalink":"https://blog.fangjiahui.me/posts/2017-10-08-python-property-tutorial/","summary":"Python中@propery 装饰器的使用 python是面向对象的语言，当我们想在类中封装一个变量，并提供设置和获取值的时候，往往会使用如下方法。\nclass Student: def __init__(self, score): self.__score = score def get_score(self): return self.__score def set_score(self, score): self.__score = score 然后如下输出\n\u0026gt;\u0026gt;\u0026gt; s = Student(99) \u0026gt;\u0026gt;\u0026gt; s.get_score() 99 \u0026gt;\u0026gt;\u0026gt; s.set_score(100) \u0026gt;\u0026gt;\u0026gt; s.get_score() 100 这是最简单的封装，但有没有像s.score这样属性直接调用s.score = 100直接赋值的呢，有！而且很简单。\nclass Student: def __init__(self, score): self.score = score 没错就是__init__方法直接设置。\n\u0026gt;\u0026gt;\u0026gt; s = Student(99) \u0026gt;\u0026gt;\u0026gt; s.score 99 \u0026gt;\u0026gt;\u0026gt; s.score = 100 \u0026gt;\u0026gt;\u0026gt; s.score 100 以上的方法没有封装，而且如果我想要判断score的值范围（0~100）也无法做到，使用第一种set_score倒是可以做到。\nclass Student: def __init__(self, score): self.set_score(score) def get_score(self): return self.","title":"Python中@propery 使用"},{"content":"《在宇宙间不易被风吹散》 一日茶，一夜酒，一部毫不掩饰的小说，一次没有目的的见面，一群不谈正经事的朋友，用美好的器物消磨必定留不住的时间。所谓本质一直就在那里，本一不二。\n《在宇宙间不易被风吹散》是冯唐2016年出版的杂文集。他是个高产的作家其实不止是个靠文字为生的读书人更是个投资人、前麦肯锡合伙人、战略管理顾问等等只是爱好文字业余写作，最近有《搜神记》在预售。\n冯唐算是最近两年比较火的作家特别是翻译了《飞鸟集》从翻译到下架到召回之后。由于翻译的很青春荷尔蒙，诗中到处充斥着“裤裆”、“舌吻”、“他妈”等词不符合大众对诗“信、达、雅”的标准被出版商下架召回。有时也出现在各种电视节目上《铿锵三人行》《搜神记》。\n书的封面骚气十足，他怀抱着一位他热爱的妇女，若隐若现够写意。嗯，很“冯唐”！不会是又一部《素女经》、《不二》吧。书名一开始不太理解，书中旧书店一文中说我想，每个像Moskowitz先生一样牛逼的人，都要有个笃定的核，这样在宇宙间才不易被风吹散，仿佛每个伟大的街区都要有家旧书店。而冯唐这本书就是证明他有一颗笃定的核的书。\n书是一篇篇杂文、随笔组成的，在序分中他说这本书，就和各位简单分享我理解的东方美学。，书中大部分文章介绍他玩各种器物的心得和体会加冯唐体依旧自恋。当然逼格要高煮茶要用日本龙文堂造铁壶、喝茶要用北宋建窑兔毫盏、手表要戴百达翡丽、相机要莱卡M9全幅画旁轴加50mm定焦饼干镜头、戴白玉扳指用他的话说就是用美好的器物消磨必定留不住的时间。用他扎实的文字功底加非常人的见识描述出来，世俗绝不庸俗。挺喜欢他文字中的那点“坏”或者说那点“黄”和肿胀，带着点痞子气。\n除了这些美好的器物他在“跑步，让自己和身体尽人力”中说坚持运动跑步的好处甜睡、去烦、放下等，在”大学教育 我在协和学到的十件事”中说硬着头皮学些暂时不觉的有用的知识有什么用所学过的知识，哪怕基本都忘了，如果需要，我们知道去哪里找。因为我们学过，我们知道这些知识存在，我们不容易狭隘，不狭隘往往意味着不傻逼。乔布斯说要相信会有一天这些零碎的知识会串联起来帮助你。在“财富观 富二代的自我修养”中如果我只能追求一种名牌，我一定追求教育上的名牌：上最好的大学，读最有名的名著。这些都是该汲取的地方。\n还自恋地回应了下为什么这么自恋“能做到实事求是的自恋其实是自信和自尊，任何领域做到最好之后，人只能相信自己的判断，只能自恋。”\n全文完。\n","permalink":"https://blog.fangjiahui.me/posts/2017-07-27-zai-yu-zhou-jian/","summary":"《在宇宙间不易被风吹散》 一日茶，一夜酒，一部毫不掩饰的小说，一次没有目的的见面，一群不谈正经事的朋友，用美好的器物消磨必定留不住的时间。所谓本质一直就在那里，本一不二。\n《在宇宙间不易被风吹散》是冯唐2016年出版的杂文集。他是个高产的作家其实不止是个靠文字为生的读书人更是个投资人、前麦肯锡合伙人、战略管理顾问等等只是爱好文字业余写作，最近有《搜神记》在预售。\n冯唐算是最近两年比较火的作家特别是翻译了《飞鸟集》从翻译到下架到召回之后。由于翻译的很青春荷尔蒙，诗中到处充斥着“裤裆”、“舌吻”、“他妈”等词不符合大众对诗“信、达、雅”的标准被出版商下架召回。有时也出现在各种电视节目上《铿锵三人行》《搜神记》。\n书的封面骚气十足，他怀抱着一位他热爱的妇女，若隐若现够写意。嗯，很“冯唐”！不会是又一部《素女经》、《不二》吧。书名一开始不太理解，书中旧书店一文中说我想，每个像Moskowitz先生一样牛逼的人，都要有个笃定的核，这样在宇宙间才不易被风吹散，仿佛每个伟大的街区都要有家旧书店。而冯唐这本书就是证明他有一颗笃定的核的书。\n书是一篇篇杂文、随笔组成的，在序分中他说这本书，就和各位简单分享我理解的东方美学。，书中大部分文章介绍他玩各种器物的心得和体会加冯唐体依旧自恋。当然逼格要高煮茶要用日本龙文堂造铁壶、喝茶要用北宋建窑兔毫盏、手表要戴百达翡丽、相机要莱卡M9全幅画旁轴加50mm定焦饼干镜头、戴白玉扳指用他的话说就是用美好的器物消磨必定留不住的时间。用他扎实的文字功底加非常人的见识描述出来，世俗绝不庸俗。挺喜欢他文字中的那点“坏”或者说那点“黄”和肿胀，带着点痞子气。\n除了这些美好的器物他在“跑步，让自己和身体尽人力”中说坚持运动跑步的好处甜睡、去烦、放下等，在”大学教育 我在协和学到的十件事”中说硬着头皮学些暂时不觉的有用的知识有什么用所学过的知识，哪怕基本都忘了，如果需要，我们知道去哪里找。因为我们学过，我们知道这些知识存在，我们不容易狭隘，不狭隘往往意味着不傻逼。乔布斯说要相信会有一天这些零碎的知识会串联起来帮助你。在“财富观 富二代的自我修养”中如果我只能追求一种名牌，我一定追求教育上的名牌：上最好的大学，读最有名的名著。这些都是该汲取的地方。\n还自恋地回应了下为什么这么自恋“能做到实事求是的自恋其实是自信和自尊，任何领域做到最好之后，人只能相信自己的判断，只能自恋。”\n全文完。","title":"《在宇宙间不易被风吹散》"},{"content":"Python3 Coroutine(协程) 与 asyncio 协程，又称微线程，纤程，英文名 Coroutine。协程的作用，是在执行函数 A 时，可以随时中断，去执行函数 B，然后中断继续执行函数 A（可以自由切换）。但这一过程并不是函数调用（没有调用语句），这一整个过程看似像多线程，然而协程只有一个线程执行。\n优势\n执行效率极高，因为子程序切换（函数）不是线程切换，由程序自身控制，没有切换线程的开销。所以与多线程相比，线程的数量越多，协程性能的优势越明显。 不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在控制共享资源时也不需要加锁，因此执行效率高很多。 说明：协程可以处理 IO 密集型程序的效率问题，但是处理 CPU 密集型不是它的长处，如要充分发挥 CPU 利用率可以结合多进程加协程。\n有一篇David Beazley的课程A Curious Course on Coroutines and Concurrency详细讲解了协程和并发的用法，强烈推荐。本篇文章多处参考与此。\n0x01. Generator 与 Coroutine 的区别 一开始我总是傻傻分不清Generator和Coroutine的区别感觉这两个东西差不多不一样吗，最近查了点资料并学习了下。在此做记录，我们先来看Generator。\ndef countdown(n): while n \u0026gt; 0: yield n n -= 1 c = countdown(5) print(c) for i in c: print(i) 返回一个generator object并且可以迭代，详细参考上一篇文章\n\u0026lt;generator object countdown at 0x7f82a41739e8\u0026gt; 5 4 3 2 1 [Finished in 0.0s] 如下是Corountine\ndef coprint(): while True: rs = yield print(rs) cp = coprint() cp.send(None) cp.send(1) cp.send(2) cp.send(3) send(None)或者next()方法初始化一个协程。send可以传递一个对象给cp处理遇到yield停止等待下一个send并继续运行。next()方法或者send可以传递一个对象给cp处理遇到yield停止等待下一个send\n对比可以发现虽然他们有很多相同之处但也是有区别的：\ngenerator是生成器顾名思义它负责生产对象，也就是yield后跟着的值。 generator可以迭代用于for循环等。 coroutine协程是一个消费者，消费send给协程的值（yield的左边） coroutine不能用于迭代，主要用于内部消费处理操作 0x02. 协程(Corountine)管道(Pipeline)的运用 先来实现一个使用协程版的tail -f命令。\ndef follow(f, target): f.seek(0, 2) while True: last_line = f.readline() if last_line is not None: target.send(last_line) def printer(): while True: line = yield print(line, end='') f = open('access-log') prt = printer() next(prt) follow(f, prt) 以上只要access-log文件有写入follow()就会显示出来，而真正的协程是printer()并非follow()所以prt需要调用next方法初始化启动，而follow它只是一个调度者send数据给协程。\n我们加入类似与grep过滤的功能。filter也是一个协程。但加了一个装饰器init_coroutine以便不用每次调用next()方法\ndef init_coroutine(func): def wrapper(*args, **kwargs): rs = func(*args, **kwargs) next(rs) return rs return wrapper def follow(f, target): f.seek(0, 2) while True: last_line = f.readline() if last_line is not None: target.send(last_line) @init_coroutine def printer(): while True: line = yield print(line, end='') @init_coroutine def filter(key_string, target): while True: line = yield if key_string in line: target.send(line) f = open('access-log') follow(f, filter('python', printer())) 上面的效果等同于tail -f access-log | grep python，filter也是一个协程并且数据可以传递所以先send到filter然后再到printer显示出来。这就是协程的管道。你还可以像这样的follow(f, filter('python', filter('string', printer())))就两次过滤等于用了两次grep。\n0x03. asyncio asyncio是 Python 3.4 中新增的模块，是一个基于事件循环的实现异步 I/O 的模块，它提供了一种机制，使得你可以用协程（coroutines）、IO 复用（multiplexing I/O）在单线程环境中编写并发模型。\nimport asyncio @asyncio.coroutine def co_print(n): print('Start: ', n) r = yield from asyncio.sleep(1) print('End: ', n) loop = asyncio.get_event_loop() tasks = [co_print(i) for i in range(5)] loop.run_until_complete(asyncio.wait(tasks)) loop.close() \u0026gt; Out： Start: 3 Start: 4 Start: 1 Start: 2 Start: 0 End: 3 End: 4 End: 1 End: 2 End: 0 [Finished in 1.1s] @asyncio.coroutine把一个generator标记为coroutine类型，从上面的运行结果可以看到每个co_print(n)是同时开始执行的，线程并没有等待前一个执行完再运行下一个。每个co_print(n)遇到yield from都会中断，并继续执行下一个co_print(n)。\n@asyncio.coroutine def compute(x, y): print(\u0026quot;Compute %s + %s ...\u0026quot; % (x, y)) yield from asyncio.sleep(1) return x + y @asyncio.coroutine def print_sum(x, y): result = yield from compute(x, y) print(\u0026quot;%s + %s = %s\u0026quot; % (x, y, result)) loop = asyncio.get_event_loop() loop.run_until_complete(print_sum(1, 2)) loop.close() \u0026gt; Out: Compute 1 + 2 ... # 停顿大约一秒 1 + 2 = 3 [Finished in 1.1s] 这是coroutine嵌套的例子，当事件循环(EventLoop)开始运行时，它会在 Task 中寻找 coroutine 来执行调度，因为事件循环注册了print_sum()，然后print_sum()被调用，执行result = yield from compute(x, y)这条语句，因为compute()自身就是一个coroutine，因此print_sum()这个协程就会暂时被挂起，compute()被加入到事件循环中，程序流执行compute()中的 print 语句，打印”Compute %s + %s …”，然后执行了yield from asyncio.sleep(1.0)，因为asyncio.sleep()也是一个coroutine，接着compute()就会被挂起，等待计时器读秒，在这 1 秒的过程中，事件循环会在队列中查询可以被调度的coroutine，而因为此前print_sum()与compute()都被挂起了没有其余的coroutine，因此事件循环会停下来等待协程的调度，当计时器读秒结束后，程序流便会返回到compute()中执行return语句，结果会返回到print_sum()中的result中，最后打印result，事件队列中没有可以调度的任务了，此时loop.close()把事件队列关闭，程序结束。\n0x04. one more thing Python3.5 中又添加了 async def、await这样就使得协程变得更加易用了。PEP 492中详细说明了使用async、await来定义coroutine避免和generator混淆。\n只要把@asyncio.coroutine替换成async加在函数头，把yield from替换成await，其余不变就好了。但不能在同一个coroutine混用，就是用了@asyncio.coroutine而里面却用yield from中断。\nasync def compute(x, y): print(\u0026quot;Compute %s + %s ...\u0026quot; % (x, y)) await asyncio.sleep(1) return x + y async def print_sum(x, y): result = await compute(x, y) print(\u0026quot;%s + %s = %s\u0026quot; % (x, y, result)) 还有就是await之后必须接支持协程的函数或语句上面asyncio.sleep(1)就是一个模拟异步 IO 的过程，否者程序会同步执行看下面例子\nimport time import asyncio import threading async def normal_sleep(w, i): print(\u0026#39;[{}] id ({}) normal sleep 2 seconds.\u0026#39;.format(w, i)) time.sleep(2) print(\u0026#39;[{}] id ({}) ok\u0026#39;.format(w, i)) async def worker(name): print(\u0026#39;-\u0026gt; start {} worker {}\u0026#39;.format(name, threading.current_thread().name)) for i in range(3): print(\u0026#39;handle {}..\u0026#39;.format(i)) await normal_sleep(name, i) print(\u0026#39;\u0026lt;- end {}.\\n\u0026#39;.format(name)) start = time.time() loop = asyncio.get_event_loop() # 启动两个worker tasks = [worker(\u0026#39;A\u0026#39;), worker(\u0026#39;B\u0026#39;)] loop.run_until_complete(asyncio.wait(tasks)) loop.close() print(\u0026#39;Total time {:.2f}s\u0026#39;.format(time.time()-start)) 运行结果\n-\u0026gt; start A worker MainThread handle 0.. [A] id (0) normal sleep 2 seconds. [A] id (0) ok handle 1.. [A] id (1) normal sleep 2 seconds. [A] id (1) ok handle 2.. [A] id (2) normal sleep 2 seconds. [A] id (2) ok \u0026lt;- end A. -\u0026gt; start B worker MainThread handle 0.. [B] id (0) normal sleep 2 seconds. [B] id (0) ok handle 1.. [B] id (1) normal sleep 2 seconds. [B] id (1) ok handle 2.. [B] id (2) normal sleep 2 seconds. [B] id (2) ok \u0026lt;- end B. Total time 12.02s 观察以上输出，发现程序共一个线程是串行执行的，就是因为使用了time.sleep，现在我们改成asyncio.sleep(2)\n... async def async_sleep(): print(\u0026#39;async sleep 2 seconds.\u0026#39;) await asyncio.sleep(2) ... 运行结果\n-\u0026gt; start A worker MainThread handle 0.. [A] id (0) normal sleep 2 seconds. -\u0026gt; start B worker MainThread handle 0.. [B] id (0) normal sleep 2 seconds. [A] id (0) ok handle 1.. [A] id (1) normal sleep 2 seconds. [B] id (0) ok handle 1.. [B] id (1) normal sleep 2 seconds. [A] id (1) ok handle 2.. [A] id (2) normal sleep 2 seconds. [B] id (1) ok handle 2.. [B] id (2) normal sleep 2 seconds. [A] id (2) ok \u0026lt;- end A. [B] id (2) ok \u0026lt;- end B. Total time 6.01s 程序也共一个线程，当遇到asyncio.sleep(1)时会被挂起，EventLoop去处理另一个任务并等待返回结果，总的运行时间大大减小，异步非阻塞，这看起来像是多线程在执行，这就是协程的最大特点。\n参考\nhttp://www.dabeaz.com\nhttps://docs.python.org\nhttp://www.liaoxuefeng.com\nhttp://www.jianshu.com\nhttp://thief.one\n","permalink":"https://blog.fangjiahui.me/posts/2017-05-18-python3-coroutine-and-asyncio/","summary":"Python3 Coroutine(协程) 与 asyncio 协程，又称微线程，纤程，英文名 Coroutine。协程的作用，是在执行函数 A 时，可以随时中断，去执行函数 B，然后中断继续执行函数 A（可以自由切换）。但这一过程并不是函数调用（没有调用语句），这一整个过程看似像多线程，然而协程只有一个线程执行。\n优势\n执行效率极高，因为子程序切换（函数）不是线程切换，由程序自身控制，没有切换线程的开销。所以与多线程相比，线程的数量越多，协程性能的优势越明显。 不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在控制共享资源时也不需要加锁，因此执行效率高很多。 说明：协程可以处理 IO 密集型程序的效率问题，但是处理 CPU 密集型不是它的长处，如要充分发挥 CPU 利用率可以结合多进程加协程。\n有一篇David Beazley的课程A Curious Course on Coroutines and Concurrency详细讲解了协程和并发的用法，强烈推荐。本篇文章多处参考与此。\n0x01. Generator 与 Coroutine 的区别 一开始我总是傻傻分不清Generator和Coroutine的区别感觉这两个东西差不多不一样吗，最近查了点资料并学习了下。在此做记录，我们先来看Generator。\ndef countdown(n): while n \u0026gt; 0: yield n n -= 1 c = countdown(5) print(c) for i in c: print(i) 返回一个generator object并且可以迭代，详细参考上一篇文章\n\u0026lt;generator object countdown at 0x7f82a41739e8\u0026gt; 5 4 3 2 1 [Finished in 0.0s] 如下是Corountine","title":"Python3 协程(Coroutine) 与 asyncio"},{"content":"深入理解 Python3 yield yield是 python 内置的关键字，它能产生一个生成器（Generator）。\n0x01. Generators 只要函数中有yield就会变成一个generator object生成器对象，生成器对象可以迭代，但与iterable不同的是它只能迭代一次。先来看一个简单的例子\n\u0026gt;\u0026gt;\u0026gt; def foo(): ... yield 1 ... yield 2 ... yield 3 ... \u0026gt;\u0026gt;\u0026gt; g = foo() \u0026gt;\u0026gt;\u0026gt; g \u0026lt;generator object foo at 0x7ffb08326ca8\u0026gt; \u0026gt;\u0026gt;\u0026gt; for i in g: ... print(i) ... ... 1 2 3 \u0026gt;\u0026gt;\u0026gt; for i in g: ... print(i) ... ... \u0026gt;\u0026gt;\u0026gt; 当你调用foo这个函数的时候，函数内部的代码并不立马执行 ，这个函数只返回一个生成器对象，如果有庞大的数据它不像iterable占用内存，会每次调用时才计算产生值。\n其实for循环隐式的调用__next__()方法，直到遇到StopIteration停止。\n\u0026gt;\u0026gt;\u0026gt; def bar(): ... yield \u0026#39;a\u0026#39; # 第一次调用next()代码运行到这，产生\u0026#39;a\u0026#39; ... yield \u0026#39;b\u0026#39; # 第二次调用next()代码运行到这，产生\u0026#39;b\u0026#39; ... yield \u0026#39;c\u0026#39; # 第三次调用next()代码运行到这，产生\u0026#39;c\u0026#39; ... \u0026gt;\u0026gt;\u0026gt; g = bar() \u0026gt;\u0026gt;\u0026gt; next(g) \u0026#39;a\u0026#39; \u0026gt;\u0026gt;\u0026gt; next(g) \u0026#39;b\u0026#39; \u0026gt;\u0026gt;\u0026gt; next(g) \u0026#39;c\u0026#39; \u0026gt;\u0026gt;\u0026gt; next(g) Traceback (most recent call last): File \u0026#34;\u0026lt;input\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; next(g) StopIteration 也可以使用 Python3 内置的next()函数调用，直到产生StopIteration错误。\n下面是一个斐波那契数列的例子\n\u0026gt;\u0026gt;\u0026gt; def fib(n): ... a, b = 0, 1 ... while n \u0026gt;= 0: ... b, a = a, a+b ... n -= 1 ... yield b ... ... \u0026gt;\u0026gt;\u0026gt; for i in fib(5): ... print(i) ... ... 0 1 1 2 3 5 0x02. send Method /Coroutines yield不仅可以通过next()取得产生的值，还可以通过send()接受值。\n\u0026gt;\u0026gt;\u0026gt; def simple_coroutine(): ... print(\u0026#39;coroutine has been started!\u0026#39;) ... x = yield ... print(\u0026#39;coroutine received:\u0026#39;, x) ... ... \u0026gt;\u0026gt;\u0026gt; cr = simple_coroutine() \u0026gt;\u0026gt;\u0026gt; cr \u0026lt;generator object simple_coroutine at 0x7ffb08337a40\u0026gt; \u0026gt;\u0026gt;\u0026gt; next(cr) # 等于send(None) coroutine has been started! \u0026gt;\u0026gt;\u0026gt; cr.send(\u0026#39;Hi\u0026#39;) coroutine received: Hi Traceback (most recent call last): File \u0026#34;\u0026lt;input\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; cr.send(\u0026#39;Hi\u0026#39;) StopIteration 首先必须调用next()或send(None)开始这个生成器，程序运行到x = yield暂停，这就是yield神奇的地方可以中断和恢复。因为yield后面没有值，默认为None，之后send('Hi')，生成器接受'Hi'并把它赋值给左边的x继续运行。由于没有下一个yield就抛出了StopIteration错误。\nsend(value)会传递 value 给yield，并且返回下一个yield右边的值。next()也会传递给yield值只是值为None，返回yield右边的值，这个和send一样。所以第一次调用next()等同于send(None)开始一个生成器。\n具体什么是协程，我记录在了这里，欢迎参阅。\n0x03. throw / close Method throw(type)方法会在yield暂停的地方直接抛出一个为type的异常，程序退出。如果被try...except..捕获了就继续执行返回下一个yield值，之后没有yield的话就会抛出一个StopIteration错误。\nclose()是一个优雅地退出generator的方法，本质是抛出一个GeneratorExit异常。\n\u0026gt;\u0026gt;\u0026gt; def echo(value=None): ... print(\u0026#34;Execution starts when \u0026#39;next()\u0026#39; is called for the first time.\u0026#34;) ... try: ... while True: ... try: ... value = (yield value) ... except Exception as e: ... value = e ... finally: ... print(\u0026#34;Don\u0026#39;t forget to clean up when \u0026#39;close()\u0026#39; is called.\u0026#34;) ... ... ... \u0026gt;\u0026gt;\u0026gt; generator = echo(1) \u0026gt;\u0026gt;\u0026gt; print(generator) \u0026lt;generator object echo at 0x7ffb0822ec50\u0026gt; \u0026gt;\u0026gt;\u0026gt; print(generator.send(None)) Execution starts when \u0026#39;next()\u0026#39; is called for the first time. 1 \u0026gt;\u0026gt;\u0026gt; print(next(generator)) None \u0026gt;\u0026gt;\u0026gt; print(generator.send(2)) 2 \u0026gt;\u0026gt;\u0026gt; generator.throw(TypeError, \u0026#34;spam\u0026#34;) TypeError(\u0026#39;spam\u0026#39;,) \u0026gt;\u0026gt;\u0026gt; generator.close() Don\u0026#39;t forget to clean up when \u0026#39;close()\u0026#39; is called. 这个是官方文档上的例子，首先send(None)开始这个生成器，输出右边的value 1 ，调用next()后输出None是因为next()默认传递None给左边的value然后到下一个yield value所以是None。send(2)只是传给value的值为2其他同理，所以输出是2。throw()会抛出一个异常，而被except捕获并赋值给了value。close()关闭了generator退出当前块代码运行finally代码块。\n0x04. yield from yield from是从Python 3.3之后加入的。\n\u0026gt;\u0026gt;\u0026gt; def gen1(): ... for char in \u0026#34;Python\u0026#34;: ... yield char ... for i in range(5): ... yield i ... ... \u0026gt;\u0026gt;\u0026gt; def gen2(): ... yield from \u0026#34;Python\u0026#34; ... yield from range(5) ... \u0026gt;\u0026gt;\u0026gt; g1 = gen1() \u0026gt;\u0026gt;\u0026gt; g2 = gen2() \u0026gt;\u0026gt;\u0026gt; for i in g1: ... print(i, end=\u0026#39;,\u0026#39;) ... ... P,y,t,h,o,n,0,1,2,3,4, \u0026gt;\u0026gt;\u0026gt; for i in g2: ... print(i, end=\u0026#39;,\u0026#39;) ... ... P,y,t,h,o,n,0,1,2,3,4, 上面的gen1和gen2是等价的但代码看上去更加的整洁。yield from后接可迭代对象(iterable)。然后我们看一个后面接生成器的例子。\n\u0026gt;\u0026gt;\u0026gt; def accumulate(): ... tally = 0 ... while True: ... next = yield ... if next == None: ... return tally ... tally += next ... ... ... \u0026gt;\u0026gt;\u0026gt; def gather_tallies_verbose(tallies): ... acc = accumulate() ... next(acc) ... while True: ... try: ... value = yield ... acc.send(value) ... except StopIteration as tally: ... tallies.append(tally.value) ... acc = accumulate() ... next(acc) ... except Exception as e: ... print(e.value) ... acc.throw(e) ... ... ... ... \u0026gt;\u0026gt;\u0026gt; def gather_tallies(tallies): ... while True: ... tally = yield from accumulate() ... tallies.append(tally) ... ... ... \u0026gt;\u0026gt;\u0026gt; tallies = [] \u0026gt;\u0026gt;\u0026gt; acc = gather_tallies(tallies) \u0026gt;\u0026gt;\u0026gt; next(acc) \u0026gt;\u0026gt;\u0026gt; for i in range(4): ... acc.send(i) ... ... \u0026gt;\u0026gt;\u0026gt; tallies [] \u0026gt;\u0026gt;\u0026gt; acc.send(None) \u0026gt;\u0026gt;\u0026gt; tallies [6] \u0026gt;\u0026gt;\u0026gt; for i in range(5): ... acc.send(i) ... ... \u0026gt;\u0026gt;\u0026gt; acc.send(None) \u0026gt;\u0026gt;\u0026gt; tallies [6, 10] 这个例子原来是官方文档上的例子我改了下。gather_tallies_verbose和gather_tallies两个是等价的，但gather_tallies使用了yield from对比发现更加简洁易懂，magic。\naccumulate()是一个生成器对象，gather_tallies()也是一个生成器。子生成器accumulate能接受gather_tallies的send()过来的值，子生成器接受到None后return的值会传递给调用者(gather_tallies)并赋值在左边也就是tally然后继续运行，子生成器return其实会抛出一个StopIteration错误而捕获到错误的value值也就是tally。\n具体可查看如下规则PEP 380 - Syntax for Delegating to a Subgenerator\nAny values that the iterator yields are passed directly to the caller. Any values sent to the delegating generator using send() are passed directly to the iterator. If the sent value is None, the iterator\u0026rsquo;s __next__ method is called. If the sent value is not None, the iterator\u0026rsquo;s send() method is called. If the call raises StopIteration, the delegating generator is resumed. Any other exception is propagated to the delegating generator. Exceptions other than GeneratorExit thrown into the delegating generator are passed to the throw() method of the iterator. If the call raises StopIteration, the delegating generator is resumed. Any other exception is propagated to the delegating generator. If a GeneratorExit exception is thrown into the delegating generator, or the close() method of the delegating generator is called, then the close() method of the iterator is called if it has one. If this call results in an exception, it is propagated to the delegating generator. Otherwise, GeneratorExit is raised in the delegating generator. The value of the yield from expression is the first argument to the StopIteration exception raised by the iterator when it terminates. return expr in a generator causes StopIteration(expr) to be raised upon exit from the generator. 参考\nhttp://www.python-course.eu\nhttps://docs.python.org\nhttps://docs.python.org\n","permalink":"https://blog.fangjiahui.me/posts/2017-04-28-python3-yield/","summary":"深入理解 Python3 yield yield是 python 内置的关键字，它能产生一个生成器（Generator）。\n0x01. Generators 只要函数中有yield就会变成一个generator object生成器对象，生成器对象可以迭代，但与iterable不同的是它只能迭代一次。先来看一个简单的例子\n\u0026gt;\u0026gt;\u0026gt; def foo(): ... yield 1 ... yield 2 ... yield 3 ... \u0026gt;\u0026gt;\u0026gt; g = foo() \u0026gt;\u0026gt;\u0026gt; g \u0026lt;generator object foo at 0x7ffb08326ca8\u0026gt; \u0026gt;\u0026gt;\u0026gt; for i in g: ... print(i) ... ... 1 2 3 \u0026gt;\u0026gt;\u0026gt; for i in g: ... print(i) ... ... \u0026gt;\u0026gt;\u0026gt; 当你调用foo这个函数的时候，函数内部的代码并不立马执行 ，这个函数只返回一个生成器对象，如果有庞大的数据它不像iterable占用内存，会每次调用时才计算产生值。\n其实for循环隐式的调用__next__()方法，直到遇到StopIteration停止。\n\u0026gt;\u0026gt;\u0026gt; def bar(): ... yield \u0026#39;a\u0026#39; # 第一次调用next()代码运行到这，产生\u0026#39;a\u0026#39; ... yield \u0026#39;b\u0026#39; # 第二次调用next()代码运行到这，产生\u0026#39;b\u0026#39; .","title":"深入理解 Python中的yield"},{"content":"Python装饰器(decorators) 装饰器(decorators)是Python强大的功能之一，语法上就支持(@符号)使用起来更方便，不需要用OOP的设计模式实现。装饰器其实就是个返回函数的函数(类)，但可以有很多的玩法，下面将一一介绍。\n函数(Functions) 讲装饰器之前，先回顾下一些函数的基础知识，装饰器就是这些简单功能的组合\n函数接收函数作为参数 python中定义一个函数很简单如下\n\u0026gt;\u0026gt;\u0026gt; def foo(): ... pass ... \u0026gt;\u0026gt;\u0026gt; foo \u0026lt;function foo at 0x1054157a0\u0026gt; \u0026gt;\u0026gt;\u0026gt; bar = foo \u0026gt;\u0026gt;\u0026gt; bar \u0026lt;function foo at 0x1054157a0\u0026gt; 定义了foo函数，而bar是对foo的引用，这很简单\n因为python中一切皆对象，函数也是对象，一个函数也可以使用函数作为参数传入，和传其他对象一样（字符串、数字、列表 \u0026hellip;)\n\u0026gt;\u0026gt;\u0026gt; def foo(): ... print(\u0026#34;hello world\u0026#34;) ... ... \u0026gt;\u0026gt;\u0026gt; def bar(f): ... print(f\u0026#34;call {f.__name__}\u0026#34;) ... f() ... ... \u0026gt;\u0026gt;\u0026gt; bar(foo) call foo hello world bar函数就接收foo函数作为参数，内部执行foo函数。\n函数内部定义函数 也可以在函数内部定义一个新的函数\n\u0026gt;\u0026gt;\u0026gt; def foo(): ... def bar(): ... print(\u0026#34;inner func\u0026#34;) ... bar() ... ... \u0026gt;\u0026gt;\u0026gt; foo() inner func \u0026gt;\u0026gt;\u0026gt; bar() Traceback (most recent call last): File \u0026#34;\u0026lt;input\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; bar() NameError: name \u0026#39;bar\u0026#39; is not defined foo函数中定义了bar函数，定义内部函数和定义在外面的函数没有任何的区别，只是它的作用域只能在foo函数内部，外部是无法应用bar的\n函数返回函数 更高级的函数甚至可以返回一个函数作为返回结果\n\u0026gt;\u0026gt;\u0026gt; def foo(): ... def bar(): ... return \u0026#34;hello world\u0026#34; ... return bar ... \u0026gt;\u0026gt;\u0026gt; foo \u0026lt;function foo at 0x10c063440\u0026gt; \u0026gt;\u0026gt;\u0026gt; foo() \u0026lt;function foo.\u0026lt;locals\u0026gt;.bar at 0x10baea170\u0026gt; \u0026gt;\u0026gt;\u0026gt; foo()() \u0026#39;hello world\u0026#39; 注意我们这一次内部不再调用bar()而是return bar，说明foo函数返回一个内部函数的引用\n可以看到调用foo()函数返回了内部定义的bar函数(\u0026lt;function foo.\u0026lt;locals\u0026gt;.bar at 0x10baea170\u0026gt;)但没有执行调用，再次调用则会被执行。\n装饰器 有了上面的基础，我们就可以创建装饰器了\ndef first_decorator(f): def wrapper(): print(f\u0026#34;call function {f.__name__!r}\u0026#34;) f() print(\u0026#34;call finished\u0026#34;) return wrapper def task(): print(\u0026#34;do some task...\u0026#34;) task = first_decorator(task) task() task函数作为first_decorator的参数传入然后重新赋值给了task变量，而first_decorator内部返回wrapper函数引用，执行task后如下结果\ncall function \u0026#39;task\u0026#39; do some task... call finished 以上就是一个最简单装饰器(first_decorator)的例子，所以装饰器的作用就是在不修改原函数(task)的基础上给原函数增加一些功能，它能包装原函数改变原函数的一些功能。在一些场景下节省了很多代码量而且简单直观，比如权限验证、日志、缓存等。\n语法糖 上面写了task = first_decorator(task)来实现包装的效果，python提供了一个更加优雅的语法糖那就是@符号，可以改写成这样\ndef first_decorator(f): def wrapper(): print(f\u0026#34;call function {f.__name__!r}\u0026#34;) f() print(\u0026#34;call finished\u0026#34;) return wrapper @first_decorator # 语法糖 def task(): print(\u0026#34;do some task...\u0026#34;) 这是不是更简单了，@first_decorator的作用和task = first_decorator(task)一样\n但被装饰的函数如果有参数怎么办呢，我们使用*args和**kwargs解决，下面的装饰器是记录某函数调用时间的\nimport time def time_cost(f): def wrapper(*args, **kwargs): # 接受任何类型的参数 start = time.perf_counter() result = f(*args, **kwargs) # 被装饰的函数调用 print(f\u0026#34;{f.__name__} run cost {time.perf_counter()-start:.5f}s\u0026#34;) return result return wrapper @time_cost def doze(t: int) -\u0026gt; int: \u0026#34;\u0026#34;\u0026#34;sleep a time\u0026#34;\u0026#34;\u0026#34; time.sleep(t) return t doze(2) # doze run cost 2.00506s 上面定义doze函数时使用了pythontype hints的特性，请使用3.6以上版本\n使用@time_cost语法糖装饰doze函数，doze的输入参数其实最后是传给了wrapper(*args, **kwargs)，之后才会被使用，而我们暂存了结果等内部处理完再返回结果，不会影响被装饰函数的返回结果。\n元数据 doze执行起来功能好像是对的，但它的一些属性可能会有些问题\n\u0026gt;\u0026gt;\u0026gt; doze.__name__ \u0026#39;wrapper\u0026#39; \u0026gt;\u0026gt;\u0026gt; doze.__doc__ 看到这些元数据都是引用内部定义的wrapper函数，因为被装饰了之后返回的是wrapper函数的引用，我们需要修复它\nimport time def time_cost(f): def wrapper(*args, **kwargs): start = time.perf_counter() result = f(*args, **kwargs) print(f\u0026#34;{f.__name__} run cost {time.perf_counter()-start:.5f}s\u0026#34;) return result wrapper.__name__ = f.__name__ wrapper.__doc__ = f.__doc__ wrapper.__module__ = f.__module__ return wrapper @time_cost def doze(t: int) -\u0026gt; int: \u0026#34;\u0026#34;\u0026#34;sleep a time\u0026#34;\u0026#34;\u0026#34; time.sleep(t) return t print(doze.__name__) # doze print(doze.__doc__) # sleep a time 在time_cost内部我们手动修改了这些属性把原函数的一些属性赋值到了wrapper函数，其实functools包提供了一个wraps装饰器专门用来干这个事情，所以可以写成下面这样子\nimport time, functools def time_cost(f): @functools.wraps(f) # 修复元数据 def wrapper(*args, **kwargs): start = time.perf_counter() result = f(*args, **kwargs) print(f\u0026#34;{f.__name__} run cost {time.perf_counter()-start:.5f}s\u0026#34;) return result return wrapper 注意functools.wraps也是一个装饰器，@functools.wraps装饰了wrapper函数使得wraper上的元数据和f函数一致\n传参 能不能在装饰的时候传入参数呢如@decorator(k=v)使装饰器更加灵活呢，答案是肯定的。\n要想@decoraotr(k=v)可用，decorator(k=v)整体就要返回一个函数引用，此函数用来装饰目标对象（接收一个函数），模版如下\ndef decorator(k): def dec_args(f): # 和之前定义的装饰器一样 # ... return dec_args @decorator(3) def foo: #... 简单理解就是多增加一层嵌套为的是传入k，decorator(k)返回的函数引用就是用来装饰目标函数的，接受目标f(被装饰的目标函数)，此dec_args(f)和之前定义的不带参数的装饰器一样（如上面的time_cost,first_decorator），如下是一个可以指定执行次数的装饰器\ndef repeat(n): def dec_args(f): @functools.wraps(f) def wrapper(*args, **kwargs): for i in range(n): result = f(*args, **kwargs) return result return wrapper return dec_args @repeat(n=3) def echo(s): print(s) echo(\u0026#34;hello world\u0026#34;) repeat装饰器接受参数n执行的次数，不用语法糖手写就是echo = repeat(n=3)(echo)，输出\nhello world hello world hello world 如何实现即可以传参(@repeat(n=3))又可以省略参数(@repeat)呢，这需要一点小trick，内部增加一个判断\nimport functools def repeat(_func=None, *, n=1): def dec_args(f): @functools.wraps(f) def wrapper(*args, **kwargs): for i in range(n): result = f(*args, **kwargs) return result return wrapper if _func is None: return dec_args # 传参的情况 else: return dec_args(_func) # 没有参数 @repeat def echo(s): print(s) @repeat(n=3) def echo3(s): print(s) echo(\u0026#34;hello world\u0026#34;) echo3(\u0026#34;hello friend\u0026#34;) 我们使用*符号确保传参必须使用键值对，使用_func变量判断有没有传参，分两种情况\n传参: echo3 = repeat(n=3)(echo3)所以_func是None 没有参数: echo = repeat(echo)所以_func是函数echo 还有一种使用functools.partial的实现方法\ndef repeat(_func=None, *, n=1): if _func is None: # 带参数 return functools.partial(repeat, n=n) @functools.wraps(_func) def wrapper(*args, **kwargs): for i in range(n): result = _func(*args, **kwargs) return result return wrapper 装饰器级连 一个函数可以使用多个装饰器，我们把repeat和time_cost两个装饰器都作用在echo上\n@time_cost @repeat(n=3) def echo(s): time.sleep(0.5) print(s) 输出\nhello world hello world hello world echo run cost 1.50582s 上面两个装饰器就是等于echo = time_cost(repeat(n=3)(echo))，当然也可以用三个以此类推\n装饰器与类 到现在为止我们都是用函数定义装饰器，使用在函数上，接下来介绍装饰器与类有关的操作\n装饰的对象为类或者类方法 使用类定义装饰器 首先看装饰在类方法上，其实和装饰在函数上是一样的，本来定义在类中的函数叫类方法\nclass Task: @time_cost def echo(self): print(\u0026#34;hello world\u0026#34;) Task().echo() 上面作用在echo方法上显示方法耗时，python提供了一些内建的用于类相关的装饰器如@classmethod类方法、@staticmethod静态方法、@property属性\n我们把装饰器用在类上面\n@time_cost class Task: def echo(self): print(\u0026#34;hello world\u0026#34;) t = Task() print(\u0026#34;-\u0026#34; * 10) t.echo() 输出\nTask run cost 0.00000s ---------- hello world 这个是作用在类实例化上，不会对类方法有什么作用，time_cost接收的是类Task，Task = time_cost(Task)\n以上我们都用的是函数定义装饰器，装饰器也可以用类来定义主要使用类的__call__方法，先来看看__call__方法\n\u0026gt;\u0026gt;\u0026gt; class Counter: ... def __init__(self): ... self.n = 0 ... ... def __call__(self): ... self.n += 1 ... print(f\u0026#34;{self} call {self.n} times\u0026#34;) ... ... \u0026gt;\u0026gt;\u0026gt; c = Counter() \u0026gt;\u0026gt;\u0026gt; c() \u0026lt;__main__.Counter object at 0x10c5b2b90\u0026gt; call 1 times \u0026gt;\u0026gt;\u0026gt; c() \u0026lt;__main__.Counter object at 0x10c5b2b90\u0026gt; call 2 times \u0026gt;\u0026gt;\u0026gt; c() \u0026lt;__main__.Counter object at 0x10c5b2b90\u0026gt; call 3 times __call__方法在实例自身调用时触发，这里记录每次调用的次数。用类定义装饰器就是定义__call__和__init__方法\nimport functools class Counter: def __init__(self, f): functools.update_wrapper(self, f) self.n = 0 self.f = f # 被装饰的对象 def __call__(self, *args, **kwargs): self.n += 1 result = self.f(*args, **kwargs) print(f\u0026#34;{self.f.__name__} call {self.n} times\u0026#34;) return result @Counter def run_task(): pass run_task() run_task() 输出\nrun_task call 1 times run_task call 2 times Counter就是用类定义的装饰器相当于run_task = Counter(run_task)，__init__方法在此时调用self.f保存函数引用，而__call__就是在被装饰的函数调用的时候触发，每次自增1。注意我们用functools.update_wrapper更新元属性而不是用functools.wraps装饰器其实wraps装饰器内部也是调用update_wrapper的，如果漏了这句被装饰对象(run_task)的类似__name__和__doc__等会丢失。\n当然上面的计数装饰器也可以用普通函数来实现，内部需要有个变量保存调用次数，我们使用函数属性wraper.n\ndef counter(f): @functools.wraps(f) def wrapper(*args, **kwargs): wrapper.n += 1 result = f(*args, **kwargs) print(f\u0026#34;{f.__name__} call {wrapper.n} times\u0026#34;) return result wrapper.n = 0 return wrapper 应用举例 缓存 因为装饰器内部可以保存变量，我们可以用它来实现缓存，先定义一个计算斐波那切数列的函数，并加上上面定义的counter装饰器用来统计计算次数\n@counter def fib(n): if n \u0026lt; 2: return n return fib(n-1) + fib(n-2) 计算fib(10)需要调用177次，而再次调用fib(20)就已经上升到了22086次，也就是说fib(20)单独调用需要21891次，这样的递归调用是非常糟糕的\n\u0026gt;\u0026gt;\u0026gt; fib(10) fib call 10 times fib call 11 times fib call 11 times fib call 12 times ... fib call 177 times 55 \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; fib(20) # long time ... ib call 22086 times # 22086 - 177 = 21891 6765 用装饰器实现一个cache\ndef cache(f): @functools.wraps(f) def wrapper(*args, **kwargs): key = args + tuple(kwargs.items()) if not wrapper.dict.get(key): wrapper.dict[key] = f(*args, **kwargs) return wrapper.dict[key] wrapper.dict = dict() return wrapper @cache @counter def fib(n): if n \u0026lt; 2: return n return fib(n-1) + fib(n-2) 试验以下\n\u0026gt;\u0026gt;\u0026gt; fib(20) fib call 20 times ... fib call 21 times fib call 21 times 6765 \u0026gt;\u0026gt;\u0026gt; fib(20) 6765 \u0026gt;\u0026gt;\u0026gt; fib(10) 55 发现第一次调用fib(20)后再次调用fib(20)或者小于20的数都不需要在次计算了，非常的快\nPython官方functools.lru_cache已经内建可以使用，且功能更丰富\n单例(Singletons) 可以使用装饰器来实现单例\nfrom functools import update_wrapper class Singleton: def __init__(self, cls): update_wrapper(self, cls) self.instance = None self.cls = cls def __call__(self, *args, **kwargs): if not self.instance: self.instance = self.cls(*args, **kwargs) return self.instance @Singleton class Foo: pass f0 = Foo() f1 = Foo() print(f0 is f1) # True print(id(f0)) # 4535987168 print(id(f1)) # 4535987168 字段验证 在api请求中通常约定特定字段作为接收参数，我们可以通过装饰器来验证改字段是否存在\nfrom flask import Flask, request, abort from functools import wraps app = Flask(__name__) def validate(*json_keys): def decorator(f): @wraps(f) def wrapper(*args, **kwargs): if request.is_json: for k in json_keys: if k not in request.get_json(): abort(400) return f(*args, **kwargs) return wrapper return decorator @app.route(\u0026#34;/info\u0026#34;, methods=[\u0026#34;POST\u0026#34;]) @validate(\u0026#34;name\u0026#34;, \u0026#34;age\u0026#34;) def user_info(): return \u0026#34;Success\u0026#34; 上面的Flask应用，路由/info使用了validate装饰器检查name,age是否存在于请求json中，如果不存在返回400。定义装饰器时使用了*json_keys可以接收任意个key。\nReference www.python-course.eu realpython.com ","permalink":"https://blog.fangjiahui.me/posts/2017-04-10-python-decorators/","summary":"Python装饰器(decorators) 装饰器(decorators)是Python强大的功能之一，语法上就支持(@符号)使用起来更方便，不需要用OOP的设计模式实现。装饰器其实就是个返回函数的函数(类)，但可以有很多的玩法，下面将一一介绍。\n函数(Functions) 讲装饰器之前，先回顾下一些函数的基础知识，装饰器就是这些简单功能的组合\n函数接收函数作为参数 python中定义一个函数很简单如下\n\u0026gt;\u0026gt;\u0026gt; def foo(): ... pass ... \u0026gt;\u0026gt;\u0026gt; foo \u0026lt;function foo at 0x1054157a0\u0026gt; \u0026gt;\u0026gt;\u0026gt; bar = foo \u0026gt;\u0026gt;\u0026gt; bar \u0026lt;function foo at 0x1054157a0\u0026gt; 定义了foo函数，而bar是对foo的引用，这很简单\n因为python中一切皆对象，函数也是对象，一个函数也可以使用函数作为参数传入，和传其他对象一样（字符串、数字、列表 \u0026hellip;)\n\u0026gt;\u0026gt;\u0026gt; def foo(): ... print(\u0026#34;hello world\u0026#34;) ... ... \u0026gt;\u0026gt;\u0026gt; def bar(f): ... print(f\u0026#34;call {f.__name__}\u0026#34;) ... f() ... ... \u0026gt;\u0026gt;\u0026gt; bar(foo) call foo hello world bar函数就接收foo函数作为参数，内部执行foo函数。\n函数内部定义函数 也可以在函数内部定义一个新的函数\n\u0026gt;\u0026gt;\u0026gt; def foo(): ... def bar(): ... print(\u0026#34;inner func\u0026#34;) ... bar() ... .","title":"Python装饰器(decorators)"},{"content":"SSH Tunnel - Port Forwarding Secure Shell (SSH) is a cryptographic network protocol for operating network services securely over an unsecured network. The best known example application is for remote login to computer systems by users.\nSSH是一个网络协议sftp、scp、ssh都是这个协议。ssh一般用来用于远程主机的登录，Linux系统自带OpenSSH可以方便的使用。它有一个叫SSH Tunnel的东西可以转发流量，下面是几个例子，以便理解和快速使用隧道，详细使用方法，请移步官方手册。\n本地端口转发（Local Port Forwarding） -L [bind_address:]port:host:hostport Specifies that the given port on the local (client) host is to be forwarded to the given host and port on the remote side. 使用-L参数，指定一个本地端口，流量通过这个端口转发到目标主机(host)上的端口(hostport)。\n例如连接远程主机(example.com)本地的mysql服务，我们可以本地开一个端口3307转发，这样我们就可以通过SSH连接到远程的数据库，不用修改远程服务器的配置就可以实现，而且数据是加密的。\nssh -L 3307:127.0.0.1:3306 user@example.com\n以上命令中3307是本地端口，127.0.0.1是远程服务器数据库地址相对于example.com而不是本地的，这个地址还可以是任意example.com能访问的地址，3306是数据库监听端口。回车之后如果没有用公钥认证输入密码后看起来像正常远程登录一样，但不影响我们远程连接。mysql -h 127.0.0.1 -P 3307 -u mysqluser -p连接到远程数据库，就可以了。\n如果想静默执行可以在后面加上-NnT不需要时按Ctrl+c结束。\nssh -L 3307:127.0.0.1:3306 user@example.com -NnT\n-N 不执行任何远程命令 -n 重定向stdin到/dev/null,阻止读取stdin -T 不分配TTY 远程端口转发（Remote Port Forwarding） -R [bind_address:]port:host:hostport Specifies that the given port on the remote (server) host is to be forwarded to the given host and port on the local side. -R参数指定一个远程端口，把远程主机(待登录主机)的端口转发到本地端指定机器(host)的端口。因为client是从本地ssh到远程服务器，而流量先是从远程端口流向本地的，返回的数据再经原路返回，两个方向相反，所以也称反向隧道反向代理。\n一个比较实用的例子是用于内网穿透，假设A是公司内网的机器没有公网IP但能连接互联网，因为有一层NAT (Network Address Translation) 阻挡着，你不能从公司以外的网络访问A机器。你有一台B机器，有公网IP并装有sshd和ssh。当然你可以在路由上设置端口映射来实现A能被访问可公司路由不是谁都能进并愉快玩耍的，这个时候简单的一条ssh命令就能派上用场了，因为A机器也可以远程连接到B，我们在A机器上建立远程端口转发使A机器在远程也能访问到，在A上执行以下命令。\nssh -R 4488:127.0.0.1:22 user@B -NnT\n4488代表在B远程机器上本地监听4488端口转发流量，127.0.0.1是本地A机器的地址，22是本地A机器的默认ssh端口22，然后在B机器上执行netstat -nlp | grep 4488应该如下显示\ntcp 0 0 127.0.0.1:4488 0.0.0.0:* LISTEN 18556/sshd: Fython 在B机器上执行ssh -p 4488 user@127.0.0.1远程连接到A机器，就是这么简单，我们已经穿透了公司内网。\n我们继续，现在你在家有一台C机器也处于内网之中和A差不多，你想在家也就是C机器上访问公司的机器A，我们可以这样。\n在机器B上编辑/etc/ssh/sshd_config配置文件，加上GatewayPorts yes允许任意的地址连接，如果为no只能是B机器能访问。 B机器重启sshd服务，systemctl restart sshd使上面的配置生效。 同样在A上执行ssh -R 4488:127.0.0.1:22 user@B -NnT，可以使用netstat查看4488连接是否建立 C机器上执行ssh -p 4488 user@B来连接A机器 注意：以上A和B都必须有ssh的客户端和服务端，C就使用客户端即可。\n隧道的维持 一般ssh长时间连接就会中断。使用autossh代替ssh可以保持隧中断自动连接，确保使用了公钥认证登录服务器。\nautossh -M 8898 -R 4488:127.0.0.1:22 user@B -NnTqf\n-M 为autossh的参数 指定一个监听端口与ssh无关 -q 为静默模式，ssh的参数 -f 后台执行, ssh的参数 这样ssh服务就会长时间在A机器的后台运行\n动态端口转发（dynamic port forwarding） -D [bind_address:]port Specifies a local “dynamic” application-level port forwarding. This works by allocating a socket to listen to port on the local side, optionally bound to the specified bind_address. 还有一个-D参数在本地建立一个SOCKS代理服务器用于动态端口转发。SOCKS是位于会话层的传输协议，能动态的代理端口，这就很合适作为浏览器代理，SOCKS5支持UDP的代理，openssh支持SOCKS5。\n比如一台机器可以科学上网，我们就可以通过这台机器跨越GFW\nssh -D 1080 user@example.com -NnTqf\n1080代表绑定本地的1080端口，之后在浏览器网络中配置SOCKS代理即可。\n接上面远程端口转发的例子，如果想在家通过C机器访问公司内网网站的网站（A机器可访问），本地建立一个动态的端口转发到B的4488端口，经A与B建立的远程隧道就能实现了。\nssh -D 1080 -p 4488 user@B -NnTqf\n参考：\nhttps://en.wikipedia.org\nhttps://www.openssh.com\nhttps://www.ibm.com\n","permalink":"https://blog.fangjiahui.me/posts/2017-04-08-ssh-tunnel-port-forwarding/","summary":"SSH Tunnel - Port Forwarding Secure Shell (SSH) is a cryptographic network protocol for operating network services securely over an unsecured network. The best known example application is for remote login to computer systems by users.\nSSH是一个网络协议sftp、scp、ssh都是这个协议。ssh一般用来用于远程主机的登录，Linux系统自带OpenSSH可以方便的使用。它有一个叫SSH Tunnel的东西可以转发流量，下面是几个例子，以便理解和快速使用隧道，详细使用方法，请移步官方手册。\n本地端口转发（Local Port Forwarding） -L [bind_address:]port:host:hostport Specifies that the given port on the local (client) host is to be forwarded to the given host and port on the remote side. 使用-L参数，指定一个本地端口，流量通过这个端口转发到目标主机(host)上的端口(hostport)。\n例如连接远程主机(example.com)本地的mysql服务，我们可以本地开一个端口3307转发，这样我们就可以通过SSH连接到远程的数据库，不用修改远程服务器的配置就可以实现，而且数据是加密的。\nssh -L 3307:127.","title":"SSH进阶 端口转发 内网穿透"},{"content":"《我们仨》—— 我一个人思念我们仨 世间好物不坚牢，彩云易散琉璃脆。\n这个清明时节没有雨纷纷，三天假期阳光都很好。没有出远门，只回家和家人待了两天，见了几个想见的朋友玩伴。偷空放松下不想学习也看了这本书。\n前段时间看《洗澡》当时感觉这书还比他丈夫的《围城》还精彩易读，有可能看《围城》时功力不够不懂钱老师深厚的多国文学基础，有些精细文字也都理解不了，那是一个很遥远的暑假了。看完《洗澡》之后意犹未尽，只想着姚宓与徐彦成精神恋爱的结局，就去看了《洗澡之后》杨绛说“假如我去世以后有人擅写续集，我就无法阻挡了。现在趁我还健在，把故事结束了吧。”多俏皮的话，看完后，还是觉得不要看的好，这部作品就当是百岁老人给我们的开的一个玩笑吧。《我们仨》是杨绛先生在先生和女儿去世之后写的回忆录，是一位孤独老人思念的产物，的确真真实实，历历在目。\n书中记录了钱媛先与一九九七年早春去世，一九九八年岁末，钟书去世。她说从此他们三人就此失散了。在短短两年内先后失去两位至亲之人，这悲痛只有当事人能感受得到。并在此后整理钱钟书书信文件出版，并从事文学工作到最后一刻，这就是老一辈知识分子典型代表。\n全书一共分为三个部分，前两部是写一个梦。\n我曾做过一个小梦，怪他一声不响的走了。他现在故意慢慢儿走，让我一程一程送，尽量多聚聚，把一个小梦拉成一个万里长梦。 我还是比较喜欢第三部，记录他们一家人分分合合，朴实的生活，温暖与亲切。他们都是从剑桥和巴黎留学归来的大学者，也见过大世面，一生不追名逐利，与世无争，与人无求，只求平淡生活。不变的是到哪都会学习、读书和创作。\n钟书是坐冷板凳的，他的学问也是冷门。他曾和我说：“有名气就是多些不相识的人。” 我们希望有几个知己， 不求有名有声。 给钟书虚名他都能推就推，只专心做学问。我想正是因为如此他们也躲过了新中国几个困难时期。\n比较有趣的是读着读着会想起《洗澡》里的情节阿瑗对我说：“妈妈，我不想结婚了，我陪着爸爸妈妈。”像极了姚蜜说的话。\n","permalink":"https://blog.fangjiahui.me/posts/2017-04-06-wo-men-san/","summary":"《我们仨》—— 我一个人思念我们仨 世间好物不坚牢，彩云易散琉璃脆。\n这个清明时节没有雨纷纷，三天假期阳光都很好。没有出远门，只回家和家人待了两天，见了几个想见的朋友玩伴。偷空放松下不想学习也看了这本书。\n前段时间看《洗澡》当时感觉这书还比他丈夫的《围城》还精彩易读，有可能看《围城》时功力不够不懂钱老师深厚的多国文学基础，有些精细文字也都理解不了，那是一个很遥远的暑假了。看完《洗澡》之后意犹未尽，只想着姚宓与徐彦成精神恋爱的结局，就去看了《洗澡之后》杨绛说“假如我去世以后有人擅写续集，我就无法阻挡了。现在趁我还健在，把故事结束了吧。”多俏皮的话，看完后，还是觉得不要看的好，这部作品就当是百岁老人给我们的开的一个玩笑吧。《我们仨》是杨绛先生在先生和女儿去世之后写的回忆录，是一位孤独老人思念的产物，的确真真实实，历历在目。\n书中记录了钱媛先与一九九七年早春去世，一九九八年岁末，钟书去世。她说从此他们三人就此失散了。在短短两年内先后失去两位至亲之人，这悲痛只有当事人能感受得到。并在此后整理钱钟书书信文件出版，并从事文学工作到最后一刻，这就是老一辈知识分子典型代表。\n全书一共分为三个部分，前两部是写一个梦。\n我曾做过一个小梦，怪他一声不响的走了。他现在故意慢慢儿走，让我一程一程送，尽量多聚聚，把一个小梦拉成一个万里长梦。 我还是比较喜欢第三部，记录他们一家人分分合合，朴实的生活，温暖与亲切。他们都是从剑桥和巴黎留学归来的大学者，也见过大世面，一生不追名逐利，与世无争，与人无求，只求平淡生活。不变的是到哪都会学习、读书和创作。\n钟书是坐冷板凳的，他的学问也是冷门。他曾和我说：“有名气就是多些不相识的人。” 我们希望有几个知己， 不求有名有声。 给钟书虚名他都能推就推，只专心做学问。我想正是因为如此他们也躲过了新中国几个困难时期。\n比较有趣的是读着读着会想起《洗澡》里的情节阿瑗对我说：“妈妈，我不想结婚了，我陪着爸爸妈妈。”像极了姚蜜说的话。","title":"《我们仨》杨绛先生回忆录"},{"content":"Python中的类变量(class variables)和实例变量(instance variables) 类变量(Class Variables) 类变量是所有实例共享的变量，类和实例都能访问。也就是说类创建了之后类变量就已经初始化了之后所有的实例都共享这个变量不会单独创建。类变量需要定义在类的里面方法的外面\nclass Foo: cls_var = \u0026#34;this is class method\u0026#34; def __init__(self): pass f0 = Foo() f1 = Foo() print(f0.cls_var, id(f0.cls_var)) print(f1.cls_var, id(f1.cls_var)) print(Foo.cls_var, id(Foo.cls_var)) Foo.cls_var = \u0026#34;changed\u0026#34; print(f0.cls_var, id(f0.cls_var)) print(f1.cls_var, id(f1.cls_var)) print(Foo.cls_var, id(Foo.cls_var)) 输出\nthis is class method 4328472272 this is class method 4328472272 this is class method 4328472272 changed 4328412136 changed 4328412136 changed 4328412136 类Foo定义了cls_var类变量没有绑定到任何实例，类Foo和实例f0,f1它们引用的变量cls_var都是同一个地址，所以共享一个类变量，只要改变了所有引用的都会影响。以下是统计一共创建了多少实例的例子\nclass Person: count = 0 # class variable def __init__(self, name): self.name = name Person.count += 1 # 递增 s0 = Person(name=\u0026#34;s0\u0026#34;) s1 = Person(name=\u0026#34;s1\u0026#34;) print(Person.count) # 2 __init__构造方法引用Person.count类变量每次实例对象都会自增\n实例变量(Instance Variables) 实例变量是每个实例拥有的单独变量在实例创建后才能访问，各个实例变量相互独立。与类变量不同的是实例变量一般定义在方法内(__init__方法)\nclass Person: def __init__(self, name): self.name = name # 实例变量 s0 = Person(\u0026#34;student0\u0026#34;) s1 = Person(\u0026#34;student1\u0026#34;) print(s0.name, id(s0.name)) print(s1.name, id(s1.name)) s1.name = \u0026#34;teacher\u0026#34; print(s0.name, id(s0.name)) print(s1.name, id(s1.name)) 输出\nstudent0 4304628528 student1 4304628464 student0 4304628528 teacher 4303557272 上面每个实例初始化后都会单独绑定一个name变量，通过实例.变量名访问，每个实例互不影响，也不能通过类Person访问，如果访问Person.name会抛出AttributeError\n其他 下面看个特殊的例子\nclass Person: name = \u0026#34;person\u0026#34; def __init__(self): pass s0 = Person() s1 = Person() print(s0.name) # person print(s1.name) # person print(Person.name) # person s0.name = \u0026#34;changed\u0026#34; print(s0.name) # changed print(s1.name) # person print(Person.name) # person 输出\nperson person person changed person person 按照刚才类变量共享的原则不是通过s0改变了name所有引用的都会收到影响么，怎么就变了s0的。其实这是实例s0本来引用的是类变量，在重新赋值之后实例新建了name属于自己本身的实例属性存在__dict__属性中，可以通过s0.__dict__查看\n\u0026gt;\u0026gt;\u0026gt; s0.__dict__ {\u0026#39;name\u0026#39;: \u0026#39;changed\u0026#39;} \u0026gt;\u0026gt;\u0026gt; s1.__dict__ {} \u0026gt;\u0026gt;\u0026gt; s0.__class__.name # 访问类变量 \u0026#39;person\u0026#39; Conclusions 类变量是所有实例共享的，实例变量绑定到单独的实例每个都不同 类变量定义在类内方法外实例和类都能访问，实例变量定义在方法内只能实例访问 如果实例新赋值一个和类变量相同的变量名，不会覆盖掉类变量，会自己新建实例变量 ","permalink":"https://blog.fangjiahui.me/posts/2017-03-25-difference-between-class-and-instance-variables/","summary":"Python中的类变量(class variables)和实例变量(instance variables) 类变量(Class Variables) 类变量是所有实例共享的变量，类和实例都能访问。也就是说类创建了之后类变量就已经初始化了之后所有的实例都共享这个变量不会单独创建。类变量需要定义在类的里面方法的外面\nclass Foo: cls_var = \u0026#34;this is class method\u0026#34; def __init__(self): pass f0 = Foo() f1 = Foo() print(f0.cls_var, id(f0.cls_var)) print(f1.cls_var, id(f1.cls_var)) print(Foo.cls_var, id(Foo.cls_var)) Foo.cls_var = \u0026#34;changed\u0026#34; print(f0.cls_var, id(f0.cls_var)) print(f1.cls_var, id(f1.cls_var)) print(Foo.cls_var, id(Foo.cls_var)) 输出\nthis is class method 4328472272 this is class method 4328472272 this is class method 4328472272 changed 4328412136 changed 4328412136 changed 4328412136 类Foo定义了cls_var类变量没有绑定到任何实例，类Foo和实例f0,f1它们引用的变量cls_var都是同一个地址，所以共享一个类变量，只要改变了所有引用的都会影响。以下是统计一共创建了多少实例的例子\nclass Person: count = 0 # class variable def __init__(self, name): self.","title":"Python中的类变量(class variables)和实例变量(instance variables)"},{"content":"Python中的装饰器@staticmethod和@classmethod的区别 staticmethod 当不想访问类变量和实例变量，又想优雅地写代码，方法不写在类外面避免以后代码难以维护。可以这样写封装在类里面\nclass TestStaticMethod(object): a = 0 def __init__(self): TestStaticMethod.a += 1 @staticmethod def smethod(): print('static method') bar = TestStaticMethod() bar.smethod() TestStaticMethod.smethod() 输出\nstatic method static method [Finished in 0.0s] 静态方法@staticmethod即不能访问类变量也不能访问实例变量，被装饰的方法不需要传入任何参数。类和实例都可以调用。\nclassmethod 在类中需要用到类变量而不需要实例参与的可以这样写\nclass TestClassMethod(object): a = 0 def __init__(self): TestClassMethod.a += 1 @classmethod def cmethod(cls): print('class method') # 访问a print(cls.a) foo = TestClassMethod() foo.cmethod() TestClassMethod.cmethod() 输出\nclass method 1 class method 1 [Finished in 0.0s] 类方法可以引用类变量，但被装饰的方法需要传入类对象参数cls，类和实例都可以调用。\n总结 class TestClassAndStaticMethod(object): @staticmethod def smethod(*args): print('staticmethod', args) @classmethod def cmethod(*args): print('classmethod', args) foo = TestClassAndStaticMethod() TestClassAndStaticMethod.smethod() foo.smethod() TestClassAndStaticMethod.cmethod() foo.cmethod() 输出\nstaticmethod () staticmethod () classmethod (\u0026lt;class '__main__.TestClassAndStaticMethod'\u0026gt;,) classmethod (\u0026lt;class '__main__.TestClassAndStaticMethod'\u0026gt;,) [Finished in 0.0s] @staticmethod可以不传任何变量在封装在类中，@classmethod需传入cls变量代表类对象，可以引用类变量，避免 hard-coded。\n参考：\nhttp://pythoncentral.io\nhttp://stackoverflow.com\n","permalink":"https://blog.fangjiahui.me/posts/2017-03-20-python-different-with-staticmethod-and-classmethod/","summary":"Python中的装饰器@staticmethod和@classmethod的区别 staticmethod 当不想访问类变量和实例变量，又想优雅地写代码，方法不写在类外面避免以后代码难以维护。可以这样写封装在类里面\nclass TestStaticMethod(object): a = 0 def __init__(self): TestStaticMethod.a += 1 @staticmethod def smethod(): print('static method') bar = TestStaticMethod() bar.smethod() TestStaticMethod.smethod() 输出\nstatic method static method [Finished in 0.0s] 静态方法@staticmethod即不能访问类变量也不能访问实例变量，被装饰的方法不需要传入任何参数。类和实例都可以调用。\nclassmethod 在类中需要用到类变量而不需要实例参与的可以这样写\nclass TestClassMethod(object): a = 0 def __init__(self): TestClassMethod.a += 1 @classmethod def cmethod(cls): print('class method') # 访问a print(cls.a) foo = TestClassMethod() foo.cmethod() TestClassMethod.cmethod() 输出\nclass method 1 class method 1 [Finished in 0.0s] 类方法可以引用类变量，但被装饰的方法需要传入类对象参数cls，类和实例都可以调用。\n总结 class TestClassAndStaticMethod(object): @staticmethod def smethod(*args): print('staticmethod', args) @classmethod def cmethod(*args): print('classmethod', args) foo = TestClassAndStaticMethod() TestClassAndStaticMethod.","title":"Python类方法与静态方法的区别 | different between staticmethod and classmethod"},{"content":"Markdown quick reference See the Markdown page for instructions on enabling Markdown for posts, pages and comments on your blog, and for more detailed information about using Markdown.\nSyntax Emphasis *This text will be italic*\nThis text will be italic\n_This will also be italic_\nThis will also be italic\n**This text will be bold**\nThis text will be bold\n__This will also be bold__\nThis will also be bold\n_You **can** combine them_\nYou can combine them\nInline Links A [link](https://www.google.com \u0026quot;Google\u0026quot;).A link.\nReferenced Links Some text with [a link][1] and another [link][2]. [1]: http://example.com/ \u0026quot;Title\u0026quot; [2]: http://example.org/ \u0026quot;Title\u0026quot; Some text with a link and another link.\nInline Images Logo: ![favicon](../images/favicon.ico \u0026quot;Title\u0026quot;)\nLogo: Linked Images Linked logo: [![Fython](../images/favicon.ico \u0026quot;Fython\u0026quot;)](https://www.google.com/ \u0026quot;Fython\u0026quot;)\nLinked logo: Unordered Lists * Item * Item - Item - Item Item Item Item Item Ordered Lists 1. Item 2. Item 3. Item Item Item Item Blockquotes \u0026gt; Quoted text. \u0026gt; \u0026gt; Quoted quote. \u0026gt; * Quoted \u0026gt; * List Quoted text.\nQuoted quote.\nQuoted List Inline Code `This is code` This is text This is code This is text\nCode block Code block with backticks\n``` This is a piece of code in a block ``` This is a piece of code in a block indented with four spaces\nThis is a piece of code in a block This is a piece of code in a block Heads # Header 1 ## Header 2 ### Header 3 #### Header 4 ##### Header 5 ###### Header 6 Header 1 Header 2 Header 3 Header 4 Header 5 Header 6 Extend Markdown Tables You can create tables by assembling a list of words and dividing them with hyphens - (for the first row), and then separating each column with a pipe |:\nFirst Header | Second Header ------------ | ------------- Content from cell 1 | Content from cell 2 Content in the first column | Content in the second column First Header Second Header Content from cell 1 Content from cell 2 Content in the first column Content in the second column Strikethrough ~~this~~ Any word wrapped with two tildes (like this) will appear crossed out.\nSyntax highlighting in code fences ```python {linenos=true,hl_lines=[1,\u0026quot;3-4\u0026quot;],linenostart=1} def foo(): if not bar: print(\u0026quot;hello world\u0026quot;) return True ``` Here’s an example\n1 2 3 4 def foo(): if not bar: print(\u0026#34;hello world\u0026#34;) return True Code block with Hugo\u0026rsquo;s internal highlight shortcode {{\u0026lt; highlight html \u0026gt;}} \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; {{\u0026lt; /highlight \u0026gt;}} \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; highlight line\n{{\u0026lt; highlight go \u0026quot;linenos=table,hl_lines=8 15-17,linenostart=199\u0026quot; \u0026gt;}} // GetTitleFunc returns a func that can be used to transform a string to // title case. // // The supported styles are // // - \u0026quot;Go\u0026quot; (strings.Title) // - \u0026quot;AP\u0026quot; (see https://www.apstylebook.com/) // - \u0026quot;Chicago\u0026quot; (see https://www.chicagomanualofstyle.org/home.html) // // If an unknown or empty style is provided, AP style is what you get. func GetTitleFunc(style string) func(s string) string { switch strings.ToLower(style) { case \u0026quot;go\u0026quot;: return strings.Title case \u0026quot;chicago\u0026quot;: return transform.NewTitleConverter(transform.ChicagoStyle) default: return transform.NewTitleConverter(transform.APStyle) } } {{\u0026lt; / highlight \u0026gt;}} 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 // GetTitleFunc returns a func that can be used to transform a string to // title case. // // The supported styles are // // - \u0026#34;Go\u0026#34; (strings.Title) // - \u0026#34;AP\u0026#34; (see https://www.apstylebook.com/) // - \u0026#34;Chicago\u0026#34; (see https://www.chicagomanualofstyle.org/home.html) // // If an unknown or empty style is provided, AP style is what you get. func GetTitleFunc(style string) func(s string) string { switch strings.ToLower(style) { case \u0026#34;go\u0026#34;: return strings.Title case \u0026#34;chicago\u0026#34;: return transform.NewTitleConverter(transform.ChicagoStyle) default: return transform.NewTitleConverter(transform.APStyle) } } Blockquote with attribution \u0026gt; Don't communicate by sharing memory, share memory by communicating. \u0026gt; \u0026gt; — \u0026lt;cite\u0026gt;Rob Pike[^1]\u0026lt;/cite\u0026gt; [^1]: The above quote is excerpted from Rob Pike's [talk](https://www.youtube.com/watch?v=PAAkCSZUG1c) during Gopherfest, November 18, 2015. Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nGist Task List - [x] @mentions, #refs, [links](), **formatting**, and \u0026lt;del\u0026gt;tags\u0026lt;/del\u0026gt; supported - [x] list syntax required (any unordered or ordered list supported) - [x] this is a complete item - [ ] this is an incomplete item @mentions, #refs, links, formatting, and tags supported list syntax required (any unordered or ordered list supported) this is a complete item this is an incomplete item Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://blog.fangjiahui.me/posts/2017-03-19-markdown-syntax-reference/","summary":"Markdown quick reference See the Markdown page for instructions on enabling Markdown for posts, pages and comments on your blog, and for more detailed information about using Markdown.\nSyntax Emphasis *This text will be italic*\nThis text will be italic\n_This will also be italic_\nThis will also be italic\n**This text will be bold**\nThis text will be bold\n__This will also be bold__\nThis will also be bold","title":"Markdown 语法说明"},{"content":"测试机器Centos7，本地安装nginx默认配置文件在/etc/nginx/nginx.conf文件下，保持配置文件不修改，确保include /etc/nginx/conf.d/*.conf未被注释，默认是有的\n基本配置 使用虚拟主机，在/etc/nginx/conf.d/文件夹下添加如下download.conf配置文件\nserver { listen 80; # 访问日志 access_log /var/log/nginx/d_access.log; # 错误日志 error_log /var/log/nginx/d_error.log; server_name download.com; # 存放文件的目录 root /var/www/html; location / { # 开启文件索引 autoindex on; # 关闭文件的实际大小on为bytes，off为M、K、G单位 autoindex_exact_size off; # 默认为off，显示的文件时间为GMT时间，on为本地时间 autoindex_localtime on; # 修复中文乱码 charset utf-8,gbk; } } 运行nginx -t检测配置是否准确\nsystemctl start nginx.service启动服务，现在浏览器输入http://download.com会列出/var/www/html目录下的文件\n注意：\n局域网其他机器需要添加hosts使其地址解析到服务器，linux在/etc/hosts下加一条x.x.x.x download.com，x.x.x.x为nginx服务器地址\nnginx需要有进入下载文件夹读取的权限\n配置Basic Auth认证 可以为某一目录设置basic auth密码认证\nhtpasswd -c /etc/nginx/passwd username输入密码创建一个passwd文件用于认证\n在server部分下增加一个location，设/var/www/html/secret目录为需要密码进入\nlocation /secret { autoindex on; autoindex_exact_size off; autoindex_localtime on; auth_basic \u0026quot;Restricted\u0026quot;; auth_basic_user_file /etc/nginx/passwd; } 测试配置文件通过和重启nginx现在文件夹/var/www/html/secret是需要密码访问下载的\n","permalink":"https://blog.fangjiahui.me/posts/2017-03-19-nginx-static-files-download-server-config/","summary":"测试机器Centos7，本地安装nginx默认配置文件在/etc/nginx/nginx.conf文件下，保持配置文件不修改，确保include /etc/nginx/conf.d/*.conf未被注释，默认是有的\n基本配置 使用虚拟主机，在/etc/nginx/conf.d/文件夹下添加如下download.conf配置文件\nserver { listen 80; # 访问日志 access_log /var/log/nginx/d_access.log; # 错误日志 error_log /var/log/nginx/d_error.log; server_name download.com; # 存放文件的目录 root /var/www/html; location / { # 开启文件索引 autoindex on; # 关闭文件的实际大小on为bytes，off为M、K、G单位 autoindex_exact_size off; # 默认为off，显示的文件时间为GMT时间，on为本地时间 autoindex_localtime on; # 修复中文乱码 charset utf-8,gbk; } } 运行nginx -t检测配置是否准确\nsystemctl start nginx.service启动服务，现在浏览器输入http://download.com会列出/var/www/html目录下的文件\n注意：\n局域网其他机器需要添加hosts使其地址解析到服务器，linux在/etc/hosts下加一条x.x.x.x download.com，x.x.x.x为nginx服务器地址\nnginx需要有进入下载文件夹读取的权限\n配置Basic Auth认证 可以为某一目录设置basic auth密码认证\nhtpasswd -c /etc/nginx/passwd username输入密码创建一个passwd文件用于认证\n在server部分下增加一个location，设/var/www/html/secret目录为需要密码进入\nlocation /secret { autoindex on; autoindex_exact_size off; autoindex_localtime on; auth_basic \u0026quot;Restricted\u0026quot;; auth_basic_user_file /etc/nginx/passwd; } 测试配置文件通过和重启nginx现在文件夹/var/www/html/secret是需要密码访问下载的","title":"Nginx局域网搭建静态文件下载服务器"},{"content":"Mariadb Mysql Character Sets and Collations MariaDB数据库管理系统是 MySQL 的一个分支，主要由开源社区在维护，采用 GPL 授权许可。开发这个分支的原因之一是：甲骨文公司收购了 MySQL 后，有将 MySQL 闭源的潜在风险，因此社区采用分支的方式来避开这个风险。\n所以说mariadb完全兼容mysql的设置，完全可以用mariadb代替mysql。\n初次安装完 mariadb 后运行mysql_secure_installation\n本人centos7编辑/etc/my.cnf添加如下配置(utf8mb4支持 4 个字节的emoji表情完全兼容utf8，当然也可以换成utf8不使用表情)\n[mysqld] init_connect='SET collation_connection = utf8mb4_unicode_ci' init_connect='SET NAMES utf8mb4' skip-character-set-client-handshake # 服务端默认字符集 character-set-server=utf8mb4 # 连接层默认字符集 collation-server=utf8mb4_unicode_ci [client] # 客户端来源数据默认字符集 default-character-set=utf8mb4 [mysql] # 客户端来源数据默认字符集 default-character-set=utf8mb4 重启 mariadb 服务，运行systemctl restart marriadb.service\n登录后show variables like '%char%'和show variables like '%collation%'查看是否和如下相同。\nMariaDB [(none)]\u0026gt; show global variables like '%char%'; +--------------------------+----------------------------+ | Variable_name | Value | +--------------------------+----------------------------+ | character_set_client | utf8mb4 | | character_set_connection | utf8mb4 | | character_set_database | utf8mb4 | | character_set_filesystem | binary | | character_set_results | utf8mb4 | | character_set_server | utf8mb4 | | character_set_system | utf8 | | character_sets_dir | /usr/share/mysql/charsets/ | +--------------------------+----------------------------+ 8 rows in set (0.00 sec) MariaDB [(none)]\u0026gt; show global variables like '%collation%'; +----------------------+--------------------+ | Variable_name | Value | +----------------------+--------------------+ | collation_connection | utf8mb4_unicode_ci | | collation_database | utf8mb4_unicode_ci | | collation_server | utf8mb4_unicode_ci | +----------------------+--------------------+ 3 rows in set (0.00 sec) ","permalink":"https://blog.fangjiahui.me/posts/2017-03-18-mysql-mariadb-character-sets-and-collations/","summary":"Mariadb Mysql Character Sets and Collations MariaDB数据库管理系统是 MySQL 的一个分支，主要由开源社区在维护，采用 GPL 授权许可。开发这个分支的原因之一是：甲骨文公司收购了 MySQL 后，有将 MySQL 闭源的潜在风险，因此社区采用分支的方式来避开这个风险。\n所以说mariadb完全兼容mysql的设置，完全可以用mariadb代替mysql。\n初次安装完 mariadb 后运行mysql_secure_installation\n本人centos7编辑/etc/my.cnf添加如下配置(utf8mb4支持 4 个字节的emoji表情完全兼容utf8，当然也可以换成utf8不使用表情)\n[mysqld] init_connect='SET collation_connection = utf8mb4_unicode_ci' init_connect='SET NAMES utf8mb4' skip-character-set-client-handshake # 服务端默认字符集 character-set-server=utf8mb4 # 连接层默认字符集 collation-server=utf8mb4_unicode_ci [client] # 客户端来源数据默认字符集 default-character-set=utf8mb4 [mysql] # 客户端来源数据默认字符集 default-character-set=utf8mb4 重启 mariadb 服务，运行systemctl restart marriadb.service\n登录后show variables like '%char%'和show variables like '%collation%'查看是否和如下相同。\nMariaDB [(none)]\u0026gt; show global variables like '%char%'; +--------------------------+----------------------------+ | Variable_name | Value | +--------------------------+----------------------------+ | character_set_client | utf8mb4 | | character_set_connection | utf8mb4 | | character_set_database | utf8mb4 | | character_set_filesystem | binary | | character_set_results | utf8mb4 | | character_set_server | utf8mb4 | | character_set_system | utf8 | | character_sets_dir | /usr/share/mysql/charsets/ | +--------------------------+----------------------------+ 8 rows in set (0.","title":"Mariadb Mysql 字符集设置"}]